<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta property="og:type" content="website">
<meta property="og:title" content="PW&#39;s notes">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="PW&#39;s notes">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="PW&#39;s notes">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/2/"/>





  <title>PW's notes</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">PW's notes</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/27/Beyond collaborative ﬁltering The list recommendation problem/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="PW">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PW's notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/27/Beyond collaborative ﬁltering The list recommendation problem/" itemprop="url">未命名</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-27T13:34:53+08:00">
                2018-01-27
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Beyond-collaborative-ﬁltering-The-list-recommendation-problem"><a href="#Beyond-collaborative-ﬁltering-The-list-recommendation-problem" class="headerlink" title="Beyond collaborative ﬁltering: The list recommendation problem"></a>Beyond collaborative ﬁltering: The list recommendation problem</h1><p>#推荐引擎/论文</p>
<h2 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><hr>
<p>传统的CF算法适用isolated (u,i)元组进行优化,没有考虑到::物品间的交互::,然而，在商业应用中，推荐的项目通常作为几个项目的有序列表而不是孤立的项目.物品间交互当然会对推荐列表的点击率CTR产生影响.大多CF方法也忽略了如::点击倾向变化，项目疲劳::等额外因素.</p>
<p>在这项工作中，我们介绍::列表推荐问题::,提出了一个新的::双层框架::，建立在现有的CF算法上，以::优化列表(某种排序)的点击概率::。我们的方法考虑了项目间的相互作用以及诸如项目疲劳，趋势模式，情景信息等附加信息。</p>
<blockquote>
<p>就是使用了多种特征,包括上面讲的这几点,来做排序,然后和常规的重排序相比有些创新之处. 注意优化的目标是”用户点击list中某一item的概率y^”  </p>
</blockquote>
<h2 id="INTRODUCTION-AND-MOTIVATION"><a href="#INTRODUCTION-AND-MOTIVATION" class="headerlink" title="INTRODUCTION AND MOTIVATION"></a>INTRODUCTION AND MOTIVATION</h2><hr>
<p>尽管已经研究了隐式反馈,冷启动,rank optimization等问题,独立的(u,i)元素优化仍然是主流.List推荐问题可以定义如下:给定用户u,时刻t,目标是产生一个ordered personlized的包含K个物品的list<img src="/2018/01/27/Beyond collaborative ﬁltering The list recommendation problem/20BE3405-F54F-40AA-AE9A-B81B2D904E42.png" alt="">,使得::用户点击lut中物品的概率最大化.::.(同样K个物品,排列不同,概率也不同).这个和LTR for collaborative ﬁltering也不同,LTR是训练pairwise关系,只关心(i,i)忽略了::物品间更深层交互::.</p>
<blockquote>
<p>换句话说,他就是觉得一般的LTR使用的特征不够  </p>
</blockquote>
<p>我们的研究有几个好地方</p>
<ol>
<li>lut的预期CTR依赖于diversity, item fatigue, contextual factors等而不仅仅是user-item ratings.(<strong>用的特征多</strong>)</li>
<li>一般研究认为accuracy和diversity之间有trade-off,而我们::把diversity和accuracy一同优化.::(<strong>策略上,不一定点击率高的就推荐</strong>)</li>
<li>协同过滤的许多排序方法尝试对整个目录进行排序，我们::只对提供给用户的K个项目列表进行优化。::,并且,不假设(排在前面的就比排在后面的好),而是根据项目间交互需学习最好的排序组合.</li>
</ol>
<p>我们假设已经有协同过滤(rating prediction)的实现,作为系统第一层,也作为我们系统第二层的feature输入,第二层使用不同的数据集(比如01binary数据),比如在[17]中,第二层也学习一个矩阵分解模型.</p>
<p>终极目标是提升推荐列表的CTR. 基于我们的经验,CF在学习taste方面很有效但是对优化点击率没啥意思.这两层结构有效地从第一个数据集提取相关信息，以改善第二个数据集的预测。</p>
<blockquote>
<p>motivation就是觉得现有的模型挖掘交互关系还不够,我们挖一下就能有提升.  </p>
</blockquote>
<h2 id="RELATED-WORK"><a href="#RELATED-WORK" class="headerlink" title="RELATED WORK"></a>RELATED WORK</h2><hr>
<p>List推荐问题与top-K优化有关,大多数工作借用了搜索问题的ranking技术,并且作为MF的拓展,::修改MF的损失函数来适应排序任务::.然而，在这种模式中，孤立的(u,i)元组相互排列，而不是将整个推荐列表视为优化的目标,还忽略了很多其他因素.另外,最好的推荐item应该放在第一个吗?比如垂直layout列表,放在中心可能更好.本文中,::在本文中，我们学习如何优化K个项目的有序组合，而无需对项目进行排序::</p>
<p>更多的就不详写了.</p>
<h2 id="DATASET"><a href="#DATASET" class="headerlink" title="DATASET"></a>DATASET</h2><hr>
<p>第一层使用purchase data训练CF来预测ratings.第一层的预测作为第二层的特征.第二层使用clicks data(推荐列表有没有被点击). 在每次展示之前，两个列表(main dash 和recommendation dash)都会使用第一层的预测项目分数来刷新,在我们的方法中,现在使用::监督学习::的方法来进行刷新。<br><img src="/2018/01/27/Beyond collaborative ﬁltering The list recommendation problem/A489E3E3-868D-4747-9944-720390639814.png" alt=""></p>
<p>一个展示就叫一次<strong>impression</strong>. main dash数据包括1406470用户的5339456次impression,10%作为测试集.recommendation dash有1423640用户的6319843次impression. 最后我们通过对导致了一个click的impression标1,否则表0来创造binary数据集.</p>
<p>Main Dash是被动推荐,CTR通常很低,因此我们通过uniformly sampling the negative impressions for each user来创建一个平衡的数据集.而recommendation dash的CTR高一点,不需要数据集平衡,列表长度也不一样.</p>
<h2 id="INSIGHTS"><a href="#INSIGHTS" class="headerlink" title="INSIGHTS"></a>INSIGHTS</h2><hr>
<blockquote>
<p>这里的东西还是有价值,这种分析就决定了在模型中需要使用哪些matters的特征  </p>
</blockquote>
<h3 id="Inter-item-Similarity-Interactions"><a href="#Inter-item-Similarity-Interactions" class="headerlink" title="Inter-item Similarity Interactions"></a>Inter-item Similarity Interactions</h3><p><img src="/2018/01/27/Beyond collaborative ﬁltering The list recommendation problem/096DC257-6437-4FC1-9C4C-4D46EF4AB5D8.png" alt=""><br>推荐一个大小为K的列表通常与Top-K项目的ranking非常不同。 一个关键的区别是::项目的相关性不是独立的::，多样性/相似性在确定列表的点击概率方面起着重要的作用。<br>对main dash中两个slot,上面那个的结果是,predicted 与CTR一般正相关,但是和本项目与下面项目的相关性没啥关系.对于下面的项目就不一样了.对高评分最好推荐相似的,对低评分,就最好推荐diversity(与上面项目相关).这也合理,因为用户通常先看上面项目,所以上面项目的CTR与下面项目无关,但是下面的与上面有关.</p>
<blockquote>
<p>意思就是top k里只要考虑每个项目的分数,谁该在前面谁在后面,但其实应该概率这些项目的相互作用,比如整体就这样排是不是好,对多样性,相似性又有什么影响.  </p>
</blockquote>
<h3 id="Item-Fatigue"><a href="#Item-Fatigue" class="headerlink" title="Item Fatigue"></a>Item Fatigue</h3><p>这和做生意的推荐系统有关,不过可以看看.意思就是,你老是展示同样的东西,在展示了一些次后,很可能用户看着就烦了,CTR就降低.<br><img src="/2018/01/27/Beyond collaborative ﬁltering The list recommendation problem/C9BBDAE7-1DAD-4B9E-8528-BC09BB7050AC.png" alt=""><br>上图的统计数据显示,The item-fatigue is not always inversely correlated with the click probability.对不同的推荐系统,甚至不同的用户物品,都::存在一个阈值::,超过这个值次数的impression会导致CTR下降.所以我们也是需要考虑这个因素的.</p>
<h3 id="CTR-Variations-by-Time-of-Day"><a href="#CTR-Variations-by-Time-of-Day" class="headerlink" title="CTR Variations by Time of Day"></a>CTR Variations by Time of Day</h3><p><img src="/2018/01/27/Beyond collaborative ﬁltering The list recommendation problem/195D46A8-91F6-4278-AE7D-5084C32C71F2.png" alt=""><br>这个表说明的是在一天的6个时段(4小时一个)中,有多少用户在该时段拥有高CTR比例.说明::many users have one or more preferred time-slots in which their consumption of recommendations are considerably higher than in other time-slots::</p>
<h2 id="METHODOLOGY"><a href="#METHODOLOGY" class="headerlink" title="METHODOLOGY"></a>METHODOLOGY</h2><hr>
<p>第二层的目标就是优化recommendation list的CTR. 数据集中→impression被点击没可以打上0/1标签,我们使用一个context feature vector来表示一次impression:<img src="/2018/01/27/Beyond collaborative ﬁltering The list recommendation problem/AC4141E4-B84F-41EB-ACEB-2CB392DCFC20.png" alt="">,u表示用户,l表示list, t表示时间.<br><img src="/2018/01/27/Beyond collaborative ﬁltering The list recommendation problem/0975243A-BB4B-4BE2-B707-58E875CF97AC.png" alt="">是标签,为1就是u在t时刻点击了l中某一item,否则y=-1;我们学习一个<img src="/2018/01/27/Beyond collaborative ﬁltering The list recommendation problem/8E638A6B-3EFF-4603-B75F-C5A8E4BC3855.png" alt="">来预测y^∈[-1,+1].(二分类问题)</p>
<p>模型上使用GBDT.选择GBDT的原因是其可以捕捉”complex feature interactions”以及” non-linearities with respect to the click probability”<br><img src="/2018/01/27/Beyond collaborative ﬁltering The list recommendation problem/3AE12737-D249-47CA-A001-B9307F88AD9B.png" alt=""><br>损失函数L是::binomial deviance loss function::,其形式是:<br><img src="/2018/01/27/Beyond collaborative ﬁltering The list recommendation problem/332D2ADC-4D94-4241-8072-941568D33025.png" alt=""><br>基学习器数量和叶子数通过交叉验证来选一个.</p>
<p>下面需要做::特征提取::,看看x向量是怎么构成的.</p>
<p>最开始的时候,我们首先把第一层预测得分称为ruj,表示u对list中j位置的item的predict rating.由于第一层召回的就是K个,于是我们前k个特征就是这些评分(顺序就是训练样本list的顺序):<br><img src="/2018/01/27/Beyond collaborative ﬁltering The list recommendation problem/DED5AB0B-59AC-43B0-A042-B35573D96DDD.png" alt=""><br>而现在,ruj是probabilities for the user to purchase the item,值是由对probabilistic矩阵分解得到的.[17]<a href="One-class collaborative ﬁltering with random graphs.">One-class collaborative ﬁltering with random graphs.</a></p>
<p>对于Similarity/ Diversity Features,我们队item-to-item similarity进行建模,我们使用0/1数据上的Jaccard相似度,其中Ui表示买了i的人数.<br><img src="/2018/01/27/Beyond collaborative ﬁltering The list recommendation problem/4ADA6E90-EDFC-4340-990E-DC7D024FE8E1.png" alt=""><br>本来对于K而言,会有CK2个特征,但是通过特征选择我们发现,::采用list中相邻项目之间的相似度已经是足够的::.加上后的特征向量是这样<br><img src="/2018/01/27/Beyond collaborative ﬁltering The list recommendation problem/FFC9FA3B-792D-4235-847A-836C60586D35.png" alt=""></p>
<p>对于Item Fatigue,我们一个特征是前几周中i被expose to u的次数,<img src="/2018/01/27/Beyond collaborative ﬁltering The list recommendation problem/680CE77D-EAC1-4FEF-8250-8AEBC9F8E852.png" alt="">,另一个是上一次impression至今的时间(分钟).使用<img src="/2018/01/27/Beyond collaborative ﬁltering The list recommendation problem/DB9C42F1-2629-4679-A202-DB75FE257359.png" alt="">表示.这两就有2K个feature.就接在刚才这个特征向量后面就好.</p>
<p>对于Trendiness and Temporal Features,首先包括物品发布天数(一般越新越吸引人),其次包括是否周末的01指示feature,最后包括用户统计出来的六个时段特性(对用户最喜欢的时段打1)</p>
<p>另外,还有User Features.包括用户购买物品的平均发布天数,用户买物品的价格和用户购买均价之差.</p>
<p>注意,这些特征的排列位置都有讲究,符合训练样本的list中的顺序.</p>
<p><strong>上线之后,应该就遍历各种排列方法,计算y^,listwise LTR应该也是这个意思</strong></p>
<h2 id="List-Recommendation-Policy"><a href="#List-Recommendation-Policy" class="headerlink" title="List Recommendation Policy"></a>List Recommendation Policy</h2><hr>
<p>我们并不把y^最高的展示出去,因为那样缺乏新颖性,导致fatigue,我们使用<img src="/2018/01/27/Beyond collaborative ﬁltering The list recommendation problem/912D5F57-27AA-43AD-8A48-1C098A22390C.png" alt="">表示推荐策略,<img src="/2018/01/27/Beyond collaborative ﬁltering The list recommendation problem/F945984F-1310-4D7B-8252-BCAF140E2C4E.png" alt="">表示u在t时刻被展示一个列表l的概率.这个概率能计算为<br><img src="/2018/01/27/Beyond collaborative ﬁltering The list recommendation problem/56E51148-D463-490C-8031-238C40DF8275.png" alt=""><br>The non-negative parameter α controls exploitation with α = 0 for uniform sampling and α → +∞ for maximal exploitation.</p>
<p>不过这是有概率推荐不好的东西的,接下来还有改进,这个初始配方推断了许多未观察到的列表组合的预测。他的改进是融合之前的启发式策略,规定<img src="/2018/01/27/Beyond collaborative ﬁltering The list recommendation problem/912D5F57-27AA-43AD-8A48-1C098A22390C.png" alt="">使用的策略只能是<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">we constrain Φ to use similar heuristics as Π which will prevent it from extrapolating predictions over lists that were never observed in the past. We denote by L u ⊂ L the subset of lists that user u was exposed to by Π, and alter our deﬁnition of Φ to consider only lists in Lu as follows:</span><br></pre></td></tr></table></figure></p>
<p><img src="/2018/01/27/Beyond collaborative ﬁltering The list recommendation problem/48A88216-11B8-4759-BA4B-B998BFE601F2.png" alt=""></p>
<h2 id="研究"><a href="#研究" class="headerlink" title="研究"></a>研究</h2><hr>
<ol>
<li>其所说的item-item-relationship,我理解是::要注意推荐列表后面的item怎么样是和前面item有关的,而前面的一般和后面无关,当然,这跟layout有关.可以考虑进来.(呼叫中心中不要老揣测用户的同一心思,万一它不是要干这个呢,这要根据用户的历史行为来看(可以反映到recommendation score上))::</li>
<li>关于这里的损失函数,参考<a href="bear://x-callback-url/open-note?id=9F4CFCBE-34D1-4CEB-A86F-A1F0064ED504-5950-0000836043C109C7" target="_blank" rel="noopener">各种损失函数</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/26/Past, Present, and Future of Recommender Systems An Industry Perspective/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="PW">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PW's notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/26/Past, Present, and Future of Recommender Systems An Industry Perspective/" itemprop="url">未命名</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-26T14:12:15+08:00">
                2018-01-26
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Past-Present-and-Future-of-Recommender-Systems-An-Industry-Perspective"><a href="#Past-Present-and-Future-of-Recommender-Systems-An-Industry-Perspective" class="headerlink" title="Past, Present, and Future of Recommender Systems: An Industry Perspective"></a>Past, Present, and Future of Recommender Systems: An Industry Perspective</h1><p>#推荐引擎/论文</p>
<p>这篇文章就从工业界角度介绍了推荐系统的过去(netflix price中的lesson)现在(当前流行的方法)和未来.最后点出了一些再工业界看来可能很有意义的研究方向.</p>
<h2 id="过去-NETFLIX-PRICE"><a href="#过去-NETFLIX-PRICE" class="headerlink" title="过去:NETFLIX PRICE"></a>过去:NETFLIX PRICE</h2><hr>
<p>Netflix Price比赛提的比赛目标就是降低rating prediction之中的RMSE指标,大家都努力地来提升这一个指标,当然,这是简化了推荐系统,不过很多东西还是学得到.</p>
<p>第一年过去后,胜者的方法是ensemble了107个方法,其中最有效的两个是:::SVD++和RBM::.不过问题是原本的代码写法不太能处理netflix工业化的这么大的数据集,并且没有设计新的评分来了怎么办;不过Netflix处理了这些问题,这两个算法就加入了生产环境.</p>
<p>还有一些其他的收获,比如temporal dynamics是一个重要因素;另一个是rating数据中噪声其实很多;最终达到指标的获奖方法倒也还是一个综合方法.这说明,方法::做emsemble当然是很有效的::.但是,Netflix评估了其中的单个算法,并没有发现更好的单个方法.</p>
<p><img src="/2018/01/26/Past, Present, and Future of Recommender Systems An Industry Perspective/4552D3A3-EBB7-4DAA-B8B4-DE7946840FCB.png" alt=""></p>
<h2 id="现在-BEYOND-RATING-PREDICTION"><a href="#现在-BEYOND-RATING-PREDICTION" class="headerlink" title="现在:BEYOND RATING PREDICTION"></a>现在:BEYOND RATING PREDICTION</h2><hr>
<p>这节介绍几个不同场景以及其带来的不同推荐问题.</p>
<ul>
<li>netflix现在的任务已经是流视频推荐,像youtube也是一样,推荐包括电影啊,TV show啊,直播视频啊这些,这就是<strong>视频推荐</strong>.</li>
<li><strong>音乐推荐</strong>也是一个方面,比如Spotify, Pandora, EchoNest(结合了包括collaborative ﬁltering, meta data, audio signal analysis等多种方法)</li>
<li>再一个就是<strong>e-commerce</strong>,比如Amazon(最开始使用的是itemCF),现在的场景包括首页,详情页等多种场景.还有eBay这种网站了.</li>
<li>新闻推荐:比如Google News,这类推荐最大的挑战就是<strong>fressness</strong>还有diversity(there can be a large number of articles about the same topic),但是,其有<strong>使用NLP技术来创建features</strong>的优势.</li>
<li>社交网络推荐:FB,TWITTER,Quora这种,主要问题是<strong>Who to Follow</strong>.<br>一些important issue是<em>scalability, business metrics, and integration of the system in the overall user experience</em>,一般使用::AB测试::进行比较</li>
</ul>
<p>显示rating既不是可以得到的唯一反馈也不是最好的反馈,隐式反馈更好获得,比如,在网页上你可以把用户浏览一个URL或者一个点击当做正反馈.比如BPR方法,使用隐式反馈来计算personal ranking.SVD++也结合了两种反馈,还有logistic ordinal regression(<em>Implicit feedback recommendation via implicit-to-explicit ordinal logistic regression mapping</em>)等等</p>
<p>ranking也是个重要方法,Netflix按照用户最可能play的video排序建模,而FB来优化用户会觉得一个Feed有趣的概率来排序.这都是去学一个<img src="/2018/01/26/Past, Present, and Future of Recommender Systems An Industry Perspective/743112C8-ED67-4F98-AD02-A48FBB06EAE7.png" alt="">. 对于ranking函数而言,一个显然的基准是取optimize <strong>popularity</strong>,因为平均俩说,用户最可能喜欢很多别人都也喜欢的东西.然而,这跟personalization是相反的,其给每个用户都生成一样的列表.所以,首先,ranking函数的第一个目标是to be better than item popularity来适应用户的不同口味.</p>
<p>一个明显的方式来实现这个(当rating data available)就是<strong>incorporate the predicted rating of each item</strong>,而不是使用物品的流行度或者rating on their own ,这样,我们学到的函数能balance these aspects.这是个例子,实际上item还会使用很多其他特征.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">One obvious way to approach this when rating data is available is to incorporate the predicted rating of each item. Rather than using either popularity or predicted rating on their own, we can learn to produce rankings that balance both of these aspects. This two-dimensional model is a basic example of a ranking function; real products use many other features.</span><br></pre></td></tr></table></figure></p>
<p>传统的Pairwise LTR问题把ranking当做二分类问题,这个场景下,典型的LR,GBDT都是常用的模型,Pairwise函数的优化函数基于pairwise preferences,最小化<strong>number of inversions</strong>,<strong>BPR</strong>就是一个这样方法的例子. Listwise的方法也是可以用的,RankALS,其目标函数directly includes ranking optimization,使用ALS方法来优化.这些方法使用用于rank的信息检索指标来衡量rank的性能. 理想情况下,我们想直接使用这些指标,但是实际上不太好直接用,<strong>CliMF</strong>使用了目标函数的平滑版本来进行梯度下降.</p>
<h2 id="未来"><a href="#未来" class="headerlink" title="未来"></a>未来</h2><hr>
<p>这里着眼于对工业界很重要的但是研究得没那么好的方面.</p>
<h3 id="Full-Page-Optimization"><a href="#Full-Page-Optimization" class="headerlink" title="Full Page Optimization"></a>Full Page Optimization</h3><p>尽管一维排名已经超出了评分预测的范围，并且可以进一步优化演示[23]，但是我们最感兴趣的是在整个页面上优化推荐体验。生成个性化和优化的完整页面非常复杂。在Netflix情景中，可用候选行的集合比单个项目的目录大得多，因为同一个项目可以包含在许多不同的行中，并且候选行的行列需要被选择和排列在一起。而且，在优化整个页面时，我们不仅优化了相关性，而且还考虑了多样性和新鲜度等其他方面。一个理想的全页面优化算法也可以通过理解用户的浏览或注意行为来个性化地将推荐与用户体验的其他元素混合在一起[15]。当用户的操作揭示他们当前的意图时，调整会话内的页面也可能是有用的。</p>
<p>尽管这在文献中还不是一个常见的主题，但最近有几篇论文涉及页面优化领域。例如，[1]在涉及用户顺序点击模型的新闻环境中提出一种方法，并通过子模块功能促进多样性的相关模型。另一个例子是[30]，其中搜索结果页面上的元素布局是使用学习函数在页面元素和布局上执行的。</p>
<h3 id="Personalizing-How-We-Recommend"><a href="#Personalizing-How-We-Recommend" class="headerlink" title="Personalizing How We Recommend"></a>Personalizing How We Recommend</h3><p>希望<strong>对不同的用户,使用的推荐方法也不同</strong>.推荐系统改进的另一个方向是个性化，不仅仅是我们推荐的内容，还有我们的建议。例如，许多推荐方法都有假设或参数来平衡要产生的系统的多样性，新颖性，知名度等。但是，不同的人在这些方面的理想水平上可能会有很大差异。在国际上进行推荐时，正如许多工业应用所需要的那样，这也意味着适当地适应不同文化和语言的需求和口味。另一个领域是个性化如何显示建议。对于一个给定的项目，它可以有多种选择，以及许多支持证据来帮助用户决定是否选择它。通过为特定用户提供最有用的信息来作出决定，有机会提出更加强大的建议。这不仅仅是从推荐算法本身生成解释，而是将呈现（图像，描述，元数据，与其他项目的连接等）的所有方面考虑为可以个性化的元素。在这个网络案例中，这可能意味着决定是否显示解释，评论，平均评分，播放预告片，演员信息等等，根据哪一个最有可能导致高质量的选择。进一步来说，推荐系统的整个交互范式可以是个性化的。</p>
<h3 id="Indirect-Feedback"><a href="#Indirect-Feedback" class="headerlink" title="Indirect Feedback"></a>Indirect Feedback</h3><p><strong>比如推荐了却没点,这就是一种间接反馈</strong>虽然我们已经看到行业从明确的反馈转向隐式反馈，但大部分工作都集中在直接的反馈形式上：用户直接对项目进行操作。使用标准的隐式反馈的<strong>一个缺点是我们没有看到负面的反馈。数据是正面的或缺失的</strong>。缺失的数据包括用户明确选择忽略的两个项目，因为他们没有吸引力，项目是完美的建议，但从来没有提交给用户[26]。一个可以帮助的信息是知道项目是否显示给用户。这增加了非常有价值的信息，但稍微复杂了我们的建议问题的表述。诸如协作竞争过滤（CCF）[31]等方法可以使用这些信息，不仅可以模拟类似的用户和项目之间的协作，而且可以模拟用户关注的项目之间的竞争。与项目如何呈现有关的一个相关问题是所谓的位置偏差：在列表的第一个位置上呈现的项目比进一步下降的项目更容易被看到和选择[19]。因此，对因果关系的深入理解有很大的潜力来帮助推荐系统。</p>
<p>当有人与涉及推荐的应用程序进行交互时，还收集了关于他们如何导航的许多其他间接形式的信息。另外，间接反馈与大量的上下文信息相关联。例如，在Netflix的情况下，用户对节目的偏好可能取决于诸如一天中的时间，星期几或观看设备之类的变量。在利用上下文的应用程序中有潜在的有效改进[8]。然而，间接的和上下文的变量代表了必须处理更多的数据，往往是嘈杂的，并创造了一个更高维的问题空间。</p>
<h3 id="Value-aware-Recommendations"><a href="#Value-aware-Recommendations" class="headerlink" title="Value-aware Recommendations"></a>Value-aware Recommendations</h3><p>(<strong>不同物品推荐的价值其实不同</strong>)推荐系统社区传统上将推荐系统分为基于内容和协作过滤两种。如今，这两种技术都以不同的方式结合在一起。例如，基于内容的建议被用作冷启动的解决方案。然而，在这两种情况下，从内容中提取的数据或用户交互被用来优化同样的事情：用户使用推荐的概率。不幸的是，这个表述是<strong>基于所有内容具有相同价值的假设</strong>。但是，在许多应用中，情况并非如此。</p>
<p>在电子商务中，有些商品可能对零售商有更高的利润率，同时给用户同样的满意度[32]。在媒体/新闻推荐中，我们可能会有一些内容非常相似，但质量差别很大。例如，Quora有兴趣推荐具有一定质量的项目，以便社会网络的规范以质量被重视的方式演变。大多数在线服务都会关注推荐长期保留的内容类型，而不是那些可能会增加短期点击量的内容，但可能不会导致长期的用户满意度。我们也可能要确保我们的算法不偏向某些用户，例如不加强偏见。因此，记住用户的价值也很重要。</p>
<p>许多产品定义了额外的规则来过滤或推广那些被认为对上述维度有正面影响的内容。然而，显然需要提出算法来全面关心被推荐的项目的长期价值，以便给定用户参与的相似概率，该算法可以转向长期收益。我们把这个算法家族称为价值意识的建议。</p>
<p>一个极端的和前瞻性的版本将是建议系统额外推荐什么新的项目或内容不应该创建，以满足缺失的需求，并增加最大的价值。公司已经在某种程度上评估项目。 Net fl ix使用数据来决定是否许可一个内容。 Quora使用作者创造高质量和引人入胜的答案的概率作为将问题发送给正确的人的方式。然而，在研究如何提出新项目会增加最大价值的建议方面，有很多潜在的影响。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/25/Local collaborative ranking/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="PW">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PW's notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/25/Local collaborative ranking/" itemprop="url">未命名</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-25T19:05:09+08:00">
                2018-01-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Local-collaborative-ranking"><a href="#Local-collaborative-ranking" class="headerlink" title="Local collaborative ranking"></a>Local collaborative ranking</h1><p>#推荐引擎/论文</p>
<ul>
<li style="list-style: none"><input type="checkbox"> 使用的是什么数据?</li>
</ul>
<h2 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><hr>
<p>推荐系统的CF方法通常假定评分矩阵low rank。</p>
<p>本文开发了另一种方法，其中评分矩阵是locallly low rank的。 具体地说，我们假设评分矩阵在由（u，i）对定义的度量空间的某些邻域内是low rank。我们结合了最近的一个local low rank approximation方法(使用矩阵2范数,对ranking losses进行general empirical risk minimization.).</p>
<p>实验表明，混合局部低秩矩阵的每一个被训练以最小化排名损失的组合优于许多当前使用的最先进的推荐系统。 此外，我们的方法::很容易并行化::，使其成为基于rank的推荐系统的好方法。</p>
<h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/25/Bayesian personalized ranking from implicit feedback/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="PW">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PW's notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/25/Bayesian personalized ranking from implicit feedback/" itemprop="url">未命名</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-25T19:04:42+08:00">
                2018-01-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Bayesian-personalized-ranking-from-implicit-feedback"><a href="#Bayesian-personalized-ranking-from-implicit-feedback" class="headerlink" title="Bayesian personalized ranking from implicit feedback"></a>Bayesian personalized ranking from implicit feedback</h1><p>#推荐引擎/论文</p>
<p>总是就是最后得出了一个基于底层模型的优化模型,基于这个优化模型来训练底层模型的参数,然后还是用底层的模型的perdiction rule来计算推荐,得出的结果就更符合ranking的情况.</p>
<p>隐式数据上,根据 看过&gt;没看过 来构造pairwise数据.</p>
<h2 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><hr>
<p>这里把ranking任务称为item recommendation.本文研究隐式反馈(点击,购买),引出BPR-Opt问题,::从问题的贝叶斯分析得出的最大的后验概率估计量.::. 我们还提供了一个通用学习算法来优化BPR-Opt模型,该方法基于SGD和bootstrap sampling.可以把方法应用到MF和KNN.</p>
<h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><hr>
<p>项目推荐的任务是为一组项目创建用户特定的排名。本文的贡献有几点</p>
<ol>
<li>我们提出通用优化准则=&gt;BPR-Opt,以从最大后验估计估计得出的最佳personlized ranking。 我们展示了BPR-Opt的类似于以最大化ROC曲线下面积。</li>
<li>提出优化算法LearnBPR</li>
<li>提出了如何把LearnBPR运用到现有stateOfArt算法</li>
<li>实验表明,对ranking任务,性能比那些都要好</li>
</ol>
<h2 id="RELATED-WORK"><a href="#RELATED-WORK" class="headerlink" title="RELATED WORK"></a>RELATED WORK</h2><hr>
<p>那就是MF和KNN及其各种变种了.其缺点是::Even though all the work on item prediction discussed above is evaluated on personalized ranking datasets, none of these methods directly optimizes its model parameters for ranking.:: 本文的方法基于pairwise(user-speciﬁc order of two items),和一般LTR相比,我们的方法是personlized的.</p>
<h2 id="Personalized-Ranking"><a href="#Personalized-Ranking" class="headerlink" title="Personalized Ranking"></a>Personalized Ranking</h2><hr>
<p>注意,implicit只有正反馈.首先,<em>U</em>表示用户集,<em>I</em>表示物品集.<em>S</em>表示<em>U×I</em>.任务可以描述为产生一个personlized total ranking <img src="/2018/01/25/Bayesian personalized ranking from implicit feedback/FA4B75A5-9F78-4427-89FA-9C13253DD1E5.png" alt="">,&gt;u满足下面的属性<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback/91C702AB-B5C2-456D-860F-7E1B95C5998A.png" alt=""><br>意思也就是说,两物品不相等,则rank不相等;若rank相等则一定物品相等,若i排j前,j排k前,则i排k前.另外,使用<em>I+</em>和<em>U+</em>表示在S中有隐式反馈的物品或用户</p>
<p>经典的ranking方法还是学习一个recommendation score然后排下来.并且有反馈当1没反馈当0.本文认为,你把要预测的都当做了0,然后学习S,要不是因为正则,你学出来的模型的估计可能都会是0,那就毫无意义.<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback/73979333-68C0-43B7-BA5E-60EBE64ECFCD.png" alt=""></p>
<p>本文基于pairwise,并假设</p>
<ul>
<li>若u看了i [(u,i)∈S],则假设u对i的喜欢比所有non-observed item要高</li>
<li>若都看了或都没看,则无法判断preference.<br>于是训练数据可表示为:<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback/A5B9E3EA-FA8A-4122-86C2-DC79D79D840A.png" alt=""><br>其中i是看过的,j是没看过的.(不过就是每个user都有这么一个矩阵了)</li>
</ul>
<p>我们的方法好处就有我们把将来要预测的任务(两个没看过物品的排序)没当做负例,而是missing的,于是这::保证了训练数据和测试数据是不相交的::<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback/ADF7D548-3473-4F68-80AF-92555D3CDD35.png" alt=""></p>
<h2 id="BPR"><a href="#BPR" class="headerlink" title="BPR"></a>BPR</h2><hr>
<p>首先介绍<strong>Optimization Criterion</strong>.我们要最大化下面的后验概率,其中θ是模型参数,模型可以是MF等<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback/85AC32E9-A5C8-4B8A-B06F-DED03B070D8A.png" alt="">……(1)(∝表示正比)<br>左边表示在&gt;u这种desired latent preference structure下,取得模型参数θ的值的概率,最大概率时的θ就是我们需要的θ,然后&gt;u的关系是由训练样本来拟合的.</p>
<p>我们假设用户之间行为独立性,用户对不同item行为的独立性.于是<img src="/2018/01/25/Bayesian personalized ranking from implicit feedback/DBA955C0-1D2E-4A66-BD82-B024DE3EF4F5.png" alt="">可以重写为<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback/B732FAA5-DDE2-4BB5-8590-C148E42F0DB5.png" alt="">……(2)<br>(2)式的意思是把&gt;u这个关系拆成S中所有(u,i,j)对的独立关系之积,那么,其值也就是所有满足&gt;u关系的(u,i,j)对,取出现概率;而所有不满足&gt;u关系的(u,i,j)对,取不出现概率(1-出现概率).<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback/D781948F-82EA-4B68-9070-B3EF3EF8523B.png" alt=""><br>(2)式又因为对称性可以简化为<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback/118E2BCA-00E3-47EB-9568-1A521133AF4D.png" alt="">…….(3)<br>然后分析(3)的右边,我们可以定义用户u对Ds中的(u,i,j)对,对i的喜好真大于u的概率是<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback/E7D90E3E-21AD-406C-980E-EC1E29171D1F.png" alt="">…….(4)<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback/60D62C44-8BB8-4E84-9007-FF620A5BA72E.png" alt=""><br>而x^表示底层模型(KNN,MF)的输出(建模了u与i,j之间的潜在关系),我们也就是把底层模型的输出利用sigmoid映射到(0,1)之间的概率.</p>
<p>在(1)式右边,<img src="/2018/01/25/Bayesian personalized ranking from implicit feedback/BA5DF0C6-4480-49D5-A714-DA1B783CB008.png" alt="">还没有讨论.我们引入一个一般的先验密度p（Θ），它是一个零均值和方差-协方差矩阵∑θ的正态分布:<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback/9B9402C0-0412-4182-B1B8-A029C8CF85C2.png" alt="">……..(5)</p>
<p>于是,我们可以取(1)式左边的对数似然函数.<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback/6DE206CC-5FAE-46C9-A774-0DCC1A97477C.png" alt="">…….(6)<br>where λΘ are model speciﬁc regularization parameters.<br>第一步是按(1)式得到,第二部是按(4)式得到,第三部按的是对数运算法则,第四步按…??</p>
<h3 id="学习算法"><a href="#学习算法" class="headerlink" title="学习算法"></a>学习算法</h3><p>我们知道我们要学习的就是(6)式,使其最大(极大似然).(6)式是可微的,梯度下降是明显的选择,但是对我们的问题还是需要修改,我们使用a stochastic gradient-descent algorithm based on bootstrap sampling of training triples<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback/2D9DEB33-2A8D-4D61-9074-56902BF37C8C.png" alt=""></p>
<p>首先求(6)对θ的梯度:<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback/7E514964-282C-4276-8F5C-AFDABE888A3A.png" alt=""><br>只需要知道x^对参数的导数就可以计算了.</p>
<p>首先因为我们的训练样本是Ds=O(S*I),整体梯度下降不可行.<br>梯度下降是这样<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback/1661373F-E76D-4761-9C25-5535260BDF99.png" alt=""><br>这是好的,但是有一个问题是我们如何遍历训练样本,如果user-wise或者item-wise,这可以导致poor convergence(收敛性差),因为在一个same u-i pair上有很多连续的更新==&gt;for one user-item pair (u,i) there are many j with (u,i,j)∈ DS.</p>
<p>为了解决上面问题,我们随机选择三元组,采用bootstrap sampling approach with replacement().我们不需要遍历所有样本一次,因为样本好大,通常一部分就够了.下图显示了效果<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback/2F9496B6-D4BA-447F-AF31-ECC67D255A80.png" alt=""></p>
<h2 id="结合其他模型"><a href="#结合其他模型" class="headerlink" title="结合其他模型"></a>结合其他模型</h2><hr>
<p>我们选择MF和KNN,其学习结果都是(u,l)用户u对物品l的喜好x^ul.我们可以定义x^uij为:<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback/EF77E2F2-BC6D-4881-9634-DF728B67B79D.png" alt="">……(7)<br>意思很明确,把两者的分差在bpr里把这拟合成喜欢i超过j的概率.</p>
<p>对于MF,用户物品评分矩阵X^分解为了W*H,W是用户隐因子矩阵,H是item隐因子矩阵,wu表示用户向量,hi表示物品向量.于是MF的θ就是(W,H),也可以看做latent variables.对于ranking,我们执行BPR-Opt算法,其中我们需要^x(7式)对参数的导数,给出如下:<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback/04FCFD29-17A4-4E09-9077-F09F4B706A08.png" alt=""><br>也就是说,x^uij跟三种参数有关,就是<br>另外,还使用三个正则约束,one λ W for the user features W; for the item features H we have two regularization constants, λH+ that is used for positive updates on hif , and λH− for negative updates on hjf .</p>
<p>对于Adaptive KNN,由于KNN不是机器学习算法,我们使用adaptive KNN(利用机器学习来学习ii相似度矩阵C),描述如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A better strategy is to adapt the similarity measure C to the problem by learning it. This can be either done by using C directly as model parameters or if the number of items is too large, one can learn a factorization HH t of C with H : I × k. In the following and also in our evaluation we use the ﬁrst approach of learning C directly without factorizing it.</span><br><span class="line"></span><br><span class="line">Again for optimizing the kNN model for ranking, we apply the BPR optimization criterion and use the LearnBPR algorithm. For applying the algorithm, the gradient of xˆ uij with respect to the model parameters C is:</span><br></pre></td></tr></table></figure></p>
<p>同样需要求偏导,下面给出<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback/7F7655BA-5604-47F4-8336-41D657DB0B96.png" alt=""><br>We have two regularization constants, λ + for updates on c il , and λ − for updates on cjl .</p>
<h2 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h2><hr>
<p>使用AUC评估指标,结果如下,看看就好<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback/C8ADC423-3CC0-49EA-BB2C-D94192F8ED01.png" alt=""></p>
<h2 id="Bootstrap"><a href="#Bootstrap" class="headerlink" title="Bootstrap"></a>Bootstrap</h2><hr>
<p>Bootstrap的思想，是生成一系列bootstrap伪样本，每个样本是初始数据有放回抽样。通过对伪样本的计算，获得统计量的分布。例如，要进行1000次bootstrap，求平均值的置信区间，可以对每个伪样本计算平均值。这样就获得了1000个平均值。对着1000个平均值的分位数进行计算， 即可获得置信区间。已经证明，在初始样本足够大的情况下，bootstrap抽样能够无偏得接近总体的分布<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback/993102CD-8DF3-4EBF-AB09-67EF0301FE0E.png" alt=""></p>
<h2 id="AUC-ROC曲线"><a href="#AUC-ROC曲线" class="headerlink" title="AUC/ROC曲线"></a>AUC/ROC曲线</h2><hr>
<p>首先有</p>
<ul>
<li>精确度P:正划分里正例的比例</li>
<li>召回率R:正例处于正划分的比例</li>
</ul>
<p>对于分类任务,我们想象把测试样本按输出概率排序(负左正右),分类相当于在序列中选择一个::截断点::.如果你重视P,那么截断点选得靠前一点(保证概率较大的你才当做正例),要是重视R,你就把截断点放后面一点.一个截断点就对应一个P/R,就可以画P/R曲线.(在RS中就对应N).我们把截断点的左边称为<strong>负划分</strong>,右边称为<strong>正划分</strong>.</p>
<p>我们使用ROC来研究模型的泛化性能.同样按上面的截断方法,可以得到ROC曲线.</p>
<ul>
<li>y轴是:真正例率,其实就是召回率(::所有正例里处于你的正划分内的比例::)</li>
<li>x轴是:假正例率,::所有反例里处于你正划分内的比例::,公式是 <blockquote>
<p>(预+真-)/[(预-真-)+(预+真-)]  </p>
</blockquote>
</li>
</ul>
<p>下面是一个ROC曲线的样子,对角线代表的即使随猜测….点(0,1)是理想情况,代表<strong>把所有正例排在了反例之前.</strong>可以看见,(0,0)对应代表你把全部都视为反例,(1,1)对应你把全部都视为正例<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback/656F644F-2862-4A9D-A25B-D66F9A0707D2.png" alt=""></p>
<p>和P/R曲线一样,若一个模型A的ROC曲线包住另一个模型B,则A性能更好,但是在曲线交叉的时候难以判断,此时::合理的依据是ROC曲线下的面积: AUC::</p>
<p>当我们拥有ROC坐标上的点{(x1,y1),(x2,y2),(x3,y3)…},通过下面公式来估算AUC<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback/F9D93F2C-A55E-4306-82D2-63EADAB70A10.png" alt=""></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/25/Bayesian personalized ranking from implicit feedback 1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="PW">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PW's notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/" itemprop="url">未命名</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-25T19:04:42+08:00">
                2018-01-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Bayesian-personalized-ranking-from-implicit-feedback"><a href="#Bayesian-personalized-ranking-from-implicit-feedback" class="headerlink" title="Bayesian personalized ranking from implicit feedback"></a>Bayesian personalized ranking from implicit feedback</h1><p>#推荐引擎/论文</p>
<p>总是就是最后得出了一个基于底层模型的优化模型,基于这个优化模型来训练底层模型的参数,然后还是用底层的模型的perdiction rule来计算推荐,得出的结果就更符合ranking的情况.</p>
<p>隐式数据上,根据 看过&gt;没看过 来构造pairwise数据.</p>
<h2 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><hr>
<p>这里把ranking任务称为item recommendation.本文研究隐式反馈(点击,购买),引出BPR-Opt问题,::从问题的贝叶斯分析得出的最大的后验概率估计量.::. 我们还提供了一个通用学习算法来优化BPR-Opt模型,该方法基于SGD和bootstrap sampling.可以把方法应用到MF和KNN.</p>
<h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><hr>
<p>项目推荐的任务是为一组项目创建用户特定的排名。本文的贡献有几点</p>
<ol>
<li>我们提出通用优化准则=&gt;BPR-Opt,以从最大后验估计估计得出的最佳personlized ranking。 我们展示了BPR-Opt的类似于以最大化ROC曲线下面积。</li>
<li>提出优化算法LearnBPR</li>
<li>提出了如何把LearnBPR运用到现有stateOfArt算法</li>
<li>实验表明,对ranking任务,性能比那些都要好</li>
</ol>
<h2 id="RELATED-WORK"><a href="#RELATED-WORK" class="headerlink" title="RELATED WORK"></a>RELATED WORK</h2><hr>
<p>那就是MF和KNN及其各种变种了.其缺点是::Even though all the work on item prediction discussed above is evaluated on personalized ranking datasets, none of these methods directly optimizes its model parameters for ranking.:: 本文的方法基于pairwise(user-speciﬁc order of two items),和一般LTR相比,我们的方法是personlized的.</p>
<h2 id="Personalized-Ranking"><a href="#Personalized-Ranking" class="headerlink" title="Personalized Ranking"></a>Personalized Ranking</h2><hr>
<p>注意,implicit只有正反馈.首先,<em>U</em>表示用户集,<em>I</em>表示物品集.<em>S</em>表示<em>U×I</em>.任务可以描述为产生一个personlized total ranking <img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/FA4B75A5-9F78-4427-89FA-9C13253DD1E5.png" alt="">,&gt;u满足下面的属性<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/91C702AB-B5C2-456D-860F-7E1B95C5998A.png" alt=""><br>意思也就是说,两物品不相等,则rank不相等;若rank相等则一定物品相等,若i排j前,j排k前,则i排k前.另外,使用<em>I+</em>和<em>U+</em>表示在S中有隐式反馈的物品或用户</p>
<p>经典的ranking方法还是学习一个recommendation score然后排下来.并且有反馈当1没反馈当0.本文认为,你把要预测的都当做了0,然后学习S,要不是因为正则,你学出来的模型的估计可能都会是0,那就毫无意义.<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/73979333-68C0-43B7-BA5E-60EBE64ECFCD.png" alt=""></p>
<p>本文基于pairwise,并假设</p>
<ul>
<li>若u看了i [(u,i)∈S],则假设u对i的喜欢比所有non-observed item要高</li>
<li>若都看了或都没看,则无法判断preference.<br>于是训练数据可表示为:<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/A5B9E3EA-FA8A-4122-86C2-DC79D79D840A.png" alt=""><br>其中i是看过的,j是没看过的.(不过就是每个user都有这么一个矩阵了)</li>
</ul>
<p>我们的方法好处就有我们把将来要预测的任务(两个没看过物品的排序)没当做负例,而是missing的,于是这::保证了训练数据和测试数据是不相交的::<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/ADF7D548-3473-4F68-80AF-92555D3CDD35.png" alt=""></p>
<h2 id="BPR"><a href="#BPR" class="headerlink" title="BPR"></a>BPR</h2><hr>
<p>首先介绍<strong>Optimization Criterion</strong>.我们要最大化下面的后验概率,其中θ是模型参数,模型可以是MF等<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/85AC32E9-A5C8-4B8A-B06F-DED03B070D8A.png" alt="">……(1)(∝表示正比)<br>左边表示在&gt;u这种desired latent preference structure下,取得模型参数θ的值的概率,最大概率时的θ就是我们需要的θ,然后&gt;u的关系是由训练样本来拟合的.</p>
<p>我们假设用户之间行为独立性,用户对不同item行为的独立性.于是<img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/DBA955C0-1D2E-4A66-BD82-B024DE3EF4F5.png" alt="">可以重写为<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/B732FAA5-DDE2-4BB5-8590-C148E42F0DB5.png" alt="">……(2)<br>(2)式的意思是把&gt;u这个关系拆成S中所有(u,i,j)对的独立关系之积,那么,其值也就是所有满足&gt;u关系的(u,i,j)对,取出现概率;而所有不满足&gt;u关系的(u,i,j)对,取不出现概率(1-出现概率).<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/D781948F-82EA-4B68-9070-B3EF3EF8523B.png" alt=""><br>(2)式又因为对称性可以简化为<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/118E2BCA-00E3-47EB-9568-1A521133AF4D.png" alt="">…….(3)<br>然后分析(3)的右边,我们可以定义用户u对Ds中的(u,i,j)对,对i的喜好真大于u的概率是<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/E7D90E3E-21AD-406C-980E-EC1E29171D1F.png" alt="">…….(4)<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/60D62C44-8BB8-4E84-9007-FF620A5BA72E.png" alt=""><br>而x^表示底层模型(KNN,MF)的输出(建模了u与i,j之间的潜在关系),我们也就是把底层模型的输出利用sigmoid映射到(0,1)之间的概率.</p>
<p>在(1)式右边,<img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/BA5DF0C6-4480-49D5-A714-DA1B783CB008.png" alt="">还没有讨论.我们引入一个一般的先验密度p（Θ），它是一个零均值和方差-协方差矩阵∑θ的正态分布:<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/9B9402C0-0412-4182-B1B8-A029C8CF85C2.png" alt="">……..(5)</p>
<p>于是,我们可以取(1)式左边的对数似然函数.<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/6DE206CC-5FAE-46C9-A774-0DCC1A97477C.png" alt="">…….(6)<br>where λΘ are model speciﬁc regularization parameters.<br>第一步是按(1)式得到,第二部是按(4)式得到,第三部按的是对数运算法则,第四步按…??</p>
<h3 id="学习算法"><a href="#学习算法" class="headerlink" title="学习算法"></a>学习算法</h3><p>我们知道我们要学习的就是(6)式,使其最大(极大似然).(6)式是可微的,梯度下降是明显的选择,但是对我们的问题还是需要修改,我们使用a stochastic gradient-descent algorithm based on bootstrap sampling of training triples<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/2D9DEB33-2A8D-4D61-9074-56902BF37C8C.png" alt=""></p>
<p>首先求(6)对θ的梯度:<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/7E514964-282C-4276-8F5C-AFDABE888A3A.png" alt=""><br>只需要知道x^对参数的导数就可以计算了.</p>
<p>首先因为我们的训练样本是Ds=O(S*I),整体梯度下降不可行.<br>梯度下降是这样<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/1661373F-E76D-4761-9C25-5535260BDF99.png" alt=""><br>这是好的,但是有一个问题是我们如何遍历训练样本,如果user-wise或者item-wise,这可以导致poor convergence(收敛性差),因为在一个same u-i pair上有很多连续的更新==&gt;for one user-item pair (u,i) there are many j with (u,i,j)∈ DS.</p>
<p>为了解决上面问题,我们随机选择三元组,采用bootstrap sampling approach with replacement().我们不需要遍历所有样本一次,因为样本好大,通常一部分就够了.下图显示了效果<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/2F9496B6-D4BA-447F-AF31-ECC67D255A80.png" alt=""></p>
<h2 id="结合其他模型"><a href="#结合其他模型" class="headerlink" title="结合其他模型"></a>结合其他模型</h2><hr>
<p>我们选择MF和KNN,其学习结果都是(u,l)用户u对物品l的喜好x^ul.我们可以定义x^uij为:<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/EF77E2F2-BC6D-4881-9634-DF728B67B79D.png" alt="">……(7)<br>意思很明确,把两者的分差在bpr里把这拟合成喜欢i超过j的概率.</p>
<p>对于MF,用户物品评分矩阵X^分解为了W*H,W是用户隐因子矩阵,H是item隐因子矩阵,wu表示用户向量,hi表示物品向量.于是MF的θ就是(W,H),也可以看做latent variables.对于ranking,我们执行BPR-Opt算法,其中我们需要^x(7式)对参数的导数,给出如下:<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/04FCFD29-17A4-4E09-9077-F09F4B706A08.png" alt=""><br>也就是说,x^uij跟三种参数有关,就是<br>另外,还使用三个正则约束,one λ W for the user features W; for the item features H we have two regularization constants, λH+ that is used for positive updates on hif , and λH− for negative updates on hjf .</p>
<p>对于Adaptive KNN,由于KNN不是机器学习算法,我们使用adaptive KNN(利用机器学习来学习ii相似度矩阵C),描述如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A better strategy is to adapt the similarity measure C to the problem by learning it. This can be either done by using C directly as model parameters or if the number of items is too large, one can learn a factorization HH t of C with H : I × k. In the following and also in our evaluation we use the ﬁrst approach of learning C directly without factorizing it.</span><br><span class="line"></span><br><span class="line">Again for optimizing the kNN model for ranking, we apply the BPR optimization criterion and use the LearnBPR algorithm. For applying the algorithm, the gradient of xˆ uij with respect to the model parameters C is:</span><br></pre></td></tr></table></figure></p>
<p>同样需要求偏导,下面给出<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/7F7655BA-5604-47F4-8336-41D657DB0B96.png" alt=""><br>We have two regularization constants, λ + for updates on c il , and λ − for updates on cjl .</p>
<h2 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h2><hr>
<p>使用AUC评估指标,结果如下,看看就好<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/C8ADC423-3CC0-49EA-BB2C-D94192F8ED01.png" alt=""></p>
<h2 id="Bootstrap"><a href="#Bootstrap" class="headerlink" title="Bootstrap"></a>Bootstrap</h2><hr>
<p>Bootstrap的思想，是生成一系列bootstrap伪样本，每个样本是初始数据有放回抽样。通过对伪样本的计算，获得统计量的分布。例如，要进行1000次bootstrap，求平均值的置信区间，可以对每个伪样本计算平均值。这样就获得了1000个平均值。对着1000个平均值的分位数进行计算， 即可获得置信区间。已经证明，在初始样本足够大的情况下，bootstrap抽样能够无偏得接近总体的分布<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/993102CD-8DF3-4EBF-AB09-67EF0301FE0E.png" alt=""></p>
<h2 id="AUC-ROC曲线"><a href="#AUC-ROC曲线" class="headerlink" title="AUC/ROC曲线"></a>AUC/ROC曲线</h2><hr>
<p>首先有</p>
<ul>
<li>精确度P:正划分里正例的比例</li>
<li>召回率R:正例处于正划分的比例</li>
</ul>
<p>对于分类任务,我们想象把测试样本按输出概率排序(负左正右),分类相当于在序列中选择一个::截断点::.如果你重视P,那么截断点选得靠前一点(保证概率较大的你才当做正例),要是重视R,你就把截断点放后面一点.一个截断点就对应一个P/R,就可以画P/R曲线.(在RS中就对应N).我们把截断点的左边称为<strong>负划分</strong>,右边称为<strong>正划分</strong>.</p>
<p>我们使用ROC来研究模型的泛化性能.同样按上面的截断方法,可以得到ROC曲线.</p>
<ul>
<li>y轴是:真正例率,其实就是召回率(::所有正例里处于你的正划分内的比例::)</li>
<li>x轴是:假正例率,::所有反例里处于你正划分内的比例::,公式是 <blockquote>
<p>(预+真-)/[(预-真-)+(预+真-)]  </p>
</blockquote>
</li>
</ul>
<p>下面是一个ROC曲线的样子,对角线代表的即使随猜测….点(0,1)是理想情况,代表<strong>把所有正例排在了反例之前.</strong>可以看见,(0,0)对应代表你把全部都视为反例,(1,1)对应你把全部都视为正例<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/656F644F-2862-4A9D-A25B-D66F9A0707D2.png" alt=""></p>
<p>和P/R曲线一样,若一个模型A的ROC曲线包住另一个模型B,则A性能更好,但是在曲线交叉的时候难以判断,此时::合理的依据是ROC曲线下的面积: AUC::</p>
<p>当我们拥有ROC坐标上的点{(x1,y1),(x2,y2),(x3,y3)…},通过下面公式来估算AUC<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/F9D93F2C-A55E-4306-82D2-63EADAB70A10.png" alt=""></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/22/Evaluation of RecommendationsRating-Prediction and Ranking/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="PW">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PW's notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/22/Evaluation of RecommendationsRating-Prediction and Ranking/" itemprop="url">未命名</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-22T22:08:26+08:00">
                2018-01-22
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Evaluation-of-Recommendations-Rating-Prediction-and-Ranking"><a href="#Evaluation-of-Recommendations-Rating-Prediction-and-Ranking" class="headerlink" title="Evaluation of Recommendations:Rating-Prediction and Ranking"></a>Evaluation of Recommendations:Rating-Prediction and Ranking</h1><p>#推荐引擎/论文</p>
<h2 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><hr>
<p>在本文中，我们仔细研究了rating和ranking两种方法，发现主要</p>
<ol>
<li>差异在于考虑到的训练和测试数据评级预测仅关注观察到的评级，而排名通常考虑集合中的所有物品，不论是用户对它们进行评价与否。</li>
<li>预测observed评级的试验方法虽然在文献中很受欢迎，但它只能解决集合中任何物品的评分预测任务的（小）部分，这是一个常见的现实世界问题。原因是数据中的选择偏差.</li>
<li>We show that the latter rating-prediction task involves the prediction task ’Who rated What’ as a subproblem, which can be cast as a classiﬁcation or ranking problem. This suggests that solving the ranking problem is not only valuable by itself, but also for predicting the rating value of any item.::</li>
</ol>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><hr>
<p>关于推荐系统的文献通常区分测量推荐准确性的两种方法：::评分预测::，通常以均方根误差（RMSE）来衡量;和::排名::，其衡量::精度和召回::等指标。在本文中，我们将详细研究这两种精度测量，并确定不同的变体。</p>
<p>关于评级预测，文献主要侧重于::预测用户故意选择评价的物品::的评价值。(::前提就是用户对这些东西感兴趣,即使看完评分很低::)这种数据可以很容易地收集，因此很容易用于推荐系统的培训和测试,所以::测试用的也是用户已然评分(感兴趣)的数据::,这样的系统泛化到实际情况难免有误差.</p>
<p>在本文的<strong>第一部分</strong>，我们确定了三个rating prediction的变种，并且说明它们在提供给推荐问题的答案以及solve them困难程度方面是如何彼此不同的。 此外，我们显示许多真实世界的评级预测任务需要解决一个额外的子问题：::哪个用户故意选择哪个物品来评分::（也称为“Who rated What”[1]）。 这个子问题可能会被当作一个分类或排名问题。</p>
<p>在本文的<strong>第二部分</strong>,我们研究了三种排名变体：收集中的所有物品的排名，仅评价用户尚未评分的物品的排名，以及仅评价用户已经评分的物品的排名。并标明”选择训练/测试集的时候,user-item pairs to consider, may be more important than the ranking metric for solving a given real-world ranking problem.”(选择训练/测试方法比选择ranking度量更重要)</p>
<p>当将评级预测与排名进行比较时，我们发现它们的::主要差异不是由不同的度量标准引起的::（例如，RMSE与排名度量标准）。相反，::这是由于考虑了用户物品对：仅在数据中观察到评级的用户物品对的子集（例如，针对RMSE）与所有用户物品对（无论是用户故意选择给一个物品分配一个评估值。)::</p>
<h2 id="Rating-Prediction"><a href="#Rating-Prediction" class="headerlink" title="Rating Prediction"></a>Rating Prediction</h2><hr>
<h3 id="model"><a href="#model" class="headerlink" title="model"></a>model</h3><p>首先是<strong>建模</strong>.一般的可用数据中,rating数据是”<strong>missing not at random(非随机缺失)</strong>”的,主要原因是用户可以自由选择要评分的物品。</p>
<blockquote>
<p><img src="/2018/01/22/Evaluation of RecommendationsRating-Prediction and Ranking/7A648180-F82A-413E-9595-C8D330696F57.png" alt="">……(1)<br>如上图所示，在这个图形模型中，U表示与用户有关的随机变量，取值为u，其中u∈{1，…，n}表示用户ID，n是用户数量。同样，I是物品的随机变量，取值i∈{1，…，m}，其中m是集合中物品的数量。<br>用户故意::选择::对物品i进行评级的决定由随机变量C表示，其取值c∈{c+，c-}，其中c+表示用户选择对物品进行评级，而c-表示用户不会故意选择评价物品。<br>最后，R是关于rating value的随机变量，取值r。例如，在1到5星级的评级中，r∈{1，…，5}.</p>
</blockquote>
<p>C依赖于U和I,所以::这个模型能捕捉依赖于u和i的任何选择物品来评级的理由::(比如物品流行度). 上图左右两部分是马尔科夫等价的(::表示相同的概率分布::). 假设所有随机变量U，I，C和R都是离散的，我们假定最一般的概率分布是multinouli分布。</p>
<h3 id="Variants"><a href="#Variants" class="headerlink" title="Variants"></a>Variants</h3><p>现在介绍<strong>Variants</strong>. 问题描述为<strong>预测u给i的r</strong>.可以转化为预测u对i打的每个评分值r的概率<img src="/2018/01/22/Evaluation of RecommendationsRating-Prediction and Ranking/2053F3C5-10FB-4C1E-BF08-A56A7D883E17.png" alt="">.根据图1,这个式子又可以分解为:</p>
<blockquote>
<p><img src="/2018/01/22/Evaluation of RecommendationsRating-Prediction and Ranking/7EC5846E-ACE7-4A73-A934-CF83D1F37197.png" alt="">……(2)<br>(1)(2)(3)就是三种预测问题的变体.并且通过＂the probability that the user deliberately chooses to rate an item＂相关联</p>
<ol>
<li>(1)这是用户在集合中为物品i分配评分值r的概率。 对于物品i是没有限制的,它可以是物品集中的任何物品。 对于任何物品i做出准确的评级预测的能力在实际应用中是非常有用的，因为它让系统能从整个物品集中找出具有最高（预测）享受值的物品。</li>
<li>(2)这是用户::在用户故意选择对该物品进行评分的情况下::将评分值r分配给物品i的概率。 事实上，由于数据的稀疏性，它可能只适用于一小部分物品. </li>
<li>这是用户在用户不会故意选择评价该项目的条件下将评价值r分配给项目i的概率,这种数据一般得不到,这让我们::难以预测这个概率分布::,由于数据稀疏，此分布适用于绝大多数&lt;用户物品&gt;.</li>
</ol>
</blockquote>
<p>(2)式还表明,<em>conditional probabilities</em> p(r|c+,u,i) and p(r|c−,u,i) <strong>have to be estimated</strong> as to obtain valid rating predictions for any item in the collection.</p>
<h3 id="Relationship-of-the-three-Variants"><a href="#Relationship-of-the-three-Variants" class="headerlink" title="Relationship of the three Variants"></a>Relationship of the three Variants</h3><p>我们简单地介绍过程.p(r)表示对所有用户u和项目i的,评级值r平均概率,从边缘概率公式我们可以推出:(2~3是由图1右的结果推出的)<br><img src="/2018/01/22/Evaluation of RecommendationsRating-Prediction and Ranking/CA0F92F9-EBBD-401E-8303-CE2FB42EBBFF.png" alt=""><br>另外还有<br><img src="/2018/01/22/Evaluation of RecommendationsRating-Prediction and Ranking/F100B51E-77D7-4DE2-983C-F337363AEF00.png" alt=""><br>由于数据稀疏性,方程6约等号的准确度可达90%多以上,我们可以得出结论:</p>
<blockquote>
<p>由于数据稀疏，评分预测的变体1.和3.必须密切相关。 相比之下，变体2不需要与变体1或3相似。  </p>
</blockquote>
<p>推荐系统的预测评分值的平均值,对RMSE的准确性有重要影响,接下来,我们分析平均评分R的期望<br><img src="/2018/01/22/Evaluation of RecommendationsRating-Prediction and Ranking/5F7959BF-0BFB-479A-BA41-04A320DCD9D6.png" alt=""><br>这还是很容易看懂意思的,事实上,雅虎音乐数据集给出了相似证明:</p>
<ul>
<li>E[R|c − ] ≈ E[R] ≈ 1.8:这是当用户要求评价雅虎随机选择的歌曲时的平均评分。 （而不是由用户选择）</li>
<li>E [R | c +]≈2.9：这是当用户有意识地选择要评分的项目时的平均评分。 显然这个数值明显大于1.8，表明有很强的选择偏差。</li>
</ul>
<p>实际研究中,一个non-personlized推荐器可以获得RMSE=1左右,而最好推荐器结果是RMSE=0.86左右, 这表明，RMSE为0.14（评分为1至5）的改善可能看起来很小，但实际上非常大。</p>
<p>让我们假设我们在可用评级数据上训练推荐系统，用户可以自由选择要评分的项目。让它的RMSE（在测试集上）由RMSE0给出 ;其<strong>对整个系统的平均预测评分值</strong>将接近训练数据中的平均评分值E [R | c +],于是,这个推荐系统适用于variant2.</p>
<p>现在，让我们考虑集合中的任何项目,也就是（变体1）任务的评分预测：在这种情况下，真实平均评级是E[R];现在，先前训练过的推荐系统有一个偏差于是有<br><img src="/2018/01/22/Evaluation of RecommendationsRating-Prediction and Ranking/5F6B98DE-EAFE-4777-9DC1-E22D60B0D76B.png" alt=""><br>那么就有<br><img src="/2018/01/22/Evaluation of RecommendationsRating-Prediction and Ranking/F6008920-E23F-4BDB-9204-A58135C9962F.png" alt=""><br>这表明,很可能对variant 1的任务而言,这个性能比non-personlized的推荐器更差,所以有结论2:</p>
<blockquote>
<p>对于评级预测变体2，具有低RMSE的推荐系统<strong>不能保证</strong>实现关于评级预测任务1或3的低RMSE。<br>于是,为variant1设计模型又是个研究方向了.</p>
</blockquote>
<h2 id="Ranking"><a href="#Ranking" class="headerlink" title="Ranking"></a>Ranking</h2><hr>
<p>我们将ranking分为两部分:::ranking protocols and ranking metrics::,并在下面比较两者.</p>
<h3 id="Ranking-Protocols"><a href="#Ranking-Protocols" class="headerlink" title="Ranking Protocols"></a>Ranking Protocols</h3><p>我们可以区分出两种variant</p>
<ol>
<li>所有项目都可被推荐</li>
<li>过去user没有rating过的项目才能被推荐<br>于是有下面几种protocols</li>
</ol>
<ul>
<li>all items:所有物品,包括trainning/test set.</li>
<li>rated test-items:for each user, only those items are considered that <strong>have been rated</strong> by the user in the <strong>test set</strong>.</li>
<li><strong>all</strong> unrated items:for each user, only those items are considered that <strong>have not yet been rated</strong> by the user.</li>
</ul>
<h3 id="Ranking-Metrics"><a href="#Ranking-Metrics" class="headerlink" title="Ranking Metrics"></a>Ranking Metrics</h3><p>数据中有显示隐式反馈,我们需要确定,物品和用户是否relevant,对于隐式反馈很好做,对于显示反馈,我们实验里把5 star的当做relevant,其余不相关.</p>
<ol>
<li>precision:(确实项目会导致这个值一般比较低),其绝对值意义不大,但是可以用于比较模型好坏.</li>
<li>MAP: presision只考虑数量,而MAP还会考虑位置.<br><img src="/2018/01/22/Evaluation of RecommendationsRating-Prediction and Ranking/D3A53E47-6D3F-4EEF-8328-3FB18257E45D.png" alt="">,Rank is the ith element of the sorted ranks of the relevant items in the top N</li>
<li>Recall</li>
<li>Area under the Recall curve(ATOP):<br><img src="/2018/01/22/Evaluation of RecommendationsRating-Prediction and Ranking/5E1533EF-36DA-47E3-9EBD-60B114327AA1.png" alt=""><br>如果m+(relevant items)&lt;&lt;m,那么也可以估计AUC</li>
<li>nDCG</li>
</ol>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><hr>
<p>对observed rated items的召回率最高的模型可能不是对all items召回最高的模型。<br>::这表明，在各种精度测试中测试模型是不够的。 相反,更重要的我们对所有项目进行测试，还是仅对observered rated item进行测试，也就是说Ranking Protocols似乎至关重要::。(也就是指示我们训练比较ranking模型的时候要从all items上去下手比较)<br><img src="/2018/01/22/Evaluation of RecommendationsRating-Prediction and Ranking/082FC39E-9F60-4228-8F70-1DEEAB8C67C2.png" alt=""><br>对于ranking,表b表示只用已有的数据(relevant/unrelavent)来测试并度量recall这些指标时的结果,表a表示使用了所有数据(哪怕是缺失数据),可见,对于ranking,我们一般都是采用表a的度量方法,所以其对整个系统的泛化能力描述的更好.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/22/Performance of Recommender Algorithms on Top-N Recommendation Tasks(2010)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="PW">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PW's notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/22/Performance of Recommender Algorithms on Top-N Recommendation Tasks(2010)/" itemprop="url">未命名</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-22T21:04:20+08:00">
                2018-01-22
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Performance-of-Recommender-Algorithms-on-Top-N-Recommendation-Tasks-2010"><a href="#Performance-of-Recommender-Algorithms-on-Top-N-Recommendation-Tasks-2010" class="headerlink" title="Performance of Recommender Algorithms on Top-N Recommendation Tasks(2010)"></a>Performance of Recommender Algorithms on Top-N Recommendation Tasks(2010)</h1><p>#推荐引擎/论文</p>
<p>该论文提出了NNCosNgbr和PureSVD(better),而且在rating(非01)数据集上,pureSVD做topn任务被证明比其他MF方法都更好.</p>
<h2 id="评估方法-in-lt-lt-推荐系统实践-gt-gt"><a href="#评估方法-in-lt-lt-推荐系统实践-gt-gt" class="headerlink" title="评估方法 in &lt;&lt;推荐系统实践&gt;&gt;"></a>评估方法 in &lt;&lt;推荐系统实践&gt;&gt;</h2><hr>
<p>最重要的指标一定是::accuracy::,没有之一,但是对于做生意而言,如果一个人本来就打算买A,你给他推荐,那并没有增加效益,所以,<strong>新颖和惊喜</strong>也很重要.下面分别说明各个指标.</p>
<h4 id="准确度"><a href="#准确度" class="headerlink" title="准确度"></a>准确度</h4><p>对于不同的任务,准确度的计算不一样.对于::评分预测::任务,准确度一般通过RMSE或者MAE(平均绝对误差)计算.<br><img src="/2018/01/22/Performance of Recommender Algorithms on Top-N Recommendation Tasks(2010)/Performance%20of%20Recommender%20Algorithms%20on%20Top-N%20Recommendation%20Tasks(2010" alt="">/63F8F5B8-84CC-4297-AA74-2A20DCB6541C.png)<br><img src="/2018/01/22/Performance of Recommender Algorithms on Top-N Recommendation Tasks(2010)/Performance%20of%20Recommender%20Algorithms%20on%20Top-N%20Recommendation%20Tasks(2010" alt="">/11850AFC-8AAB-49BC-AF25-32918E0E0162.png)<br>对于::topn::推荐(因为有些物品,即使你会评高分,但是你看它的可能性也很小,所以topn其实更符合系统需求)来说,准确度一般通过precision/recall度量,令R是训练集上的推荐列表,而T是测试集上的推荐列表,那么有<br><img src="/2018/01/22/Performance of Recommender Algorithms on Top-N Recommendation Tasks(2010)/Performance%20of%20Recommender%20Algorithms%20on%20Top-N%20Recommendation%20Tasks(2010" alt="">/9CA482D8-7648-4E55-AAFD-8E6C0B3483B6.png)<br><img src="/2018/01/22/Performance of Recommender Algorithms on Top-N Recommendation Tasks(2010)/Performance%20of%20Recommender%20Algorithms%20on%20Top-N%20Recommendation%20Tasks(2010" alt="">/D00D4F0D-E6AD-484D-8CCD-8F4221766F44.png)<br>一般会取不同的推荐列表长度,绘制::precision/recall::曲线.</p>
<p>另外有</p>
<ul>
<li>覆盖率:说明系统中的东西是不是都给出了推荐,另外,要细致分析长尾发掘能力,我们希望所有的物品出现在推荐中的次数差不多(不偏向热门).可以使用geni系数:<br><img src="/2018/01/22/Performance of Recommender Algorithms on Top-N Recommendation Tasks(2010)/Performance%20of%20Recommender%20Algorithms%20on%20Top-N%20Recommendation%20Tasks(2010" alt="">/7966A492-3A7F-4D43-9A19-34E8000775BE.png),ij是按流行度p()排序的第j个物品.</li>
<li>多样性:描述了推荐物品的不相似性,于是可以使用下面公式表示,其中s(i,j)表示i,j相似度<br><img src="/2018/01/22/Performance of Recommender Algorithms on Top-N Recommendation Tasks(2010)/Performance%20of%20Recommender%20Algorithms%20on%20Top-N%20Recommendation%20Tasks(2010" alt="">/4CF32094-BAAD-4697-A955-9FAAF054904A.png)</li>
<li>新颖性:推荐用户没听说过的物品..(可能还是其兴趣范围)</li>
<li>惊喜性:推荐非用户兴趣但是用户用了又会说好的物品.</li>
</ul>
<p>一般来说,综合这么多指标之后,我们可以有一个::综合的优化目标:::<br><img src="/2018/01/22/Performance of Recommender Algorithms on Top-N Recommendation Tasks(2010)/Performance%20of%20Recommender%20Algorithms%20on%20Top-N%20Recommendation%20Tasks(2010" alt="">/0A38BFCC-2F6D-4828-8EBC-CC3734704034.png)</p>
<h2 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><hr>
<p>有这样一种推荐系统,并不显示predicted value,而是只展示觉得你最感兴趣的那些物品,这种叫top-n推荐任务.其目标是::寻找最吸引用户的一些东西::.采用RMSE并不合适评估top-n task的性能,而precision/recall反而更合适. 实验表明,::照RMSE优化的模型,并不见得在topn任务中表现的好::,RMSE的提示并不见得就带来accuracy的提升.在评估前N推荐任务的推荐算法时，应仔细选择测试集，以避免将准确性度量偏向非个性化解决方案(因为一些热门物品会skew topn task的性能).</p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><hr>
<p>推荐系统的一个常见做法是通过诸如RMSE（均方根误差）之类的误差度量来评估其性能，该误差度量捕获实际评级与系统预测的评级之间的平均误差。 然而，在许多商业系统中，::只显示了“最佳赌注”的建议::在执行前N个推荐任务时，::不需要精确的评分计算::.对于RMSE误差表示,在topn问题中顶多serve as proxies of the true top-n experience.</p>
<p>在这篇文章中,我们通过::准确性度量::来评估几种协同过滤算法在topN推荐任务时的性能。评估与RMSE度量在相同方法上的性能对比。贡献有三个方面：</p>
<ol>
<li>我们表明误差度量和准确性度量之间没有平凡的关系; </li>
<li>我们建议仔细构建了测试集,以在准确性度量上降低bias; </li>
<li>我们引入现有算法的新变体，以及其他使用的benifit，从而提高top-N性能。</li>
</ol>
<h2 id="TESTING-METHODOLOGY"><a href="#TESTING-METHODOLOGY" class="headerlink" title="TESTING METHODOLOGY"></a>TESTING METHODOLOGY</h2><hr>
<p>对于每个数据集，已知评分被分成两个子集：训练集M和测试集T.::测试集T仅包含五星评分::。所以我们可以合理地说::T包含了与各个用户相关的项目::。对netflix和ml数据集都这样选取就是.</p>
<blockquote>
<p>模型评估与选择中用于评估测试的数据集常称为”验证集” (validation set).  </p>
</blockquote>
<p>为了测量recall和precision，我们首先使用M训练模型。然后，对于用户在T中的每个项目i(我们认为系统应该推荐出去的)：</p>
<ol>
<li>我们随机选择1000个用户未评分的项目。 我们假设他们中的大多数不会让用户感兴趣。</li>
<li>我们预测测试项目i和另外1000个物品的评分。</li>
<li>我们根据预测的评分,排列所有1001个物品，形成一个排名表。 设p表示该列表中测试项目i的排名。 最好的结果对应于测试项目i是p=1的情况。</li>
<li>我们从列表中选出N个排名最高的项目，形成前N个推荐清单。 如果p≤N，我们有一个hit（即向用户推荐测试项目i).否则，我们有一个miss。 </li>
</ol>
<p>召回和准确度可以这么计算:<br><img src="/2018/01/22/Performance of Recommender Algorithms on Top-N Recommendation Tasks(2010)/Performance%20of%20Recommender%20Algorithms%20on%20Top-N%20Recommendation%20Tasks(2010" alt="">/1080B1E5-EAD1-4194-BFA5-22646089C9EE.png)<br>where | T | 是测试集打下西。 请注意，因为1000个随机项与用户u无关的,所以这样是倾向于低估的召回率和准确度的真实值(因为实际中应该会一些有关,所以N中hit可能不止是1)。</p>
<p>另外,在这项研究中，我们旨在::评估推荐算法在建议非流行项目中的准确性::。为此，将测试集T进一步划分为两个子集T(head)和T(long)，分别表示处于短头和处于长尾的物品.</p>
<h2 id="NEIGHBORHOOD-ALGORITHMS"><a href="#NEIGHBORHOOD-ALGORITHMS" class="headerlink" title="NEIGHBORHOOD ALGORITHMS"></a>NEIGHBORHOOD ALGORITHMS</h2><hr>
<p>非个性化推荐向任何用户呈现预定义的固定项目列表。::用作更复杂的个性化算法的基线。::<br>一个简单的办法是,推荐平均得分最高的前N项。无论u给出的评分如何，用户u对项目i的评分是为项目i的平均评分。另一种是推荐最热门(行为次数最多)</p>
<p>ICF比UCF一般在RMSE上表现的更好,并且由于一般|U|&lt;&lt;|I|,其更好计算,并且由于会得出II相似度,对新数据(用户操作了另一个物品i0)的实时推荐也更好(推荐i0相似的物品).</p>
<p>II相似度通常是在一个非常稀疏的数据集上，可能有一些项目对的支持不佳，导致不可靠的相似性度量。出于这样的原因，如果nij表示::共同评价者::的数量，并且sij表示项目i与项目j之间的相似度，则可以定义收缩相似度dij<br><img src="/2018/01/22/Performance of Recommender Algorithms on Top-N Recommendation Tasks(2010)/Performance%20of%20Recommender%20Algorithms%20on%20Top-N%20Recommendation%20Tasks(2010" alt="">/08A0F7D9-2E60-4086-9DAB-E502D4F6E7AC.png)<br>λ1常取100,这样做可以使得common rater更多的sim值相对更大.</p>
<p>进而,引入bias,也就是bui,<br><img src="/2018/01/22/Performance of Recommender Algorithms on Top-N Recommendation Tasks(2010)/Performance%20of%20Recommender%20Algorithms%20on%20Top-N%20Recommendation%20Tasks(2010" alt="">/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-11-21%2017.18.27.png)<br>再引入KNN(计算rating的时候只考虑与i最靠近的k个物品,记作D,::消除噪声::),可以得到下面方法<br><img src="/2018/01/22/Performance of Recommender Algorithms on Top-N Recommendation Tasks(2010)/Performance%20of%20Recommender%20Algorithms%20on%20Top-N%20Recommendation%20Tasks(2010" alt="">/21850181-1CDA-43F7-8A91-175ACE88855D.png)<br>这称为::CorNgbr.::,其中sij以pearson相关系数计算.</p>
<p>注意到,上式子的分母让评分落到了一个区间里面,但是对top-n任务,这并没啥必要,我们可以消除分母,我们建议以下面方法计算预测值并排序<br><img src="/2018/01/22/Performance of Recommender Algorithms on Top-N Recommendation Tasks(2010)/Performance%20of%20Recommender%20Algorithms%20on%20Top-N%20Recommendation%20Tasks(2010" alt="">/2D8A1B40-417B-42C8-AD45-B98A0DE0D867.png)<br>其中sij::取得最好accuracy的是使用cosine相似度::(Unlike Pearson correlation which is computed only on ratings shared by common raters, the cosine coeﬃcient between items i and j is computed over all ratings (taking missing values as zeroes)<br>这称作::NNCosNgbr::</p>
<h2 id="LFM"><a href="#LFM" class="headerlink" title="LFM"></a>LFM</h2><hr>
<p>公式是:<br><img src="/2018/01/22/Performance of Recommender Algorithms on Top-N Recommendation Tasks(2010)/Performance%20of%20Recommender%20Algorithms%20on%20Top-N%20Recommendation%20Tasks(2010" alt="">/E337066D-B38E-4C78-9DFD-0A876A3DF04D.png)<br>对于missing value, 最近的研究通过适当的目标函数直接在已知评级上学习因子向量，并优化预测误差使其最小化。 所提出的目标函数通常是正则化的，以避免过度拟合,并应用梯度下降来使目标函数最小化。</p>
<p>对topn任务,现在引入一种PureSVD,这更像SVD的形式,缺失值就当做0,我们使用真正的SVD分解方法拟合R<br><img src="/2018/01/22/Performance of Recommender Algorithms on Top-N Recommendation Tasks(2010)/Performance%20of%20Recommender%20Algorithms%20on%20Top-N%20Recommendation%20Tasks(2010" alt="">/84DB24AD-24E1-491B-A3D5-7843CB5BDCF7.png)<br>U是n<em>f正交矩阵,q是m</em>f正交矩阵,而∑是一个f*f的对角阵(元素是f个singular value)</p>
<p>让我们定义<img src="/2018/01/22/Performance of Recommender Algorithms on Top-N Recommendation Tasks(2010)/Performance%20of%20Recommender%20Algorithms%20on%20Top-N%20Recommendation%20Tasks(2010" alt="">/15FD1ED4-5573-4334-888A-C333AAC8651A.png),那么P的第u行就代表user factor pu, Q第i列就是item factor qi.<br>并且,根据矩阵运算关系,我们可以知道<br><img src="/2018/01/22/Performance of Recommender Algorithms on Top-N Recommendation Tasks(2010)/Performance%20of%20Recommender%20Algorithms%20on%20Top-N%20Recommendation%20Tasks(2010" alt="">/8FB19931-A5D0-4736-8DB6-CB19986BDDFE.png),R是评分矩阵,这样就把<strong>用户特征作为了项目特征的组合</strong><br>所以我们可以把预测分公式写成:<br><img src="/2018/01/22/Performance of Recommender Algorithms on Top-N Recommendation Tasks(2010)/Performance%20of%20Recommender%20Algorithms%20on%20Top-N%20Recommendation%20Tasks(2010" alt="">/EC769823-A528-408C-A926-720ECE050F38.png)……………(1)<br>这就是PureSVD.</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>按上面提到的试验方法做实验,设置不同的N(召回数)值, 比较6种算法(4种面向RMSE,2种新的),并且分别测试全测试集和长尾测试集,结果如下<br><img src="/2018/01/22/Performance of Recommender Algorithms on Top-N Recommendation Tasks(2010)/Performance%20of%20Recommender%20Algorithms%20on%20Top-N%20Recommendation%20Tasks(2010" alt="">/6F806520-DAE3-41BE-BFAB-D4981D4F52FD.png)<br>也就是说,PureSVD效果最好,不论是在哪种数据集上.不过,在NetFlix数据上的测试结果是::CorNgbr方法在发掘长尾的能力上表现很不错::</p>
<p>在Movielens和Netflix数据集上，无论是否包含短头，PureSVD一直是表现最出色的，打败了更为详细和复杂的潜在因子模型。鉴于其简单性和RMSE优化方面的糟糕设计，我们并没有期待这一结果。事实上，我们认为这对于推荐系统的从业者来说是一个好消息，因为PureSVD结合了多种优势。首先，编码非常容易，::不需要调整学习常数，完全依赖现有的优化SVD包::。这在计算和在线模式下都具有良好的计算性能。</p>
<p>当从业者使用PureSVD时，他们应该选择其维度，::同时考虑到latent factor影响长尾项目质量的数量远远高于短头。::</p>
<h2 id="LAST"><a href="#LAST" class="headerlink" title="LAST"></a>LAST</h2><hr>
<p>最后给出top-n问题的10种评估方法</p>
<ol>
<li>AUC(ROC下的面积)</li>
<li>AveragePrecision</li>
<li>AverageReciprocalHitRank</li>
<li>Diversity</li>
<li>HitRate </li>
<li>IdealDCG</li>
<li>Normalized</li>
<li>Precision</li>
<li>Recall</li>
<li>REciprocalRank</li>
</ol>
<p>precision/recall曲线的判断:</p>
<ol>
<li>若一个学习器的 P-R 曲线被另一个学习器的曲线完全”包住”,则可断言后者的性能优于前者.</li>
<li>如果两个学习器 的 P-R 曲线发生了交叉只能在具体的查准率或查全率条件下进行比较.</li>
<li>硬要比,也有F1度量,参照&lt;&lt;机器学习&gt;&gt;</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/22/Factored item similarity models for top-n recommender systems(FISM)2013/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="PW">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PW's notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/22/Factored item similarity models for top-n recommender systems(FISM)2013/" itemprop="url">未命名</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-22T20:41:55+08:00">
                2018-01-22
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Factored-item-similarity-models-for-top-n-recommender-systems-FISM-2013"><a href="#Factored-item-similarity-models-for-top-n-recommender-systems-FISM-2013" class="headerlink" title="Factored item similarity models for top-n recommender systems(FISM)2013"></a>Factored item similarity models for top-n recommender systems(FISM)2013</h1><p>好像,是::针对0/1数据集::</p>
<p>学的是物品本身的隐向量</p>
<p>#推荐引擎/论文</p>
<h2 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><hr>
<p>现有的topN推荐方法的有效性::随着数据集稀疏度的增加而降低::。为了缓解这个问题，我们提出了一个item-based的方法来生成top n推荐，::将item similarity matrix表示为两个low demensional的latent factor矩阵的乘积::。 这些矩阵是使用结构化方程建模方法学习的，其中要被估计的值不用估计自己。 在三个不同稀疏水平上的多个数据集上进行全面的实验表明，所提出的方法可以::有效地处理稀疏数据集::，并且胜过其他最先进的前N种推荐方法。与竞争方法相比，::相对性能随着数据稀疏而增加::。</p>
<h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><hr>
<p>SLIM也是有固有局限性的:其只能对有co-purchased/co-rated的item之前的关系进行建模,于是,他也就::不能捕捉物品之间的transitive relations(传递关系)::,而这对稀疏数据及上item-based方法的性能很重要.</p>
<p>本文中的FISM方法,::将item similarity matrix表示为两个low demensional的latent factor矩阵的乘积::,于是,这种factored表示使得FISM能捕捉并建模物品之间的关系,即使在很稀疏的数据集(lack of co-purchased record).主要贡献可以总结为:</p>
<ol>
<li>将factored item-based methods扩展到top-N问题以有效处理sparse数据集.</li>
<li>使用squared error以及ranking loss来估计模型</li>
<li>研究各种参数对偏差，邻域一致性和模型引入稀疏性的影响。</li>
</ol>
<h2 id="记号"><a href="#记号" class="headerlink" title="记号"></a>记号</h2><hr>
<ul>
<li>小写表示向量,并且表示<strong>行向量</strong>,比如p,q</li>
<li>矩阵使用大写,比如R,W,R代表<strong>隐式反馈</strong>的矩阵.</li>
<li>A矩阵的第i行是ai</li>
<li>C,D表示集合,C是用户集,D是物品集合,用户n个,物品m个.</li>
<li>~表示predict value,^表示estimated value.</li>
</ul>
<h2 id="REVIEW-OF-RELEVANT-RESEARCH"><a href="#REVIEW-OF-RELEVANT-RESEARCH" class="headerlink" title="REVIEW OF RELEVANT RESEARCH"></a>REVIEW OF RELEVANT RESEARCH</h2><hr>
<p>这里介绍SLIM和NSVD,SLIM就不讲了.<br>NSVD是一个<strong>factored</strong>的ii协同过滤方法,用于rating prediction,方法中,ii相似度被两个low-rank矩阵P,Q表示,于是ii相似度就是对应向量的点积表示,于是u对i的评分被predicted和estimated为:<br><img src="/2018/01/22/Factored item similarity models for top-n recommender systems(FISM)2013/Factored%20item%20similarity%20models%20for%20top-n%20recommender%20systems(FISM" alt="">2013/5E8C93A0-A02D-4CF6-A849-F43E22C2DCF3.png)……..(1)<br>R+ is the set of items rated by u,于是,参数就使用如下的最优化问题来解:<br><img src="/2018/01/22/Factored item similarity models for top-n recommender systems(FISM)2013/Factored%20item%20similarity%20models%20for%20top-n%20recommender%20systems(FISM" alt="">2013/D82EB0C7-162E-4704-AC96-69FA7A10297C.png)…….(2)<br>把(1)式代入(2)式,用最优化方法解就是了,拟合的也是评分矩阵R,并采用l1正则项.当然,这些模型的目标是最小化RMSE,于是适用于rating prediction.</p>
<h2 id="MOTIVATION"><a href="#MOTIVATION" class="headerlink" title="MOTIVATION"></a>MOTIVATION</h2><hr>
<p>SLIM这样的方法依赖于学习项目之间的相似性,不能捕捉没有被共同作用的物品之间的依赖关系.但实际上,两个物品之间的相似性也许可以因为他们有共同的相似物品而得到描述(::传递关系::).</p>
<p>比较FISM和NSVD，这两种方法的区别除了是用来解决不同的问题（top-N vs rating rating）之外，它们的关键在于如何估计分解矩阵。FISM采用::基于结构方程模型的回归方法::.而对于NSVD(SVD++)而言,FISM对已知的rui在when rating for that item is being estimated的时候是不用的.</p>
<p>FISM,u对i的recommendation score是:(::这叫predicted value::)<br><img src="/2018/01/22/Factored item similarity models for top-n recommender systems(FISM)2013/Factored%20item%20similarity%20models%20for%20top-n%20recommender%20systems(FISM" alt="">2013/D5C862F6-DD58-4765-A143-9C4ED767864D.png)…………(3)<br>也就是i的隐向量*所有用户打分项目j的隐向量(以表示ij相似度).而nu+表示u打过分物品的数目,a是一个(0,1)的数.可见,nu+越大,<img src="/2018/01/22/Factored item similarity models for top-n recommender systems(FISM)2013/Factored%20item%20similarity%20models%20for%20top-n%20recommender%20systems(FISM" alt="">2013/E055FB42-C235-4B1B-B322-82ECACB940CC.png)越小,举个例子,如果i=1,那么后面这项就是j们与i的平均相似度(除非大约所有j都和i相似度不错,i就能有高得分),如果i=0,那么就是∑相似度(可能只要某一个j和i相似度很高,i就能有高得分.),正确的选择应该是在这之间,也就是有一些j们和i相似.α取值要看数据集,一般就看经验咯.</p>
<p>这和NSVD类似,还是个item模型来预测打分,而学习方法上,设计了损失函数为RMSE的和AUC的两种方法,RMSE的就不说了,说说AUC的.</p>
<p>训练过程中的::estimate(使用训练数据)::的时候,使用下面公式:<br><img src="/2018/01/22/Factored item similarity models for top-n recommender systems(FISM)2013/Factored%20item%20similarity%20models%20for%20top-n%20recommender%20systems(FISM" alt="">2013/6AC31F58-0BE9-4105-B649-65F780D72E03.png)……..(4)<br>可见和predict公式相比,R+中去除了可能的i本身..(这也是和NSVD,SVD++等的重要区别)</p>
<p>作为第二个损失函数，我们考虑一个基于ranking error的损失函数。 这是由于top n推荐问题涉及按照正确顺序对项目进行排序的事实，这不同于评级预测问题(最小化RMSE是目标)。<br>我们使用了BPR一样的loss function,来优化area under the curve(AUC),用户打过分的记作R+,没有的记作R-,那么ranking loss就是:<br><img src="/2018/01/22/Factored item similarity models for top-n recommender systems(FISM)2013/Factored%20item%20similarity%20models%20for%20top-n%20recommender%20systems(FISM" alt="">2013/D7F33E43-A035-43FB-B83D-74D3BBAD4C0E.png)………(5)<br>其中^的estimate使用(4).这个公式还是容易明白,就是<strong>评分(non-zero)和未评分物品(0)的差</strong>和预测出来值的差异性(relative diﬀerence).因此，这个损失函数不关注估计正确的值，而是关于零和非零值的排序。<br>于是加上正则项后,整体的优化函数是:<br><img src="/2018/01/22/Factored item similarity models for top-n recommender systems(FISM)2013/Factored%20item%20similarity%20models%20for%20top-n%20recommender%20systems(FISM" alt="">2013/DA356978-4947-4513-A45F-3EE676B3D264.png)<br>并且,为了减少计算复杂度,会::对负样本采样::.这个问题也可以使用SGD来求解,下面的框图说明了步骤.<br><img src="/2018/01/22/Factored item similarity models for top-n recommender systems(FISM)2013/Factored%20item%20similarity%20models%20for%20top-n%20recommender%20systems(FISM" alt="">2013/2433EA15-0C87-4D5E-8C62-F190DE822C72.png)</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><hr>
<p>数据集是ML,Netflix和Yahho,全部转化为1,0数据(有评分就是1),并抽样取三种稀疏度情况<br><img src="/2018/01/22/Factored item similarity models for top-n recommender systems(FISM)2013/Factored%20item%20similarity%20models%20for%20top-n%20recommender%20systems(FISM" alt="">2013/2364E228-8B32-4F24-BFBA-E60837315125.png)<br>实验方法也是取估计Hit Rate和ARHR,和SLIM是一样的.用于比较的方法如下</p>
<ul>
<li>ItemKNN(cos,cprob,log)</li>
<li>PureSVD</li>
<li>BPRkNN</li>
<li>BPRMF</li>
<li>SLIM<br>并且也计算了在estimate中加入物品i本身做计算的情况以比较.结论有</li>
</ul>
<ol>
<li>Bias是很起作用的,其中item-bias起的作用挺大.</li>
<li>neighborhood agreement,也就是使用不同给的α,表明α在0.4~0.5比较合适,并且对不同的α,AUC方法比RMSE方法更加稳定(因为都是对同一个user,user bias对于排序来说作用不算那么大)</li>
<li>对于esimate中是否使用自己,结果是当latent space k越大,不使用自己的方法性能变得更好.</li>
<li>FISM对相似性没有非负约束(SLIM有),如果加上约束,反而性能下滑</li>
<li>总的实验效果,::RMSE方法取得了稍好的成绩,AUC方法紧随其后(这让人惊讶,正在调查)::<br><img src="/2018/01/22/Factored item similarity models for top-n recommender systems(FISM)2013/Factored%20item%20similarity%20models%20for%20top-n%20recommender%20systems(FISM" alt="">2013/A6999CA0-8145-485C-9369-9818B0A48DAB.png)</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/22/Slim Sparse linear methods for top-n recommender systems2011/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="PW">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PW's notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/22/Slim Sparse linear methods for top-n recommender systems2011/" itemprop="url">未命名</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-22T19:35:22+08:00">
                2018-01-22
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Slim-Sparse-linear-methods-for-top-n-recommender-systems2011"><a href="#Slim-Sparse-linear-methods-for-top-n-recommender-systems2011" class="headerlink" title="Slim: Sparse linear methods for top-n recommender systems2011"></a>Slim: Sparse linear methods for top-n recommender systems2011</h1><p>数据集上测试了0/1数据集和rating数据集<br>学的是物品间作用关系的向量</p>
<p>#推荐引擎/论文</p>
<h2 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><hr>
<p>提出一种新的SLIM方法,该方法通过aggeregate用户购买/评分档案来生成top n推荐.通过解决一个1范式和2范式正则化的优化问题来生辰过了一个::稀疏的聚合coefficient矩阵W(不需要对称)::.其稀疏性使得W产生推荐::又快又好::.</p>
<h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><hr>
<p>这里目标是:为用户推荐一个排序好的列表,以鼓励<strong>additional purchases</strong>.这就造就了top-n推荐系统的广泛运用.基于邻居的和基于模型的算法运用的最广泛,基于邻居的做推荐很快,但是牺牲了一些推荐质量,而基于模型的相反.</p>
<p>SLIM学习一个稀疏的稀疏矩阵,Feature selection methods使得SLIM能显著减少学习稀疏矩阵所需的时间.此外,SLIM::可以从rating数据中学些top-n推荐::.</p>
<h2 id="RELATED-WORK"><a href="#RELATED-WORK" class="headerlink" title="RELATED WORK"></a>RELATED WORK</h2><hr>
<p>基于邻居的方法能快速生成推荐的一个原因就是item neighborhood is sparse(不需要考虑到所有item).由于其并不了解item本身的某些特性,导致精度有时低.</p>
<p>Top N推荐也被视为ranking问题。 Rendle等人提出了一个贝叶斯个性化排序（BPR）标准，它是贝叶斯分析的最大后验估计量，用来衡量用户购买物品和其他物品的排名之间的差异。 BPR可以很好地用于项目knn方法（BPRkNN）和矩阵分解方法（BPRMF）,作为一般目标函数。</p>
<h2 id="定义和符号"><a href="#定义和符号" class="headerlink" title="定义和符号"></a>定义和符号</h2><hr>
<p>u代表用户,t代表物品.U和T代表全集,用户共m个,物品n个.m*n的行为矩阵记为A,元素为1或者某个正值,表示用户购买/评分了物品,否则值是0. aiT表示用户哪一行,aj表示武平那一列.</p>
<h2 id="SPARSE-LINEAR-METHODS-FOR-Top-N-RECOMMENDATION"><a href="#SPARSE-LINEAR-METHODS-FOR-Top-N-RECOMMENDATION" class="headerlink" title="SPARSE LINEAR METHODS FOR Top-N RECOMMENDATION"></a>SPARSE LINEAR METHODS FOR Top-N RECOMMENDATION</h2><hr>
<p>在SLIM方法中,用户ui对物品tj(未购买/评分)的计算方法是,对用户已经购买/评分过的物品的一个sparse aggregation:<br><img src="/2018/01/22/Slim Sparse linear methods for top-n recommender systems2011/328D1526-9591-4A78-99C2-EA7A0141637E.png" alt="">………(1)<br>也就是用户i的行为向量与物品j在W中的列向量的<strong>点积</strong>,这相当于去补全A矩阵.<br>aij是=0的(没购买过),wj的含义是稀疏矩阵中各个物品对j的作用构成的列向量.所以,整个模型可以表示为:<br><img src="/2018/01/22/Slim Sparse linear methods for top-n recommender systems2011/0CE10767-BFAF-4D23-9BFD-BF558A935C80.png" alt="">………(2)<br>其中A~的每一行<img src="/2018/01/22/Slim Sparse linear methods for top-n recommender systems2011/06457A82-F833-419E-B214-8E5143F40757.png" alt="">就代表了u对所有物品的recommendation score.做推荐就是基于recommendation score,对没购买过的物品排序,得出N个就是.</p>
<p>现在要看看如何学习W.我们知道(2)式,所以我们解下面的优化目标<br><img src="/2018/01/22/Slim Sparse linear methods for top-n recommender systems2011/C67D633D-8EE2-44C5-A447-929FD3434553.png" alt=""><br>对上面正则项的解释是:<br><img src="/2018/01/22/Slim Sparse linear methods for top-n recommender systems2011/6976354E-87BF-4DE8-A067-5C8F2CF0EB06.png" alt=""><br>(3)的第一项::说明了sparse linear model对训练数据fit得多好.::而约束表示W表示的是positive relations between items,并且自己和自己的作用是0, 这确保aij不被用来计算˜aij.</p>
<p>我们使用l1正则项来使得学到的矩阵尽量稀疏(推荐的时候会更快).另外,矩阵的l2正则项(lF)描述了魔心更复杂度,避免过拟合.由于W中的列向量们是::独立::的,所以优化问题可以解耦成一组优化问题:<br><img src="/2018/01/22/Slim Sparse linear methods for top-n recommender systems2011/FF40C549-30FE-4B07-BCA0-AA00C4BD8DC0.png" alt="">……(4)<br>这使得W的每一列可以分别(::并行::)计算.这个优化可以使用::坐标下降法::或者soft thresholding法解决.</p>
<p>方程4中wj的估计可以看作是正则化回归问题的解，其中A的第j列是作为A的剩余n-1列（自变量x）的函数估计的因变量y。 这个观点表明::特征选择方法::可以地被用于在计算wj之前,以减少自变量的数量,加速SLIM训练.我们的特征选择方法是,由于目标是学习线性模型来估计A的第j列（即aj），因此::与aj最相似的A中的列::可以用作选择的特征。</p>
<p>复杂度上,为ui做推荐的复杂度是<br><img src="/2018/01/22/Slim Sparse linear methods for top-n recommender systems2011/EE6328B9-B8CA-43C4-8414-412615501A6D.png" alt=""><br>nai是A中用户行不为0元素个数(用户作用过的元素个数),nw是W中每列的平均不为0元素个数,Nlog(N)是为了排序取Top-n</p>
<p>下面看看SLIM和MF的联系.可以把SLIM看做MF的特殊情况(A就是U,而W是V)<br><img src="/2018/01/22/Slim Sparse linear methods for top-n recommender systems2011/0EB70C70-D398-404A-9A25-2FE7B1534E77.png" alt="">……(5),MF的形式<br>对应MF,U和V都是in latent space,而在SLIM中,latent space就是item space.这样,SLIM不需要学习user表示,学习过程简化了,由于U,V一般维度不高,所以可能<strong>丢失某些有用的信息.</strong>对SLIM,由于用户信息在A中完全保留,SLIM应该是可以给出更好的推荐.并且U,V在MF中是密集的,推荐的时候计算起来相对慢一些.</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><hr>
<p>总共8个数据集,第一类包含购买记录,第二类包含ratings数据.::我们应用了5次Leave-One-Out交叉验证来评估SLIM方法的性能。::,其中测试集中每个用户都会有一个relevant项目以计算hit与否,使用Hit Rate和Average Reciprocal Hit-Rank,我们对其的定义是<br><img src="/2018/01/22/Slim Sparse linear methods for top-n recommender systems2011/D2CF2E33-98EA-4A2F-ABE2-9575D6FE6123.png" alt=""><br><img src="/2018/01/22/Slim Sparse linear methods for top-n recommender systems2011/7AFB5611-A74F-48AB-87BD-C7427AF9A126.png" alt=""><br>::users:: is the total number of users, and  ::hits:: is the number of users whose item in the testing set is recommendedin the size-N recommendation list.而ARHR考虑到了推荐位置,其中pi是被hit物品推荐的位置(可见,若所有hit都在1位置,那么ARHR值==HR值).</p>
<p>实验结果也得分对01数据集和rating数据集..从实验结果上来,总结为</p>
<ol>
<li>效果上一般比其他方法都要好</li>
<li>速度上比一般MF方法要好,比KNN稍逊,但是这取决于数据集,通过特征选择方法可以提升.</li>
</ol>
<p>SLIM对长尾分布效果如何?把实验集中去除短头再测,它说的结果也是得到的HR比其他算法要好.然后,对于N取值,当推荐较小数量的项目时，SLIM比其他方法产生更好。这表明SLIM倾向于将最相关的项目排在高于其他方法的位置。</p>
<p><img src="/2018/01/22/Slim Sparse linear methods for top-n recommender systems2011/CA7F14EB-E4B1-49E9-A5B2-44FB35DCC27A.png" alt=""><br><img src="/2018/01/22/Slim Sparse linear methods for top-n recommender systems2011/E26F52FF-F6E0-4F5D-A770-6AF17341777D.png" alt=""><br>-b代表使用的是binary data,-r代表使用的是ratings data.</p>
<h2 id="坐标下降法"><a href="#坐标下降法" class="headerlink" title="坐标下降法"></a>坐标下降法</h2><hr>
<p><img src="/2018/01/22/Slim Sparse linear methods for top-n recommender systems2011/26CE3DE4-F61C-4F7C-8EC9-5D57357FA2C8.png" alt=""><br><img src="/2018/01/22/Slim Sparse linear methods for top-n recommender systems2011/Coordinate_descent.jpg" alt=""><br>对于非平滑函数，坐标下降法可能会遇到问题。下图展示了当函数等高线非平滑时，算法可能在非驻点中断执行。(沿着两个方向走都走不到下一点,只能在原本这点困住)<br><img src="/2018/01/22/Slim Sparse linear methods for top-n recommender systems2011/Nonsmooth.jpg" alt=""></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/22/Local Item-Item Models for Top-N Recommendation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="PW">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PW's notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/22/Local Item-Item Models for Top-N Recommendation/" itemprop="url">未命名</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-22T16:26:51+08:00">
                2018-01-22
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Local-Item-Item-Models-for-Top-N-Recommendation"><a href="#Local-Item-Item-Models-for-Top-N-Recommendation" class="headerlink" title="Local Item-Item Models for Top-N Recommendation"></a>Local Item-Item Models for Top-N Recommendation</h1><ul>
<li style="list-style: none"><input type="checkbox"> 优化还是没理解透,需要再看看SLIM的论文</li>
</ul>
<p>#推荐引擎/论文</p>
<p>下一步根据librec的收录找论文看,<strong>这篇文章的引用也很不错,以了解topn问题和评分预测问题的区别</strong></p>
<blockquote>
<p>local item-item models isitemitem models capturing similarities in user subsets.  </p>
</blockquote>
<h2 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><hr>
<p>基于SLIM（Sparse Lenear Methods）的item-based方法对topN推荐表现出非常好的性能;但是其把所有用户归为一个单一的模型。而我们认为,并不是所有的用户都以相同的方式行事,而是存在志趣相投的用户的子集。通过对这些用户子集使用不同的item-item model，我们可以捕获他们偏好的差异，这可以提高topN推荐的性能。</p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><hr>
<p>从网上购物网站到视频门户，Top-N推荐系统[3]无处不在。 他们向用户提供他们可能感兴趣的N个项目的排名列表，以鼓励观看和购买。</p>
<p>时间已经证明,LFM方法解决评分预测问题是很好的,而普通CF对于解决topN问题表现得更好.而基于item的,比如KNN方法和SLIM,是比基于用户的topN推荐方法更有效的.</p>
<p>但是，基于项目的方法的缺点是仅为所有用户取做::单个模型::。 在许多情况下，用户行为存在差异，单一模式无法捕捉到。 例如，::对于特定用户子集可能有一对非常相似的项目::，(比如红花会和lamar对于hiphop用户群相似,但是对于中国音乐用户群却不想死.)而对于另一个用户子集则相似度较低。 通过使用全局模型，这些项目之间的相似性往往会趋于一些平均值; 从而::失去了其在第一个用户子集的高度相关性::。</p>
<p>在本文中，我们提出了一个扩展SLIM模型的前N推荐方法，以捕获不同用户子集之间偏好的差异。 我们称之为GLSLIM,其可以::自动识别用户子集::,这是通过求解一个联合优化问题来完成的.实现表明,比竞争方法性能提升了17%.</p>
<h2 id="NOTATION"><a href="#NOTATION" class="headerlink" title="NOTATION"></a>NOTATION</h2><hr>
<p>矩阵采用大写,向量采用小写,对于矩阵A,其第i行表示为<img src="/2018/01/22/Local Item-Item Models for Top-N Recommendation/12481F7D-68AD-49ED-B23C-4224986AA3BD.png" alt="">,第j列表示为<img src="/2018/01/22/Local Item-Item Models for Top-N Recommendation/91B7D729-E027-4381-958C-36AC42D6432B.png" alt="">.”~”表示预测值.<br>假设有n个用户,m个物品. R(n*m)代表了user-item implicit feedback matrix,表示item是否被用户purchased/viewed/rated.<br>u表示一个用户,i表示一个物品,如果用户u对物品i有隐式反馈,那么rui=1,否则=0.R的非0项我们使用”rating”来表示,进而有”rated items”和”unrated items”.使用<img src="/2018/01/22/Local Item-Item Models for Top-N Recommendation/B41074B0-D889-444D-9AF0-08688D8D1323.png" alt="">表示用户u的rated items集合.使用<img src="/2018/01/22/Local Item-Item Models for Top-N Recommendation/026F8E3C-65C2-458F-95AE-CE1634C34353.png" alt="">表示Hadamart product(对应位置元素相乘的矩阵乘法).</p>
<h2 id="RELATED-WORK"><a href="#RELATED-WORK" class="headerlink" title="RELATED WORK"></a>RELATED WORK</h2><hr>
<p>SLIM，这是第一个::使用统计学习::来计算item-item relationship的方法，并被证明是最好的方法之一.SLIM估计一个稀疏的m×m的::aggregation coeﬃcient matrix S::.对于u unrated的i的recommendation score被计算为::a sparse aggregation of all the user’s past rated items::</p>
<blockquote>
<p><img src="/2018/01/22/Local Item-Item Models for Top-N Recommendation/7E844368-63D3-4F86-8E75-25E357B2D25F.png" alt="">……(1)<br>也就是R属于用户u的那一行* coeﬃcient矩阵S的属于物品i的列. 而S是通过求解下面优化问题来估计:<br><img src="/2018/01/22/Local Item-Item Models for Top-N Recommendation/C8B8A50C-EA16-4D60-83FD-3E668D5B680C.png" alt="">………(2)  </p>
</blockquote>
<p>β和λ是正则化参数.在约束中,使用非负性约束使得估矢量估计中coeffect都是正数。 s ii = 0约束确保在计算项目的权重时，不会使用该项目本身.</p>
<p>有些工作中已经提出了估计多个::局部模型::的想法。其通过对item-wise的rating matrix进行聚类,并且对每个聚类使用KNN协同过滤来为每个聚类生成separate local model. 另外一个工作中,使用不同的CF方法对用户-物品进行co-cluster.一个ui pair的评分是从具有largest weight for the user的subgroup中选取的.</p>
<p>我们的GLSLIM有如下特点:</p>
<ol>
<li>在上述所有的工作中，只考虑局部模型; 而::GLSLIM也计算全局模型，并为每个用户确定全局和本地信息之间的相互作用的个性化因素。::</li>
<li>用户到subset的分配会更新,使得local model更好</li>
</ol>
<h2 id="PROPOSED-APPROACH"><a href="#PROPOSED-APPROACH" class="headerlink" title="PROPOSED APPROACH"></a>PROPOSED APPROACH</h2><hr>
<h3 id="MOTIVATION"><a href="#MOTIVATION" class="headerlink" title="MOTIVATION"></a>MOTIVATION</h3><p>全球物品项目模型可能不足以捕捉一组用户的偏好，特别是当存在具有多样化并且有时是相反偏好的用户子集时。最重要的这::捕捉了不同用户集的不同喜好::</p>
<p>需要明确,用户子集间要有common rated items, local模型才会有提升(不同用户子集中的ii相似度不同)(left),不然会和全局模型产生一样的结果(right),像下图的结构<br><img src="/2018/01/22/Local Item-Item Models for Top-N Recommendation/C1B383C6-47A8-4338-8FF8-AAA33737FFC4.png" alt=""><br>c和i的相似度在A中和在B中是不同的(在B中是0,因为B中用户对i就没有行为,于是i的行为向量就是0向量,内积计算出来是0).</p>
<h3 id="OVERVIEW"><a href="#OVERVIEW" class="headerlink" title="OVERVIEW"></a>OVERVIEW</h3><p>我们有特定user subset的model和一个全局model, ::These models are jointly optimized along with computing the user assignments for them.::我们使用SLIM来训练模型,于是,我们会估计一个全局的item-item coefficient矩阵S, k个local的item-item coefficient矩阵<img src="/2018/01/22/Local Item-Item Models for Top-N Recommendation/26839026-9D15-41A2-B8D4-0CD331C13DED.png" alt="">,k是subset(聚类)数,而<img src="/2018/01/22/Local Item-Item Models for Top-N Recommendation/B3EA7B8A-C403-4FE5-B25D-7CD41590E4D3.png" alt="">是subset索引.</p>
<p>对于属于pu子集的用户u,对i的rating是根据如下的prediction rule:</p>
<blockquote>
<p><img src="/2018/01/22/Local Item-Item Models for Top-N Recommendation/E11A1940-62A9-41E4-A268-737AAA07DEF3.png" alt=""><br>sli代表的是用户评分过的l物品和目标item i的全局相似度,而<img src="/2018/01/22/Local Item-Item Models for Top-N Recommendation/0F11C71D-5CC7-4AAF-B894-5A556E362E56.png" alt="">就是其局部相似度,而gu是personalized weight per user,控制全局和局部两部分的interplay,它位于区间[0，1]中，其中0表示推荐仅受局部模型影响，1表示用户只使用全局模型。(注意,和传统itemCF相比,没有乘以对u对l的rating,因为都是1).</p>
</blockquote>
<p>为了执行对用户u的前N个推荐，我们用等式3计算每个未分类项目i的估计额定值。然后，我们对这些值进行排序，并向用户推荐具有最高评价的前N个项目。</p>
<h3 id="Estimating-the-item-item-models"><a href="#Estimating-the-item-item-models" class="headerlink" title="Estimating the item-item models"></a>Estimating the item-item models</h3><p>我们首先使用某种聚类算法来把用户聚类(比如CLUTO),或者随机聚类,并且对所有用户设定gu=0.5,我们保持g和g’,是n维向量,分别表示所有用户的gu和(1-gu).</p>
<p>当把用户assign到k个subset的时候,我们把R矩阵split到k个training matrix <img src="/2018/01/22/Local Item-Item Models for Top-N Recommendation/4AAE219A-F57E-4403-BEE8-AC7BBA17623A.png" alt="">,并且每个矩阵还是保持n*m大小,取值的方式是,如果u属于pu子集,那么<img src="/2018/01/22/Local Item-Item Models for Top-N Recommendation/4AAE219A-F57E-4403-BEE8-AC7BBA17623A.png" alt="">的这一行就是R中这一行,否则是empty.当估计本地模型<img src="/2018/01/22/Local Item-Item Models for Top-N Recommendation/9434019D-B75B-4733-B869-E0F6A7FBA6CE.png" alt="">的时候,只有R中对应的行们<img src="/2018/01/22/Local Item-Item Models for Top-N Recommendation/998EFC32-D86E-4D81-8269-C6A956CE325B.png" alt="">会被使用.</p>
<p>和SLIM一样,coefficient矩阵可以按列计算,这允许不同列可以并行来估计,为了估计S的第i列以及<img src="/2018/01/22/Local Item-Item Models for Top-N Recommendation/32A1D797-BAF4-4F4E-A150-48F8318BA0DA.png" alt="">的第i列,我们解下面的目标函数</p>
<blockquote>
<p><img src="/2018/01/22/Local Item-Item Models for Top-N Recommendation/1A5A8E35-8494-4798-A308-25C7B3EAB0C1.png" alt=""><br>ri是R的第i列(也就是属于物品i的一列)而β和λ分别是l2正则项和l1正则项(控制S模型的稀疏度),g和l分别代表global model的和local model的. (约束的含义是coefficient&gt;=0,且和自己的coefficient==0(否则一个item会把自己推荐出去))</p>
</blockquote>
<p>通过为全局和局部稀疏系数矩阵::提供不同的正则化参数::，就可以控制这两个组成部分中的哪一个将在推荐中扮演更重要的角色。而上式的优化问题可以用::坐标下降法和软阈值法来求解::[9]。</p>
<h3 id="Finding-the-optimal-assignment-of-users-to-subsets"><a href="#Finding-the-optimal-assignment-of-users-to-subsets" class="headerlink" title="Finding the optimal assignment of users to subsets"></a>Finding the optimal assignment of users to subsets</h3><p>在估计了局部模型（和全局模型）之后，GLSLIM将它们<strong>固定</strong>并进行第二部分优化：::更新用户子集::。在这样做的同时，也将确定personalized权重。我们把这个过程称为”reﬁnement”</p>
<p>具体来说，GLSLIM会尝试将每个用户分配给每个可能的cluster,，同时计算用户分配给该集群的权重gu。 然后，对于每个聚类pu和用户u，分别计算训练误差。误差最小的cluster就是用户将分配到的cluster。 如果训练误差没有差异，或者没有训练误差较小的聚类，则用户u<strong>保持在初始聚类</strong>。The training error is computed for both the user’s rated and unrated items.</p>
<p>为了计算个性化的权重gu，我们对 属于子集pu的用户u按prediction rule对所有item计算预测评分并最小化square error,令square error的导数为0,我们可以知道<br><img src="/2018/01/22/Local Item-Item Models for Top-N Recommendation/9F92C1B1-8DA4-47E9-87E0-94A1ED50239B.png" alt=""></p>
<p>总的GLSLIM算法可以总结为:<br><img src="/2018/01/22/Local Item-Item Models for Top-N Recommendation/DC46DA16-2CD3-4CD2-9218-D56A9F783E47.png" alt=""></p>
<ol>
<li>1,2初始化.</li>
<li>3~12循环,(知道变换cluster的用户&lt;1%为止)<ol>
<li>按最优化问题求解S和Spu.</li>
<li>为所有用户所有集群<ol>
<li>计算gu for pu(每个用户在每个集群里都有一个gu)</li>
<li>计算trainning error</li>
<li>重新把用户分配到合适的集群pu,并且更新gu到用户所在cluster中的那个gu.</li>
</ol>
</li>
</ol>
</li>
</ol>
<p>在试验阶段,我们看到的结果是:PureSVD最次,BMR-MF和SLIM不相上下,GLSLIM最好.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">PW</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">69</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">PW</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
