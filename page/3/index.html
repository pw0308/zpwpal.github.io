<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta property="og:type" content="website">
<meta property="og:title" content="PW&#39;s notes">
<meta property="og:url" content="http://yoursite.com/page/3/index.html">
<meta property="og:site_name" content="PW&#39;s notes">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="PW&#39;s notes">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/3/"/>





  <title>PW's notes</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">PW's notes</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/22/上下文推荐系统/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="PW">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PW's notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/22/上下文推荐系统/" itemprop="url">未命名</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-22T14:18:12+08:00">
                2018-01-22
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="上下文推荐系统"><a href="#上下文推荐系统" class="headerlink" title="上下文推荐系统"></a>上下文推荐系统</h1><p>#推荐引擎/推荐系统实践</p>
<p>下面会给出几种基于时间上下文/地点上下文的推荐算法</p>
<h2 id="最近最热门"><a href="#最近最热门" class="headerlink" title="最近最热门"></a>最近最热门</h2><p>其实就是给最热门的物品,但是热门的判定需要考虑到时间因素,用以下公式计算流行度:<br><img src="/2018/01/22/上下文推荐系统/814D6A7F-CC21-429D-9EAD-FA1743C5F593.png" alt=""><br>T代表时间T,i代表物品.</p>
<h2 id="Item-CF-with-Time"><a href="#Item-CF-with-Time" class="headerlink" title="Item CF with Time"></a>Item CF with Time</h2><p>思想是若用户对i,j操作的时间相隔的很远,那么i,j相似度需要降低(也就是假设用户会在一段时间类搞相似的东西).在计算上需要的是,在余弦公式的点积部分乘一个时间衰减函数,一个典型的时间衰减函数如下:<br><img src="/2018/01/22/上下文推荐系统/FE360C2F-629B-4CD7-B38A-6A88FE3CACE7.png" alt=""><br>分析一下,由于item相似度可以分为多个分相似度(点积分量),每个分相似度都是基于在某用户u1下i和j的共现行为,所以,就肯定有tui和tuj,代表u对i,j的操作时间,所以你给每个点积分量应用一下这个函数就好.</p>
<blockquote>
<p>item CF最好需要归一化,这也是其本身提高推荐性能的办法,归一的做法是<strong>按列中最大值归一</strong>  </p>
</blockquote>
<p>另外,还可以考虑时间信息对用户-物品推荐列表的预测公式做修改.这是基于假设”用户的兴趣可能和最近时间的兴趣差不多”<br><img src="/2018/01/22/上下文推荐系统/D7F72F57-B3A0-4847-9720-AB3F3953841B.png" alt=""></p>
<h2 id="位置上下文"><a href="#位置上下文" class="headerlink" title="位置上下文"></a>位置上下文</h2><p>分析可知两个特性:</p>
<ol>
<li>兴趣本地化,比如湖南和陕西人喜欢的东西就不同的,要考虑到用户地域</li>
<li>活动本地化:大多用户活动范围有限,于是需要考虑到物品地域.</li>
</ol>
<p>按用户/物品有没有位置信息,可以划分三种数据集<br><img src="/2018/01/22/上下文推荐系统/B68E4364-D365-4F20-817D-45539A19F1F0.png" alt=""><br>下面介绍LARS,其底层算法就算作使用了ItemCF吧.<br><img src="/2018/01/22/上下文推荐系统/C1FC3947-0066-48F4-8E33-584B93CC0694.png" alt=""><img src="/2018/01/22/上下文推荐系统/5708224D-437C-498A-B2B0-2BE24D4E5820.png" alt=""></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/22/Deep Neural Networks for YouTube Recommendations/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="PW">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PW's notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/22/Deep Neural Networks for YouTube Recommendations/" itemprop="url">未命名</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-22T12:23:10+08:00">
                2018-01-22
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Deep-Neural-Networks-for-YouTube-Recommendations"><a href="#Deep-Neural-Networks-for-YouTube-Recommendations" class="headerlink" title="Deep Neural Networks for YouTube Recommendations"></a>Deep Neural Networks for YouTube Recommendations</h1><p>#推荐引擎/论文</p>
<p>在本文中,首先，我们详细描述一个::深度候选生成模型::，然后描述一个单独的::深度排序模型::。</p>
<p>youtube推荐算法需要关注几个方面</p>
<ol>
<li>规模:很多推荐算法在如此的规模上难以运行,需要<strong>Highly specialized distributed learning algorithms</strong></li>
<li>新物品非常多,需要及时对新内容和用户新动作建模.</li>
<li>只能获得有噪声的隐式反馈信号,算法应该对此具有鲁棒性</li>
</ol>
<h2 id="OverView"><a href="#OverView" class="headerlink" title="OverView"></a>OverView</h2><hr>
<p><img src="/2018/01/22/Deep Neural Networks for YouTube Recommendations/E810C952-1CED-46C7-91BC-BB7A77E38225.png" alt=""><br>蓝色的是两个神经网络.第一个的输入是::用户YouTube活动历史中的事件,每个事件(用户U和上下文C的条件下,对用户在t时刻的一次观看wt)就是个样本呗::,输出是::从大型语料库中检索出的一小部分（数百个）视频::,这些检索出的视频通常::高度精确地与用户相关::.<br>The candidate generation network only provides broad personalization via <strong>collaborative ﬁltering</strong>. The similarity between users is expressed in terms of coarse features such as IDs of video watches, search query tokens and 人口学特征.</p>
<p>排名模块会对每个video,建模丰富的用户物品特征,依照desired 目标函数对video打分,然后rank by score,把高分视频推荐给用户.</p>
<p>在开发过程中，我们广泛使用了度量指标（::精度，召回率，ranking loss::等）来指导我们系统的迭代改进。</p>
<h2 id="CANDIDATE-GENERATION-…"><a href="#CANDIDATE-GENERATION-…" class="headerlink" title="CANDIDATE GENERATION(….)"></a>CANDIDATE GENERATION(….)</h2><hr>
<p>把问题看做一个extreme分类问题,可以描述为</p>
<blockquote>
<p>为用户U和上下文C的条件下,对用户在t时刻的一次观看wt,在语料库V的millions个类别i中进行分类,看wt属于哪一类(用户u看过一些视频后，我们需要预测用户下一个要看的视频是100万分类中的哪一个分类？)<br><img src="/2018/01/22/Deep Neural Networks for YouTube Recommendations/57103E06-37C7-49D8-BFA8-1C27B0980C81.png" alt="">…………(1)<br>从公式可以看出这是个使用了softmax输出层的多分类问题.softmax层的输入就是vi*u,其中u 代表::a high-dimensional“embedding”of the &lt;user,context&gt;::,vi是每个candidate video的embedding(提前根据video信息做好了). </p>
</blockquote>
<p>所以DNN的目标就是在用户信息和上下文信息为输入条件下::学习用户的embedding向量::,学到了u你就可以计算vi*u,于是就可以通过softmax输出(1)</p>
<p>考虑训练数据,使用隐式反馈来训练这个,只取完成了观看的事件作为样本.一条训练数据可以描述为(u1,c1,5)(用户u1在上下文c1的情况下观看了类别为5的视频).</p>
<p>在服务的时候,我们需要::计算最有可能的N个类（视频），以便选择前N个呈现给用户::。在数十毫秒的严格服务延迟下对数百万项目进行评分，::需要在类别数量上有近似线性时间的评分方案::。以前的YouTube系统依赖于::哈希::[24]，这里描述的分类器使用类似的方法。由于softmax输出层的校准可能性在服务时间是不需要的，因此::得分问题可以简化为点积空间中的最近邻点搜索::.(把user vector和video vector用某种计算快速地做类似KNN的计算就得到了候选集).</p>
<h3 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h3><p><img src="/2018/01/22/Deep Neural Networks for YouTube Recommendations/BB87A64B-3DAD-4127-9165-D5A8873E60B5.png" alt=""><br>底层对video watches和search tokens(当然很稀疏)做embedding,也包括一些其他特征的embedding,形成一个::比较dense的特征向量::,代表(用户特征与上下文特征)</p>
<h2 id="Ranking"><a href="#Ranking" class="headerlink" title="Ranking"></a>Ranking</h2><hr>
<p>We use a deep neural network with similar architecture as candidate generation to assign an independent score to each video impression using logistic regression,并且测试指标是”a simple function of expected watch time per impression”</p>
<p>此处的问题是,建模预计的观看时长,ReLu输出的自然也可以看做”精炼后的特征.”</p>
<p>训练数据的选取上以有没有点击来划分正负样本，正样本根据播放时长进行加权，正样本的权重是播放时长 Ti，负样本权重是1.(其实也就是样本的回归值) 拟合逻辑回归的函数(Wx+b)就好,然后线上的时候根据e^(f)来预测观看时间,根据这个排名就好.<br><img src="/2018/01/22/Deep Neural Networks for YouTube Recommendations/3259CBFB-E46B-42C4-9388-0A0AD11593B9.png" alt=""><br>前面有<strong>复杂的特征工程</strong>…特征怎么选,有通用经验,当然也和业务相关..</p>
<p>更细节的部分不探讨先.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/18/Ad Click Prediction a View from the Trenches/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="PW">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PW's notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/18/Ad Click Prediction a View from the Trenches/" itemprop="url">未命名</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-18T17:38:54+08:00">
                2018-01-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Ad-Click-Prediction-a-View-from-the-Trenches"><a href="#Ad-Click-Prediction-a-View-from-the-Trenches" class="headerlink" title="Ad Click Prediction: a View from the Trenches"></a>Ad Click Prediction: a View from the Trenches</h1><p>#推荐引擎/论文</p>
<p>我们规定,在推荐系统里的用法是:(因为需要个性化,按请求加入用户特征和环境特征)<br>::Y是是否点击 看作想得到逻辑回归那样的结果 然后每条数据都是一次展现 Y取值0或者1 我们去预测点击的概率:: </p>
<p>该文是GoogleFTRL在点击率模型上的应用，从技术实现的角度介绍了在线学习算法FTRL的工程实现，并且给出一些内存优化、特征选择等工程细节。从此FTRL算法才大规模推广使用。<br>该笔记主要介绍一下几类在线学习算法的思路以及FTRL实现细节以及工程上技巧。</p>
<p><a href="http://blog.csdn.net/fangqingan_java/article/details/51020653" target="_blank" rel="noopener">【每周一文】Ad Click Prediction: a View from the Trenches(2013) - CSDN博客</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/18/Field-aware Factorization Machines for CTR Prediction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="PW">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PW's notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/18/Field-aware Factorization Machines for CTR Prediction/" itemprop="url">未命名</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-18T17:35:49+08:00">
                2018-01-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Field-aware-Factorization-Machines-for-CTR-Prediction"><a href="#Field-aware-Factorization-Machines-for-CTR-Prediction" class="headerlink" title="Field-aware Factorization Machines for CTR Prediction"></a>Field-aware Factorization Machines for CTR Prediction</h1><p>#推荐引擎/论文</p>
<p>每条数据都是以1,0为标签,我们要做的事是类似LR的,就是用的技术不一样.</p>
<h1 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h1><hr>
<p>本文中我们建立了FFMs作为一种有效的方法来对包括CTR预测数据在内的大量::稀疏数据::进行::分类::。 首先,提出了训练FFM的高效实现。 然后,全面分析FFM,并与其他模型比较。 实验表明，FFM对于::某些分类问题::是非常有用的。</p>
<h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><hr>
<p>对CTR预测问题,LR可能是最广泛使用的模型,给定m个训练样本(y,x),x是n维向量,y是标签,LR模型w是求解下面问题得来的<br><img src="/2018/01/18/Field-aware Factorization Machines for CTR Prediction/017AF03A-B021-4E6E-B6A6-9B1CB1B63CAF.png" alt="">………(1)<br>其中<br><img src="/2018/01/18/Field-aware Factorization Machines for CTR Prediction/F5130C88-40C6-45EE-BF0B-14C4FC47FFD8.png" alt="">……….(2)<br>学习feature conjunctions的效果似乎是CTR预测的关键; 例如见下表,以更好地理解feature conjunctions。 来自Gucci的广告在Vogue上的点击率特别高。 然而，这些信息对于学习线性模型是不容易的，因为他们分别学习了两个权重Gucci和Vogue。<br><img src="/2018/01/18/Field-aware Factorization Machines for CTR Prediction/4A4C2633-E2F5-49B5-AF44-F30C66C2A106.png" alt=""><br>于是有了Poly2方法和<strong>FM方法</strong>. FM的一个变体称为::PITF::,其用于个性化的标签推荐。 在2012年有人提出了一个称为“::factor model::”的PITF的推广。 进而,把其field从user,item,tag三个扩展到更general的情况,就是FFM.</p>
<h2 id="FFM"><a href="#FFM" class="headerlink" title="FFM"></a>FFM</h2><hr>
<p>FFM的想法源于<strong>PITF [7]</strong>提出的带有个性化标签的推荐系统。在PITF中，他们假定三个可用字段，包括User，Item和Tag，并在单独的潜在空间中分解（User，Item），（User，Tag）和（Item，Tag）。由于::[7]针对的是推荐系统::，仅限于三个特定的领域（用户，项目和标签）. 本节我们提供关于实况报道预测的全面的FFM研究。对于大多数CTR数据集，如表1所示，“::features::”可以分成“::fields::”。在我们的例子中，ESPN，Vogue和NBC三个功能属于ﬁeld:发布商，FFM是利用这些信息的FM的变体。为了解释实况调查如何运作，我们考虑下面的新样本：<br><img src="/2018/01/18/Field-aware Factorization Machines for CTR Prediction/9AEA4B3F-9D3B-4E07-B32D-5F5AA466FA52.png" alt=""><br>在FM中，每个特征只有一个::隐向量::,在FFM中，每个特征都有::多个隐向量::。 根据其他feature的filed，其中之一是用来做内积。 在我们的例子中，φFFM（w，x）是<br><img src="/2018/01/18/Field-aware Factorization Machines for CTR Prediction/99A32351-255A-44B7-A41A-1137A59C7FC2.png" alt=""><br>我们看到要学习（ESPN，NIKE）的latent effect,，我们使用了<img src="/2018/01/18/Field-aware Factorization Machines for CTR Prediction/7F5563C3-0005-486B-8259-55464861E3AE.png" alt="">,因为Nike属于Field A(Advertizer). 而要学习(EPSN, Male)的latent eﬀect,就使用<img src="/2018/01/18/Field-aware Factorization Machines for CTR Prediction/79E2B1AC-5DCE-486F-9082-8EC08898B35C.png" alt="">因为Male属于Filed G(Gender),同时<img src="/2018/01/18/Field-aware Factorization Machines for CTR Prediction/DFEBAF07-223E-4B47-92D1-CFF98F05CA40.png" alt="">也会用上,因为ESPN属于filed P(Publisher).</p>
<p>于是数学上描述两个filed交互是:<br><img src="/2018/01/18/Field-aware Factorization Machines for CTR Prediction/D265B289-A599-41D7-B3FD-97CF03DD0394.png" alt="">……..(3)</p>
<p>其中f1和f2分别是j1和j2的field。 如果f是field的数量，那么FFM的变量的数量是nfk(n是维度)，并且计算(3)的复杂度是<img src="/2018/01/18/Field-aware Factorization Machines for CTR Prediction/EDA29CC1-5F68-4D98-8694-6DFBC686BCA9.png" alt="">(n-是值不为0的平均column树). 值得注意的是，在FFM中，因为每个潜在向量只需要学习对特定filed的效果，通常取的k值比FM中远小:<br><img src="/2018/01/18/Field-aware Factorization Machines for CTR Prediction/30EE340D-9D2C-4F38-A3E3-2225D9C1252B.png" alt=""></p>
<h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><hr>
<p>除了φLM（w，x）被φFFM（w，x）代替之外，优化问题与（1）相同(<strong>是一个输出概率二分类的问题</strong>)。 我们使用SGD。优化过程如下.<br><img src="/2018/01/18/Field-aware Factorization Machines for CTR Prediction/A5C63DC4-981B-4998-BA8B-C7BBCB0EDD05.png" alt=""><br>…具体的解释看论文吧</p>
<h2 id="Adding-Field-Information"><a href="#Adding-Field-Information" class="headerlink" title="Adding Field Information"></a>Adding Field Information</h2><hr>
<p>这节讨论如何把filed info加入到数据上,实际上就是把数据格式做转换如下<br><img src="/2018/01/18/Field-aware Factorization Machines for CTR Prediction/0DE1C564-65CE-4897-978D-373E4F1164D3.png" alt="">==&gt;<img src="/2018/01/18/Field-aware Factorization Machines for CTR Prediction/2A75B59F-DA42-4EAE-8C95-D6E743DC077C.png" alt=""><br>我们需要说明feature号,field号.</p>
<ol>
<li>Categorical Features<br>假设使用libsvm格式,那么使用one-hot,而且0值不储存,那么,既然一个field只能有一个1,那么就把数据里每个元素之前加上filed信息就好<br><img src="/2018/01/18/Field-aware Factorization Machines for CTR Prediction/3C7BF9D9-8481-4EF4-8719-A392A687F0A0.png" alt=""><br>符合field:feature号:value的格式</li>
<li>Numerical Features<br>比如对下面论文是否被接受的数据做预测<br><img src="/2018/01/18/Field-aware Factorization Machines for CTR Prediction/384982E5-1D30-44AA-88C8-66BFB9BF8D5C.png" alt=""><br>你可以直接使用实数值<br><img src="/2018/01/18/Field-aware Factorization Machines for CTR Prediction/B78ACB52-A161-4518-A4C8-75B2C26A16F0.png" alt=""><br>也可以把::连续值离散化::,得到<br><img src="/2018/01/18/Field-aware Factorization Machines for CTR Prediction/29A3A1AF-E258-4FCE-B8AA-9D8BE17AA147.png" alt=""><br>就是不知道到底哪种离散化好,比如…we may transform 45.73 to “45.7,”“45,”“40,” or even “int(log(45.73)).</li>
<li>Single-ﬁeld Features<br>对有些数据集,比如下面,一个特征就是一个field,这时候你弄个域没啥意义<br><img src="/2018/01/18/Field-aware Factorization Machines for CTR Prediction/48EA0FE9-48EE-44D7-B40E-A8C322D79274.png" alt=""></li>
</ol>
<p>找到的::真实CTR数据集::说明<br>Data fields</p>
<ul>
<li>Label - Target variable that indicates if an ad was clicked (1) or not (0).</li>
<li>I1-I13 - A total of 13 columns of integer features (mostly count features).</li>
<li>C1-C26 - A total of 26 columns of categorical features. The values of these features have been hashed onto 32 bits for anonymization purposes.<br><img src="/2018/01/18/Field-aware Factorization Machines for CTR Prediction/DA130343-A93E-4757-9640-63F60644B7AE.png" alt=""></li>
</ul>
<h2 id="Tag-Problem简介"><a href="#Tag-Problem简介" class="headerlink" title="Tag Problem简介"></a>Tag Problem简介</h2><hr>
<p>Recommender systems can help to suggest a user the tags he might want to use for tagging a speciﬁc item</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/18/Fast Context-aware Recommendations with Factorization Machines/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="PW">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PW's notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/18/Fast Context-aware Recommendations with Factorization Machines/" itemprop="url">未命名</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-18T17:35:02+08:00">
                2018-01-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Fast-Context-aware-Recommendations-with-Factorization-Machines"><a href="#Fast-Context-aware-Recommendations-with-Factorization-Machines" class="headerlink" title="Fast Context-aware Recommendations with Factorization Machines"></a>Fast Context-aware Recommendations with Factorization Machines</h1><p>#推荐引擎/论文</p>
<p>面向rating prediction,数据就使用explicit这样的了,当然,也可以改造.</p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><hr>
<p>行为发生的situation是推荐系统的重要信息.Context-aware推荐系统考虑了这个.当前,从准确度上来看,最好的context-aware评分预测方法是基于Tucker张量分解的<strong>Multiverse Recommendation</strong>.但是两个缺点</p>
<ul>
<li>模型复杂度对context遍历个数是指数的,对factorization是多项式的..</li>
<li>只对离散型context变量起作用.</li>
</ul>
<p>我们使用FM来建模contextual info,并提供context-aware评分预测.并提供ALS的优化方法.</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><hr>
<p>评分预测除了关于参与评级事件的实体的(谁,什么物品,评分数)数据之外，还可能有关于评级事件发生的情况的信息，例如，当前位置，时间，附近的人或用户的当前情绪。这种情景信息通常被称为情境。</p>
<p>经典推荐系统方法不考虑上下文信息。一些方法执行数据的预处理或后处理以使标准方法具有情境(context)感知能力。虽然这种特殊的解决方案可能在实践中发挥作用，但它们有缺陷，即在这个过程中的所有步骤都需要supervision和fine-tuning。将各种输入数据整合到一个模型中的方法在这方面比较实用，理论上也比较优雅,比如目前在预测准确性方面最灵活和最强的方法是Multiverse推荐[5]，它依赖于Tucker分解，并允许使用任何categorical上下文。然而，对于真实世界的场景，其计算复杂度太高.</p>
<p>在本文中，我们提出了一种基于因子分解机器（FM）的情境感知的评分预测器. FMs包括并可以模仿推荐系统中最成功的方法，包括矩阵分解,SVD ++,或PITF,。我们展示了FM如何应用于各种各样的上下文领域，包括categorical，set categorical或real-valued domains。</p>
<p>此外我们提出了一种基于交替最小二乘（ALS）的新算法。 the complexity for one iteration of our ALS algorithm is in O(|S| m k) where |S| is the number of training examples.(k是分解维度,m是the number of modes/variables involved) 我们新的ALS算法相对于SGD的主要优点是::不需要确定学习率::。 这在实践中非常重要.</p>
<h2 id="CONTEXT-AWARE-RATING-PREDICTION"><a href="#CONTEXT-AWARE-RATING-PREDICTION" class="headerlink" title="CONTEXT-AWARE RATING PREDICTION"></a>CONTEXT-AWARE RATING PREDICTION</h2><hr>
<p>我们首先描述任务,然后,我们将展示如何将这个任务表示为矩阵极端稀疏时的,对实值特征向量的回归任务。</p>
<p>评分预测可以看做在给定用户集<img src="/2018/01/18/Fast Context-aware Recommendations with Factorization Machines/C7EBA6E2-8C0B-43CF-BE9D-73C03782B72A.png" alt="">和item集<img src="/2018/01/18/Fast Context-aware Recommendations with Factorization Machines/0B59375F-D070-48DF-BEF2-C70FE6C33139.png" alt="">上的一个回归任务.y(u,i)代表u对i的评分,把所有<strong>已知</strong>的y(u,i)记作S.我们需要估计函数y<br><img src="/2018/01/18/Fast Context-aware Recommendations with Factorization Machines/BF3C5109-5FAD-4865-A076-D4DCC89A3BD7.png" alt="">,以预测任何y(u,i).(item prediction又是另一种任务了,可以看做ranking)</p>
<p>在情境感知推荐系统中，假设有一些附加信息可以影响评分行为,我们::把上下文变量表示为c ∈C::,那么可以举例,用户在评价一个项目（例如C = {happy，sad，…}）时所处的情绪，给出评分的时间 （例如C=R+），上次浏览的物品（例如C=P(I)）或位置（例如C=R^2）。</p>
<p>包含了上下文的预测任务就是估计下面函数了<br><img src="/2018/01/18/Fast Context-aware Recommendations with Factorization Machines/DEED3721-4AC2-4DC3-9EFE-8EDF56CA1AE3.png" alt=""></p>
<h2 id="CONTEXT-AWARE-RATING-PREDICTION-WITH-FMS"><a href="#CONTEXT-AWARE-RATING-PREDICTION-WITH-FMS" class="headerlink" title="CONTEXT-AWARE RATING PREDICTION WITH FMS"></a>CONTEXT-AWARE RATING PREDICTION WITH FMS</h2><hr>
<p>首先既然是回归任务,就用一下square loss,并且加入L2正则化项,那么FM的损失函数就是<br><img src="/2018/01/18/Fast Context-aware Recommendations with Factorization Machines/4028A48D-24D8-40A1-B656-6E6C20770049.png" alt="">……….(0)<br>λ是针对参数θ的正则化超参数,在我们的实验中，我们使用：λ（w0）= 0，因为不需要调整全局偏差; 对于所有参数wi∈W其λ相同, 而对于所有参数vif∈V 其λ也都是相同的.</p>
<p>让我们看看各种参数如何运用进来.</p>
<ul>
<li>Categorical domain:使用one-hot编码就行</li>
<li>Categorical set domain:多值枚举型,那就使用多hot编码呗.(我们建议对非0的context向量z(zi是表示ci向量),将其::归一化::，使得所有向量总和为1.这确保了所有向量具有相同的权重，这通常是合意的)</li>
<li>Real valued domains:直接使用就行</li>
</ul>
<p>总的来讲,样本的特征向量就是<br><img src="/2018/01/18/Fast Context-aware Recommendations with Factorization Machines/034EFF6F-B90B-40FF-8D46-64DD707EB403.png" alt=""></p>
<p>考虑到下图表示的特征<br><img src="/2018/01/18/Fast Context-aware Recommendations with Factorization Machines/008900C2-62C0-4736-9AE0-1CACE3E476A1.png" alt=""><br>FM公式对这个问题可以重写为<br><img src="/2018/01/18/Fast Context-aware Recommendations with Factorization Machines/5DA9AE4F-45A3-439C-92A8-AA9507ED719B.png" alt=""><br>和矩阵分解相比,看得出FM正好就包含了矩阵分解所需的&lt;Vi,Vu&gt;.此外，它::将所有context变量的所有配对相互作用因式分解::。言下,FM包含了矩阵分解模型</p>
<h2 id="Fast-Learning-ALS"><a href="#Fast-Learning-ALS" class="headerlink" title="Fast Learning(ALS)"></a>Fast Learning(ALS)</h2><hr>
<p>对任意需要学习的参数θ,我们都可以发现,y^公式可以看做θ的一个线性函数<br><img src="/2018/01/18/Fast Context-aware Recommendations with Factorization Machines/B2CA2E57-8032-4230-9BDE-04FBB0D218FF.png" alt="">………..(1)<br>其中g()与h()是与θ无关的,比如</p>
<ol>
<li>当θ为w0<br><img src="/2018/01/18/Fast Context-aware Recommendations with Factorization Machines/3208EE4D-18B9-47EB-B308-558F74F975C1.png" alt=""></li>
<li>当θ为wl<br><img src="/2018/01/18/Fast Context-aware Recommendations with Factorization Machines/224210FD-4425-4075-B1FD-44D6577DDD94.png" alt=""></li>
<li>当θ为vlf<br><img src="/2018/01/18/Fast Context-aware Recommendations with Factorization Machines/61903558-B2E0-4A88-87D2-CE183E250E7D.png" alt=""></li>
</ol>
<p>并且,与FM论文中给出的梯度对比<br><img src="/2018/01/18/Fast Context-aware Recommendations with Factorization Machines/4FED5EE1-F44B-4140-BBF0-489B6CFC9A5A.png" alt=""><br>可以发现,不管θ是哪一种参数,h(x)其实就是y^上θ的梯度(当然了,你从线性角度来看,y=hx+g,y对x的导数不就是a嘛.)(所以::想要求复杂的g的时候你就可以用y-hx表示::)</p>
<p>于是,对θ的最优解就是<br><img src="/2018/01/18/Fast Context-aware Recommendations with Factorization Machines/6FF9DEF8-A67F-4FD3-83C9-9CA572921B79.png" alt="">…………(3)<br>::证明:::<br>    使用Loss,也就是(0)式对参数θ求导,并令导数为0(<strong>含义是使得y极小</strong>),只要把(1)式子代入,就有:<br><img src="/2018/01/18/Fast Context-aware Recommendations with Factorization Machines/44EB27BF-61DD-4012-9973-C2A55AB1B7DD.png" alt=""><br><img src="/2018/01/18/Fast Context-aware Recommendations with Factorization Machines/D7C18BF1-1766-4916-A8D9-3E39AB36AB8D.png" alt=""></p>
<p>所以,整个的ALS算法是:<br><img src="/2018/01/18/Fast Context-aware Recommendations with Factorization Machines/C5B5A08B-46EA-4F6E-AA66-F53A23298862.png" alt=""></p>
<ol>
<li>初始化各个参数.其中向量参数使用符合0均值正态分布的小数字随机初始化</li>
<li>对<strong>所有已知样本</strong>,提前计算error(预测-真实)和q(<img src="/2018/01/18/Fast Context-aware Recommendations with Factorization Machines/72A2096F-9CB2-431B-8203-4F5393C94A62.png" alt="">)</li>
<li>开始主过程<ol>
<li>按公式(3),代入w0的h()和g(), 更新w0(其中用到了e),并且更新error()……optimize ﬁrst lower interactions and then higher ones because for lower interactions more data is observed and thus their estimates are more reliable.</li>
<li>按公式(3),代入wi的h()和g(), 更新所有一次项参数,并且再次更新error()</li>
<li>按公式(3),代入wij的h()和g(),更新二次项参数,病根新error()和q().</li>
</ol>
</li>
<li>循环一些次,直到到达停止条件结束</li>
</ol>
<blockquote>
<p>ALS的思想体现在3里,对三种参数w0,wi,wij,求其最优值的时候都是固定其他参数来更新它.  </p>
</blockquote>
<p>做了一些pre-computation以加速计算,</p>
<ol>
<li>你想用公式(3),一个计算瓶颈就是为每一个训练样本计算<img src="/2018/01/18/Fast Context-aware Recommendations with Factorization Machines/5C78DCFD-2AB1-4B09-9F65-DF786675E4B8.png" alt="">,时间复杂度是<img src="/2018/01/18/Fast Context-aware Recommendations with Factorization Machines/A8407B22-DB0F-4EA3-A45B-1097AE883793.png" alt="">,但是如果我们提前计算好error<img src="/2018/01/18/Fast Context-aware Recommendations with Factorization Machines/2C4503EA-7865-4265-92D6-7E9DEE7428E4.png" alt="">,那么我们想要的就能表示为<img src="/2018/01/18/Fast Context-aware Recommendations with Factorization Machines/F06690BA-8DA0-4C79-AD0D-C3A61F237B74.png" alt="">,这样就每次计算时候只需要计算h(θ)就可以了…而这本来就要计算…</li>
<li>现在计算复杂度只在于h（θ）函数的复杂性, 对于参数w 0和wi，h（θ）的复杂度是恒定的，但是对于二次参数，计算h包含了一个遍历所有变量的循环。…反正就又把h(θ)分解了,得到一个无关样本的,都需要计算的值..,看图吧,-项目是去除i==l的情况.<br><img src="/2018/01/18/Fast Context-aware Recommendations with Factorization Machines/7BBC2EAF-9BB9-4720-8247-DC011BC143AC.png" alt=""></li>
</ol>
<p>这两种优化,实际上思想就是::为所有样本都需要计算的一个复杂项a,分解出a=b+c,并且b对所有样本一样,于是就只需要计算不同的c::</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/17/今日头条推荐详解/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="PW">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PW's notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/17/今日头条推荐详解/" itemprop="url">未命名</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-17T10:48:00+08:00">
                2018-01-17
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="今日头条推荐详解"><a href="#今日头条推荐详解" class="headerlink" title="今日头条推荐详解"></a>今日头条推荐详解</h1><p>#推荐引擎/论文</p>
<p>::主要介绍今日头条推荐系统概览以及内容分析、用户标签、评估分析，内容安全等原理。::</p>
<h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><p>本质是解决三种特征的匹配问题y=F(xi,xu,xc)</p>
<ul>
<li>内容特征</li>
<li>用户特征,包括::兴趣标签::,职业,年龄,性别等等…总之就是动态画像+静态画像</li>
<li>环境特征:时间,地点,设备等等….</li>
</ul>
<p><img src="/2018/01/17/今日头条推荐详解/5936000249cf2a9275f0.jpg" alt=""><br>前面提到的公式y = F(Xi ,Xu ,Xc)，是一个很经典的监督学习问题。可实现的方法有很多，比如传统的协同过滤模型，监督学习算法Logistic Regression模型，基于深度学习的模型，Factorization Machine和GBDT等。<br>现在很流行将::LR和DNN结合::，前几年Facebook也将LR和GBDT算法做结合。</p>
<p>上面说了模型,下面说模型主要用的特征,当然,还是那三大类特征,从另外一个角度来看,有4类特征对推荐影响很大<br><img src="/2018/01/17/今日头条推荐详解/59340005abb4a45cf02c.jpg" alt=""></p>
<ul>
<li>相关性特征，就是评<strong>估内容的属性和与用户是否匹配</strong>,会有一个相似度值</li>
<li>热度特征。包括全局热度、分类热度，主题热度，以及关键词热度等。内容热度信息在大的推荐系统特别在<strong>用户冷启动</strong>的时候非常有效。</li>
<li>环境特征，包括地理位置、时间。这些既是bias特征</li>
<li>协同特征，它可以在部分程度上帮助解决所谓算法越推越窄的问题。协同特征并非考虑用户已有历史。而是通过用户行为分析不同用户间相似性，比如点击相似、兴趣分类相似、主题相似、兴趣词相似，甚至向量相似，从而扩展模型的探索能力。</li>
</ul>
<p>下面说训练模型<br><img src="/2018/01/17/今日头条推荐详解/593900019ec5491e09ba.jpg" alt=""><br>我们线上目前::基于storm集群实时处理样本数据::，包括点击、展现、收藏、分享等动作类型。::模型参数服务器::是内部开发的一套高性能的系统，因为头条数据规模增长太快，类似的开源系统稳定性和性能无法满足.</p>
<p>整体的训练过程是线::上服务器记录实时特征::，导入到Kafka文件队列中，然后进一步导入Storm集群消费Kafka数据，客户端回传推荐的label::构造训练样本::，随后根据最新样本进行在线训练更新模型参数，最终线上模型得到更新。</p>
<p>但是,item非常大的时候,推荐系统不可能所有内容全部由模型预估。所以需要设计一些::召回策略::，每次推荐时从海量内容中筛选出千级别的内容库。召回策略最重要的要求是性能要极致(这个我们靠离线计算可以做到),意思就是,::先赶紧地召回一批,然后模型去预估到底推荐哪些..::<br><img src="/2018/01/17/今日头条推荐详解/8yitwoytgmtnd168.jpeg" alt=""><br><img src="/2018/01/17/今日头条推荐详解/593500054d52b679a646.jpg" alt=""><br>召回策略种类有很多，我们主要用的是倒排的思路。离线维护一个倒排，这个倒排的key可以是分类，topic，实体，来源等，排序考虑热度、新鲜度、动作等。线上召回可以迅速从倒排中根据用户兴趣标签对内容做截断，高效的从很大的内容库中筛选比较靠谱的一小部分内容。意思就是一个根据新内容的实时的::tag_item_rec_list::,::对用户和内容都分析,挖掘标签::</p>
<blockquote>
<p>他为什么要做这么做?我觉得,他维护倒排,主要还是因为其物品实时更新太快了…不断有东西给加进来  </p>
</blockquote>
<h2 id="item分析"><a href="#item分析" class="headerlink" title="item分析"></a>item分析</h2><p>item分析在推荐系统中一个很重要的::作用是用户兴趣建模::.却使用到了高深的NLP技术.下面是一个item的分析结果<br><img src="/2018/01/17/今日头条推荐详解/59390001a2892dd9254d.jpg" alt=""><br><img src="/2018/01/17/今日头条推荐详解/5935000550a189635540.jpg" alt=""><br><img src="/2018/01/17/今日头条推荐详解/59340005b1576ced60f1.jpg" alt=""><br>今日头条推荐系统的::线上分类采用典型的层次化文本分类算法::。最上面Root，下面第一层的分类是像科技、体育、财经、娱乐，体育这样的大类，再下面细分足球、篮球、乒乓球、网球、田径、游泳…，足球再细分国际足球、中国足球，中国足球又细分中甲、中超、国家队…，相比单独的分类器，利用层次化文本分类算法能更好地解决数据倾斜的问题。有一些例外是，如果要提高召回，可以看到我们连接了一些飞线。这套架构通用，但根据不同的问题难度，每个元分类器可以异构，像有些分类SVM效果很好，有些要结合CNN，有些要结合RNN再处理一下。<br><img src="/2018/01/17/今日头条推荐详解/59340005b1c095914cdc.jpg" alt=""><br>上图是一个::实体词识别算法::的case。基于分词结果和词性标注选取候选，期间可能需要根据知识库做一些拼接，有些实体是几个词的组合，要确定哪几个词结合在一起能映射实体的描述。如果结果映射多个实体还要通过词向量、topic分布甚至词频本身等去歧，最后计算一个相关性模型</p>
<p>其实这种对资讯类业务更加重要,如果考虑呼叫中心,其实item(坐席)无法进行这样分析,只能进行行为分析..</p>
<h2 id="用户标签"><a href="#用户标签" class="headerlink" title="用户标签"></a>用户标签</h2><p><img src="/2018/01/17/今日头条推荐详解/593600025096875e450e.jpg" alt=""><br>可以看出,第一类是动态的,第二类一般是静态的,当然,如果没提供也可以去预估..第三类当然是动态的了.</p>
<p><img src="/2018/01/17/今日头条推荐详解/59390001a5378c52f1c1.jpg" alt=""><br>最简单的是”view”标签,处理策略包括</p>
<ol>
<li>过滤噪声。通过停留时间短的点击，过滤标题党</li>
<li>热点惩罚。对用户在一些热门文章（如前段时间PG One的新闻）上的动作做降权处理。</li>
<li>时间衰减。用户兴趣会发生偏移，因此策略更偏向新的用户行为。因此，随着用户动作的增加，老的特征权重会随时间衰减，新动作贡献的特征权重会更大。</li>
<li>惩罚展现。如果一篇推荐给用户的文章没有被点击，相关特征（类别，关键词，来源）权重会被惩罚。(这个反馈收集对引擎有点难..)</li>
</ol>
<p>用户标签怎么计算?第一种方案是离线计算<br><img src="/2018/01/17/今日头条推荐详解/5935000553e66b76f797.jpg" alt=""><br>可以看出其实是全量更新的..映射到我们的系统里..</p>
<ol>
<li>每天取过去一天的log数据,分析有哪些用户</li>
<li>取过去两个月这些用户的数据</li>
<li>交给离线计算来挖掘标签,一个任务做统计,一个打标签.</li>
<li>存入Hbase,线上就读这个…(在线调用这个作为特征去精排?)<br><img src="/2018/01/17/今日头条推荐详解/59340005b39b10af62d7.jpg" alt=""><br>反正一个是<strong>性能</strong>,一个是<strong>效果</strong>的问题..</li>
</ol>
<p>第二种方案是近线计算方案<br><img src="/2018/01/17/今日头条推荐详解/593a0001a47f266e3a03.jpg" alt=""><br>映射进来就是</p>
<ul>
<li>上传日志的时候触发近线计算,计算标签也是流程之一</li>
<li>这种近线计算任务采用spark streaming就是了,(或者三次日志上传触发更新一次)或者独立做一个tag系统,用消息组件就是了</li>
<li>近线任务读取离线的基本tag,更新之,存入之…</li>
</ul>
<p>当然,tag定义需要人工指定…</p>
<p>当然,离线还是可以计算一些基本基本稳定的信息的.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/16/GBDT在CTR中的运用/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="PW">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PW's notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/16/GBDT在CTR中的运用/" itemprop="url">未命名</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-16T19:52:35+08:00">
                2018-01-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="GBDT在CTR中的运用"><a href="#GBDT在CTR中的运用" class="headerlink" title="GBDT在CTR中的运用"></a>GBDT在CTR中的运用</h1><p>#推荐引擎/论文</p>
<h3 id="Post-1"><a href="#Post-1" class="headerlink" title="Post 1"></a>Post 1</h3><p>从如何组合使用来解释.</p>
<p>经常是LR+GBDT加起来用,另外,LR还有其在线版本::FTRL::<br>LR这种线性模型很容易并行化，处理上亿条训练样本不是问题，但线性模型学习能力有限，需要<strong>大量特征工程预先分析出有效的特征、特征组合</strong>，从而去间接增强LR的非线性学习能力。</p>
<p>LR模型中的特征组合很关键，但又无法直接通过特征笛卡尔积解决，<strong>只能依靠人工经验</strong>，耗时耗力同时并不一定会带来效果提升。如何自动发现有效的特征、特征组合，弥补人工经验不足，缩短LR特征实验周期，是亟需解决的问题。(FM其实是一种思路?)</p>
<p>组合的思路是<strong>gbdt的输出作为LR或者FM的输入, 原始特征经过gbdt转变成高维稀疏特征</strong></p>
<p>原理解释是,GBDT的思想使其具有天然优势可以发现多种有区分性的特征以及特征组合(<strong>所谓组合就是树里从上而下判断所判断的特征们组合在一起的效果</strong>)..下图1为使用GBDT+LR前后的特征实验示意图，融合前人工寻找有区分性特征（raw feature）、特征组合（cross feature），融合后直接通过黑盒子（Tree模型GBDT）进行特征、特种组合的自动发现。<br><img src="/2018/01/16/GBDT在CTR中的运用/20150827190140295.png" alt=""><br>Facebook的paper有个例子如下图所示，图中Tree1、Tree2为通过GBDT模型学出来的两颗树，x为一条输入样本，遍历两棵树后，x样本分别落到两颗树的叶子节点上，每个叶子节点对应LR一维特征，那么通过遍历树，就得到了该样本对应的所有LR特征。由于树的每条路径，是通过最小化均方差等方法最终分割出来的有区分性路径，根据该路径得到的特征、特征组合都相对有区分性，效果理论上不会亚于人工经验的处理方式。<br><img src="/2018/01/16/GBDT在CTR中的运用/20150827190225375.png" alt=""></p>
<p>那么,why this way?</p>
<ol>
<li>为什么建树采用ensemble决策树？<br>一棵树的表达能力很弱，不足以表达多个有区分性的特征组合，多棵树的表达能力更强一些。GBDT每棵树都在学习前面棵树尚存的不足，迭代多少次就会生成多少颗树。按paper以及Kaggle竞赛中的GBDT+LR融合方式，多棵树正好满足LR每条训练样本可以通过GBDT映射成多个特征的需求。</li>
<li>为什么建树采用GBDT而非RF<br>RF也是多棵树，但从效果上有实践证明不如GBDT。且GBDT前面的树，特征分裂主要体现对多数样本有区分度的特征；后面的树，后面树针对残差依然较大的样本，<strong>即针少数的对长尾样本。更适合ctr模型预估</strong>。优先选用在整体上有区分度的特征，再选用针对少数样本有区分度的特征，思路更加合理，这应该也是用GBDT的原因。</li>
</ol>
<h3 id="Post-2"><a href="#Post-2" class="headerlink" title="Post 2"></a>Post 2</h3><p>从适用特征来解释.<br>从适用性上来讲,<strong>LR和FM适合categorical的特征</strong>，使用的时候一般上会先进行为one-hot编码或者统一将categorical特征映射到值空间<br>FM和LR是无法连续的特征的，因此可以通过<strong>树模型(能处理连续特征</strong>)，将其转换为categorical的特征，比如GBDT.<br>比如说，对于一个样本，我们有K棵树，因此对于该样本，落在每棵树的哪个叶子节点作为一个categorical特征</p>
<p>GBDT+FM其实也是一种思路…</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/15/Learning To Rank/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="PW">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PW's notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/15/Learning To Rank/" itemprop="url">未命名</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-15T21:25:36+08:00">
                2018-01-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Learning-To-Rank"><a href="#Learning-To-Rank" class="headerlink" title="Learning To Rank"></a>Learning To Rank</h1><p>#推荐引擎/论文</p>
<p>互联网搜索经历了三代的发展历程。</p>
<pre><code>1. 第一代技术，将互联网网页看作文本，主要采用传统信息检索的方法。
2. 第二代技术，利用互联网的超文本结构，有效地计算网页的::相关度::与::重要度::，代表的算法有 PageRank 等。
3. 第三代技术，有效利用日志数据与**统计学习方法**，使网页相关度与重要度计算的精度有了进一步的提升，代表的方法包括排序学习、网页重要度学习、匹配学习、话题模型学习、查询语句转化学习。
</code></pre><p>为什么现在才LTR?</p>
<ol>
<li>现在数据膨胀,对于某个网页进行<strong>排序需要考虑的因素越来越多</strong>，比如网页的pageRank值、查询和文档匹配的单词个数、网页URL链接地址长度等都对网页排名产生影响，Google目前的网页排序公式考虑200多种因子，此时机器学习的作用即可发挥出来.(以前特征少,没必要)</li>
<li>对于有监督机器学习来说，首先需要<strong>大量的训练数据</strong>，在此基础上才可能自动学习排序模型. 一种方法是”用户发出一个查询，搜索引擎返回搜索结果，用户会点击其中某些网页,可以假设用户点击的网页是和用户查询更加相关的页面”.</li>
</ol>
<p>LTR作用过程的一个图:(可以任务对Q2,由于用户点击了Doc2所以Doc2最相关).<br><img src="/2018/01/15/Learning To Rank/1347943194_4835.jpg" alt=""><br>当然,训练数据(文档)进入系统是要用特征向量的,常用的特征包括</p>
<ol>
<li>查询词在文档中的词频信息 </li>
<li>查询词的IDF信息</li>
<li>文档长度</li>
<li>网页的入链数量</li>
<li>网页的出链数量</li>
<li>网页的pageRank值</li>
<li>网页的URL松度</li>
<li>査询词的Proximity值：即在文档中多大的窗口内可以出现所有査询词。<br>文档于是就转化为了(特征x,打分y)的形式了…</li>
</ol>
<p>共三类学习方法:::Pointwise/Pairwise/Listwise::,Pointwise和Pairwise把排序问题转换成<strong>回归</strong>,<strong>分类</strong>或<strong>有序分类</strong>问题。Listwise把Query下整个搜索结果作为一个训练的实例。3种方法的区别主要体现在损失函数（Loss Function）上</p>
<h4 id="Pointwise"><a href="#Pointwise" class="headerlink" title="Pointwise"></a>Pointwise</h4><p>下图是个例子,对于每个文档采用了3个特征： 査询与文档的Cosme相似性分值、査询词的Proximity值及页面的PageRank数值，而相关性判断是二元的，即要么相关要么不相关.<br><img src="/2018/01/15/Learning To Rank/1347946810_5795.jpg" alt=""><br>训练将训练下面的函数</p>
<blockquote>
<p> Score(Q, D)=a x CS+b x PM+cx PR+d<br>如果得分大于设定阀值，则叫以认为是相关的， 如果小于设定闽值则可以认为不相关.对于某个新的<strong>查询Q</strong>和文档D，系统首先获得其文档D对应的3个特征值，之后利用学习到的参数组合计算两者得分，当得分大于设定的闽值，即可判断文档是相关文档，否则判断为不相关文档。</p>
</blockquote>
<p>当然,这个函数和具体查询Q是相关的,不同Q的函数当然有异,这个方法仍然是<strong>计算查询和文档的相似度.</strong></p>
<h4 id="PairWise"><a href="#PairWise" class="headerlink" title="PairWise"></a>PairWise</h4><p>单文档方法完全从单个文档的分类得分角度计算，没有考虑文档之间的顺序关系。文档对方法则将重点转向量对文档顺序关系是否合理进行判断.这种机器学习方法的训练过程和::训练目标是判断任意两个文档组成的文档对&lt;D0C1，D0C2&gt;是否满足顺序关系，即判断是否D0C1应该排在DOC2的前面::<br><img src="/2018/01/15/Learning To Rank/1347947868_9185.jpg" alt=""><br>具体的学习方法有很多，比如SVM Rank. Boosts、神经网络等都可以作为具体的学习方法</p>
<p>这个方法问题是:<br>文档对方法只考虑了两个文档对的相对先后顺序，却没有考虑文档出现在搜索列表中的位置，排在搜索站果前列的文档更为重要，如果前列文档出现判断错误，代价明显高于排在后面的文档。</p>
<h4 id="ListWise"><a href="#ListWise" class="headerlink" title="ListWise"></a>ListWise</h4><p>文档列表方法与上述两种表示方式不同，是将::每一个查询对应的所有搜索结果列表整体作为一个训练实例::</p>
<p><img src="/2018/01/15/Learning To Rank/1347949724_3710.jpg" alt=""></p>
<p>我们假设搜索结果集合包含A. B 和C 3个文档，搜索引擎要对搜索结果排序，而这3个文档的顺序共有6种排列组合方式:</p>
<blockquote>
<p> ABC, ACB, BAG, BCA, CAB和CBA,<br>对于某个评分函数F来说，对3个搜索结果文档的相关性打分，得到3个不同的相关度得分F(A)、 F(B)和F(C)， 根据这3个得分就可以::计算6种排列组合情况各自的概率值::。 不同的评分函数，其6种搜索结果排列组合的概率分布是不一样的。</p>
</blockquote>
<p>上图展示了一个具体的训练实例，即査询Q1及其对应的3个文档的得分情况，这个得分可以看做是标准答案。可以<strong>设想</strong>存在一个最优的评分函数g，对查询Q1来说，其打分结果是：A文档得6分，B文档得4分，C文档得3分，因为得分是人工打的，所以具体这个函数g是怎样的我们不清楚，我们的任务就是<strong>找到一个函数，使得函数对Q的搜索结果打分顺序和g()打分顺序尽可能相同</strong>。<br>既然人工打分 (虚拟的函数g) 已知，那么我们可以计算函数g对应的搜索结果排列组合概率分布，其具体分布情况如图中间的概率分布所示。<br>假设存在两个其他函数h和f，它们的计算方法已知，对应的对3个搜索结果的打分在图上可以看到，由打分结果也可以推出每个函数对应的搜索结果排列组合概率分布，那么h与f哪个与虚拟的最优评分函数g更接近呢？一般可以用两个分布概率之间的距离远近来度量相似性，::KL距离就是一种衡量概率分布差异大小的计算工具::，通过分别计算h与g的差异大小及f与g的差异大小，可以看出f比h更接近的最优函数g，那么在这个函数中，我们应该优先选f作为将来搜索可用的评分函数，::训练过程就是在可能的函数中寻找最接近虚拟最优函数g的那个函数作为训练结果，将来作为在搜索时的评分函数::。<br>上述例子只是描述了对于单个训练实例如何通过训练找到最优函数，事实上我们有K 个训练实例，虽然如此，其训练过程与上述说明是类似的，::可以认为存在一个虚拟的最优 评分函数g (实际上是人工打分），训练过程就是在所有训练实例基础上，探寻所有可能的 候选函数，从中选择那个KL距离最接近于函数g的，以此作为实际使用的评分函数::。 经验结果表明，基于文档列表方法的机器学习排序效果要好于前述两种方法。</p>
<p>包含::LambdaMART::,RankNet, LambdaRank等方法</p>
<h4 id="L2R效果评价"><a href="#L2R效果评价" class="headerlink" title="L2R效果评价"></a>L2R效果评价</h4><ol>
<li>WTA(Winners take all) 对于给定的查询q，如果模型返回的结果列表中，第一个文档是相关的，则WTA(q)=1，否则为0.</li>
<li>MRR(Mean Reciprocal Rank) 对于给定查询q，如果第一个相关的文档的位置是R(q)，则MRR(q)=1/R(q)。</li>
<li>MAP(Mean Average Precision) 对于每个真实相关的文档d，考虑其在模型排序结果中的位置P(d)，统计该位置之前的文档集合的分类准确率，取所有这些准确率的平均值。</li>
<li>NDCG(Normalized Discounted Cumulative Gain) 是一种综合考虑模型排序结果和真实序列之间的关系的一种指标，也是最常用的衡量排序结果的指标，详见Wikipedia。</li>
<li>RC(Rank Correlation) 使用相关度来衡量排序结果和真实序列之间的相似度，常用的指标是Kendall’s Tau。 </li>
</ol>
<ol>
<li><a href="http://blog.csdn.net/eastmount/article/details/42367515" target="_blank" rel="noopener">机器学习排序之Learning to Rank简单介绍 - 杨秀璋的专栏 - CSDN博客</a></li>
<li><a href="l2rrecysystutaly-final-131012040539-phpapp01.pdf">l2rrecysystutaly-final-131012040539-phpapp01.pdf</a>…LTR 4 RS</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/15/GDBT学习/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="PW">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PW's notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/15/GDBT学习/" itemprop="url">未命名</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-15T19:05:15+08:00">
                2018-01-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="GDBT学习"><a href="#GDBT学习" class="headerlink" title="GDBT学习"></a>GDBT学习</h1><p>#推荐引擎/论文</p>
<p>这篇笔记里学习的步骤是:</p>
<ul>
<li>普通决策树的构建算法</li>
<li>回归树CART</li>
<li>Boosting</li>
<li>Gradient Boosting Tree</li>
<li>Spark GBDT demo.</li>
</ul>
<p>网上摘的一些参考资料: [[决策树]]</p>
<h2 id="普通决策树的构建算法"><a href="#普通决策树的构建算法" class="headerlink" title="普通决策树的构建算法"></a>普通决策树的构建算法</h2><hr>
<p><img src="/2018/01/15/GDBT学习/C9B45B5E-B3C2-40FE-8EB8-AEACF7F2689B.png" alt=""><br>这是一个自上而下的<strong>递归的过程</strong>,递归返回的条件有三个</p>
<ul>
<li>当前节点包含的样本都是同一类别,无需划分</li>
<li>当前属性集为空,或样本在属性集上取值相同,无法划分</li>
<li>当前节点包含的样本集合为空,不能划分</li>
</ul>
<p>用图解释一下:<br><img src="/2018/01/15/GDBT学习/IMG_8237.JPG" alt=""></p>
<p>然后就是如何选择<strong>最佳划分</strong>了.一般而言，随着划分过程不断进行，我们希望决策树的分支结点所包含的样 本尽可能属于同一类别，即结点的”<strong>纯度</strong>“ (purity)越来越高…</p>
<p>信息熵就是首先假设集合样本共有k类(2分类那就是k==2),然后:…<br><img src="/2018/01/15/GDBT学习/63538259-CD5B-4A01-887D-9631A119B089.png" alt=""><br>可知,信息熵越小,D的”<strong>纯度</strong>”越高,所以我们选择信息熵最小的划分,具体做法是<strong>对各种属性划分计算信息增益:</strong><br><img src="/2018/01/15/GDBT学习/A9B4CF3A-E018-4DD5-90B4-05A275AC19BE.png" alt=""><br>公式可以看出,∑项的信息熵越小,那么Gain就会越大,于是<strong>选择使得Gain最大的属性a</strong>作为最佳划分.</p>
<p>当然,，信息增益准则对可取值数目较多的属性有所偏好(<strong>取值多,划分后每个子集中样本可能就越少,越纯..)</strong>，为减少这种偏好可能带来的不利影响，著名的 C4.5 决策树算法不直接使 用信息增益，而是使用”增益率” (gain ratio) 来选择最优划分属性,定义如下:<br><img src="/2018/01/15/GDBT学习/6F28C98D-4CBD-4CB9-BCFA-456D010F1340.png" alt=""><br>可以看出,对IV(a),这是属性a的固有值,属性a可能取的数目越多,那么IV(a)的值一般就越大,可以降低取值数太多的影响.</p>
<p><strong>CART(回归树)</strong>使用<strong>基尼系数</strong>来选择划分属性,这也是为了度量<strong>数据集D的纯度</strong><br><img src="/2018/01/15/GDBT学习/707D8064-558F-4EE6-9B1B-5F2330ECFA10.png" alt=""><br>直观来说， Gini(D) <strong>反映了从数据集 D 中随机抽取两个样本，其类别标记不一致的概率.因此， Gini(D) 越小，则数据集 D 的纯度越高</strong>.那么我们就对各种属性a的划分计算其<strong>基尼系数</strong><br><img src="/2018/01/15/GDBT学习/8D94B1BA-07EC-4AEF-91B1-C7E4E8E234F4.png" alt=""><br>选择划分时选择使得Geni_index最小的a即可.</p>
<h4 id="决策树的连续值与缺失值处理"><a href="#决策树的连续值与缺失值处理" class="headerlink" title="决策树的连续值与缺失值处理"></a>决策树的连续值与缺失值处理</h4><p>由于连续属性的可取值数目不再有限， 因 此，不能直接根据连续属性的可能取值来对结点进行划分.此时<strong>连续属性离散化</strong>技术可派上用场. 最简单的策略是<strong>采用二分法(bi-partition)对连续属性进行处理</strong>.<br>缺失值是值样本在有些attribute上没有取值的情况.<br>详细做法先不说明了.</p>
<h2 id="回归树CART"><a href="#回归树CART" class="headerlink" title="回归树CART"></a>回归树CART</h2><hr>
<p>from&lt;&lt;统计学习方法&gt;&gt;</p>
<p>之前的切分,属性有多少种取值就划分多少个枝子,一旦按某特征切分后，该特征在之后的算法执行过程中将不会再起作用，所以所以有观点认为这种切分方式过于迅速。另外一种方法是<strong>二元切分法</strong>，即每次把数据集切成两份。<strong>如果数据的某特征值等于切分所要求的值，那么这些数据就进入树的左子树，反之则进入树的右子树</strong>。</p>
<p>之前的算法还只能把连续特征转换为离散型特征才能处理(ID3),而<strong>CART算法使用二元切分来处理连续型变量。对CART稍作修改就可以处理回归问题</strong>。CART决策树使用“基尼指数”来选择划分属性，基尼值是用来度量数据集的纯度。</p>
<p>CART同样由三个技术点:特征选择,树的生成,树的剪枝组成.得到的是<strong>给定X特征条件下输出变量Y的条件概率分布.</strong></p>
<p>算法分为两步</p>
<ol>
<li>生成树,要生成<strong>尽量大</strong>的树.</li>
<li>使用min{loss function}来对树进行剪枝.</li>
</ol>
<h4 id="生成"><a href="#生成" class="headerlink" title="生成"></a>生成</h4><p>树的生成过程中,对回归树使用MSE最小化,对分类树使用GeniIndex最小化准则,进行特征选择,生成二叉树.</p>
<p>对<strong>回归树</strong>,当划分都确定之后,使用<img src="/2018/01/15/GDBT学习/FF9620BB-9B38-4C0C-B6A0-849D4F627402.png" alt="">表示回归树对训练数据的预测误差,并且最小化这个来::求解每个节点上的输出值::,实际上,对于划分好的子节点,子节点Rm上的最优取值cm就是Rm上所有样本对应y的<strong>均值</strong></p>
<p>那么,如何划分呢? 若给定j和s,那么就可以定义左边和右边区域:<br><img src="/2018/01/15/GDBT学习/C4C034BB-6BEB-4782-B6F7-E965391384B5.png" alt=""><br>寻找最佳切分特征j和最佳切分点s的方法是求解下式:<br><img src="/2018/01/15/GDBT学习/B6BCD192-89E4-4C63-BCF4-EAF1EE0A0977.png" alt=""><br>步骤是,首先<strong>固定一个特征j</strong>(假设我们要按特征j进行划分),在此条件下,<strong>定一个j的切分点s</strong>,于是就得到左边区域和右边区域,并可知两个区域的值c1,c2…也就是说,<strong>一个s取值就对应了一对(c1,c2)</strong>.然后,使得上式[]中最小的s,就是<strong>最优的切分点s</strong>…进而,<strong>遍历所有j</strong>,就得到了<strong>最佳(j,s)对</strong>…<br>当然,由于s是连续的,我们也不能看清所有的s,我们就<strong>选择样本里出现过的s进行探究</strong>就好了.这也叫<strong>最小二乘回归树</strong></p>
<p>对分类树采用基尼系数进行划分,之前说过就不再说了,就是要注意这里是二叉树,你只能依据划分点把数据划分为2份然后计算基尼系数.实际问题里,就看你的取值是连续还是离散了…</p>
<p><strong>剪枝</strong>就不详细说了.</p>
<h2 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h2><hr>
<p>也就是<strong>集成学习</strong>.<br><img src="/2018/01/15/GDBT学习/36DAA479-56E5-42A7-906D-43505C58068B.png" alt=""><br>集成学习通过将多个学习器进行结合,常可获得比单一学习器显著优越的泛化性能.这对<strong>“弱学习器”</strong>(弱学习器常指繁华性能略优于随机猜测的学习器，例如在二分类问题上精度咯高于 50% 的分类器目)</p>
<p>在一般情况下,好的坏的混合,一般结果就比最好的要差一点,但是我们需要的是<strong>比任何单一学习器效果都好</strong>.要获得好的集成，个体学习器应”好而不同”,就是都需要有<strong>一定准确性</strong>,并且有一定<strong>差异性</strong>.(虽然这有点冲突)</p>
<p>根据个体学习器的生成方式，目前的集成学习方法大致可分为两大类.</p>
<ol>
<li>个体学习器问存在<strong>强依赖关系</strong>、必须<strong>串行生成</strong>的序列化方法.(::Boosting::)</li>
<li>以及个体学习器间不存在强依赖关系、可同时生成的并行化方法(Bagging 和”随机森林” )</li>
</ol>
<p><strong>Boosting</strong> 是一族可将弱学习器提升为强学习器的算法.这族算法的工作机制类似:先从初始训练集训练出<strong>一个基学习器</strong>，再根据基学习器的表现<strong>对训练样本分布进行调整</strong>，使得先前基学习器<strong>做错的训练样本在后续受到更多关注</strong>， 然后<strong>基于调整后的样本分布来训练下一个基学习器</strong>; 如此重复进行，直至基学习器数目达到事先指定的值 T,最终将这T个基学习器进行<strong>加权结合</strong>.<br>Boosting 主要关注降低<strong>偏差</strong>，</p>
<p>下面简单以AdaBoost为例介绍一下.任务就是一个二分类任务{-1,+1}.<br><img src="/2018/01/15/GDBT学习/F98833DD-65AA-4BBF-81C0-60C7960DC07F.png" alt=""></p>
<ol>
<li>初始化最开始的分布D1(x)=1/m,也就是个multinoulli分布.</li>
<li>对训练轮数t<ol>
<li>使用基本分类器E来对样本D以数据分布Dt(x)来进行训练(数据分布Dt的含义是样本被用来训练的概率)</li>
<li>计算基分类器的误差率e</li>
<li>如果误差率e大于0.5就break算了</li>
<li>求α(t),含义是<strong>指数化损失函数</strong>对误差e的偏导数=0为0时的”基分类器线性组合方法H”</li>
<li>根据α(t)调整数据分布,如7..</li>
</ol>
</li>
<li>迭代t次以后输出sign(H)就是我们二分类所需要的分类函数….</li>
</ol>
<h2 id="Gradient-Boosting-Tree-GBDT"><a href="#Gradient-Boosting-Tree-GBDT" class="headerlink" title="Gradient Boosting Tree(GBDT)"></a>Gradient Boosting Tree(GBDT)</h2><hr>
<h3 id="Review-of-key-concepts-of-supervised-learning"><a href="#Review-of-key-concepts-of-supervised-learning" class="headerlink" title="Review of key concepts of supervised learning"></a>Review of key concepts of supervised learning</h3><p>不如先回顾一下::监督学习::的几个概念. 首先,定义需要使用的<strong>数学符号</strong>:<br><img src="/2018/01/15/GDBT学习/EB5D7C33-C767-4FFE-812C-4384CBCEC2EB.png" alt=""></p>
<p>supervised learning都有目标函数,其<strong>目标函数</strong>可拆分为:<br><img src="/2018/01/15/GDBT学习/32A865C8-EDBE-4BFC-992B-B190117743E6.png" alt=""><br>其中::损失函数::的自变量是Loss(y,y^),即<strong>真实值y</strong>和<strong>预测值y^</strong>的函数,这相当于<strong>bias偏差</strong>,下面是两种常用的Loss<br><img src="/2018/01/15/GDBT学习/63B6C514-EA50-437B-9B1F-8260FEA22437.png" alt=""><br>(logistic loss可分为两部分,看做yi=1,h()(预测值)=0和yi=0,h()=1的情况相加)<br><a href="http://blog.csdn.net/bitcarmanlee/article/details/51165444" target="_blank" rel="noopener">logistic回归详解(二）：损失函数（cost function）详解 - bitcarmanlee的博客 - CSDN博客</a><br>::正则项::就是跟参数w有关了,我们希望<strong>参数小(L2)</strong>或者<strong>少(L1)</strong>(<strong>相当于variance方差</strong>),下面是两种正则项:<br><img src="/2018/01/15/GDBT学习/42EB54CC-231C-45A8-8E4B-0741D0822F19.png" alt=""></p>
<p>代入使用的loss function和正则项,几个<strong>常见的回归的优化目标函数</strong>是:<br><img src="/2018/01/15/GDBT学习/6D6563FE-3C16-45C8-A71C-B7C73C73D133.png" alt=""></p>
<h3 id="Regression-Tree-and-Ensemble-What-are-we-Learning"><a href="#Regression-Tree-and-Ensemble-What-are-we-Learning" class="headerlink" title="Regression Tree and Ensemble (What are we Learning)"></a>Regression Tree and Ensemble (What are we Learning)</h3><p>一颗回归树做emsemble,就像下面这样,每棵树倒都是<strong>使用了所有训练instance</strong>.<br><img src="/2018/01/15/GDBT学习/6154D156-3015-4F2E-AE2D-AA791DC59868.png" alt=""><br>Why ensemble trees?</p>
<ol>
<li>和输入的数字规模无关,所以不需要特别注意的<strong>features normalization</strong>(将特征向量的每一维映射为均值为0,方差为1)</li>
<li>可以学习到特征间的<strong>高阶交互关系</strong></li>
<li>scalable,工业中好用.</li>
</ol>
<p>进入<strong>数学</strong>,假设我们有<strong>K</strong>棵树,于是对样本i的预测值y^i就是<br><img src="/2018/01/15/GDBT学习/31610517-F485-4A89-A746-705B2396B00D.png" alt=""><br>如果我们把每棵树的输出函数fk()看做参数,我们现在就是需要<strong>学习函数</strong>(而不是参数)</p>
<p>那我们如何定义emsemble tree目标函数呢?<br><img src="/2018/01/15/GDBT学习/CD967556-0D48-4DEC-B861-9D13DAC97BC4.png" alt=""><br>那么把正则化项定义为什么?树中节点数?L2 of leaf weights?…..</p>
<p>对决策树而言,经常都是<strong>启发式</strong>的,而非Objective…</p>
<ul>
<li>信息增益—&gt;损失 L()</li>
<li>剪枝—&gt;正则化by nodes</li>
<li>规定Max depth—&gt;constraint on the function space</li>
<li>Smoothing leaf values—&gt;L2 regulation on <em>leaf weights</em>.</li>
<li>回归树其实还可以做,分类,,回归,,Ranking…都可以.</li>
</ul>
<h3 id="Gradient-Boosting-How-do-we-Learn"><a href="#Gradient-Boosting-How-do-we-Learn" class="headerlink" title="Gradient Boosting (How do we Learn)"></a>Gradient Boosting (How do we Learn)</h3><p>现在已经介绍了我们要学什么模型,下面介绍如何学习模型,那就是::梯度提升::了.</p>
<p>对于上一小节介绍的目标函数,我们既然没有办法通过像SGD这样的方法去优化目标函数(寻找每一个f,因为他们是树,而不是一般向量)…于是我们使用additive training. 其中<img src="/2018/01/15/GDBT学习/767C8C2D-7A52-4484-815F-6423B3102621.png" alt="">表示<strong>训练t轮后,model对样本i的预测值</strong>,<strong>ft()表示第t轮的树</strong><br><img src="/2018/01/15/GDBT学习/3D694F1D-C0BB-475B-82B9-66435D2E2E8F.png" alt=""></p>
<p>由于在第t轮时有<br><img src="/2018/01/15/GDBT学习/F25F7812-7CF1-43AC-899C-E6051A58974E.png" alt="">…….(1)<br>于是第t轮时,把(1)代入Loss(y,y^),于是Loss()可以写成<br><img src="/2018/01/15/GDBT学习/35A5F5EF-6543-4FCD-926A-7404CCA588EA.png" alt="">………(2)<br>如果采用<strong>square loss</strong>,代入(2),那么Loss()就是<br><img src="/2018/01/15/GDBT学习/5E2F365E-A2CB-4AF9-8C88-0ABD322D2456.png" alt="">………(3)<br>把平方展开,化简为:<br><img src="/2018/01/15/GDBT学习/91786C01-6306-4479-BDA5-126BC60FD363.png" alt="">……(4)<br>甚至不用展开,可以化简为,<br><img src="/2018/01/15/GDBT学习/IMG_9712_500x222.JPG" alt="">……..(5)<br>注意到,(4)的椭圆圈圈里,或者(5)中的r的不就是::残差::吗?<br>所以说,在第t轮的时候,如果想要Loss极小,只需要(r-ft)够小,所以我们下一轮的树ft要<strong>拟合</strong>(接近)上一棵树的残差r.</p>
<p>按照这种情况,从&lt;&lt;统计学习方法里&gt;&gt;,一般采用square loss的GBDT构建算法是<br><img src="/2018/01/15/GDBT学习/7BA219ED-0ABD-4CC7-A434-D694E47505EB.png" alt=""><br>其中T是第m轮得到的单树,算法很好理解,也好实施.</p>
<p><strong>::但是::,我们想把模型抽象化,不想限于某种Loss…</strong></p>
<p>回忆一下泰勒公式<br><img src="/2018/01/15/GDBT学习/D9333131-D6BB-4381-9212-FDA1E245FBC3.png" alt=""></p>
<p>如果不采用square loss,在一般情况下,利用::泰勒展开::,可以把下面<strong>目标函数</strong><br><img src="/2018/01/15/GDBT学习/8BEEFAEF-3AEF-4356-956F-D932D6A480A8.png" alt=""><br>中的Loss()给展开(f()就是l(),x是<img src="/2018/01/15/GDBT学习/B60E3761-2327-4ACF-90EB-6E32F7749322.png" alt="">,δx是<img src="/2018/01/15/GDBT学习/2AEB0BDD-C581-419B-A3B3-DD75BEAA76A9.png" alt="">),进而写成:<br><img src="/2018/01/15/GDBT学习/EF9C7C59-42F9-4644-8931-5C5F40B7D9D9.png" alt=""><br>其中包含符号::gi::和::hi::(i表示instance)</p>
<ul>
<li>gi=<img src="/2018/01/15/GDBT学习/2899D802-18DC-4FAF-863C-5EA7D531DDCA.png" alt="">,即<strong>第t-1轮的损失</strong>对<strong>t-1轮预测值</strong>的导数.</li>
<li>hi=<img src="/2018/01/15/GDBT学习/27544280-9A45-4893-9186-97D5E1817B68.png" alt="">是<strong>二阶导数</strong></li>
<li>这不太好理解,那么,如果像上面采用square loss, 就有gi=2r,hi=2…</li>
</ul>
<p>最终,移除常数项,<strong>第t轮的优化目标函数</strong>就是<br><img src="/2018/01/15/GDBT学习/41F8ABFC-1B4A-4505-912C-ADFC5A417D68.png" alt=""><br>::只依赖于每个数据点的在误差函数上的一阶导数和二阶导数::</p>
<p><strong>::现在::,做好了转化,就让我们看看如何解这玩意儿.</strong></p>
<p><strong>首先</strong>,我们可以把回归树重新定义为两部分</p>
<ol>
<li>叶子节点的值组成的<strong>vector w</strong></li>
<li><strong>mapping function q()</strong>以把instance map到leaf, q(x)=j表示x实例落在了j号叶子上,进而,w(q(x))就表示x实例在树上的预测值,也就等于ft(xi).</li>
</ol>
<p><strong>其次</strong>,我们可以把一棵树的<strong>复杂度</strong>定义为:<br><img src="/2018/01/15/GDBT学习/1AF20DA0-BD85-4481-AD50-48F5727A7470.png" alt=""><br>其中包含两个常数,也就是说复杂度和<strong>叶子数T</strong>和<strong>叶子值w之和</strong>有关.可以用作<strong>正则化项</strong></p>
<p><strong>再者</strong>,把leaf j上的<strong>实例集合</strong>(Instance set)定义为<strong>Ij</strong><br><img src="/2018/01/15/GDBT学习/36CF82C0-E45B-434B-8453-E5221D3DA821.png" alt=""></p>
<p>我们之前的目标函数是按每个样本来∑,代入以上三点符号定义,我们按<strong>叶子</strong>重新group一下,把objective写成<br><img src="/2018/01/15/GDBT学习/5574071C-DAB4-4DCC-B4C3-9D48528EDB6C.png" alt=""><br><strong>This is sum of T independent quadratic functions,都是wj的二次函数</strong>,可以看到,只要叶子节点上的值取某些值,损失就能最小化,所以我们现在可以探究::叶子上的值到底怎么取::</p>
<p>我们发现,优化目标函数变成了一个<strong>二次函数的优化问题</strong>,二次函数的最值中学学过:<br><img src="/2018/01/15/GDBT学习/93578A52-E56A-4CC5-9B8C-B62AD8A23E9C.png" alt=""><br>若定义<br><img src="/2018/01/15/GDBT学习/53FD1ED6-0A1E-44C1-9388-E4F8442E3230.png" alt=""><br>那么优化目标函数可化简为:<br><img src="/2018/01/15/GDBT学习/86863016-EBD9-42B0-B9EB-7EBA93CC96B7.png" alt=""><br>于是目标函数是关于<strong>wj的二次函数</strong>,wj就是每个叶子的值</p>
<p>当树的结构structure q()已经确定,.于是按二次函数解法可以知道,在这个structure下最优的wj以及目标函数值就是:<br><img src="/2018/01/15/GDBT学习/04C4B4D6-F8C6-4195-A86F-C051EB1B56BD.png" alt=""><br>上图中<em>measure how good a structure is</em>就称为::structure score::,当然越小越好.<br><img src="/2018/01/15/GDBT学习/6A2D980E-935A-4A93-BD7F-13427B5A97BC.png" alt=""><br>::这样,由于Gj,和Hj(j代表leaf号)都是可以由上一轮的数据来计算,目标函数就解出来了.::</p>
<p>::现在已经知道如何优化第t轮目标函数了,下面依次来<strong>构建第t轮的一棵树</strong>::<br>下面的方法是<strong>正确</strong>的:</p>
<ol>
<li>穷举所有可能的structure q.</li>
<li>计算structure的structure score.</li>
<li>找到最佳的structure,然后叶子上的值取optimal leaf weight<br><img src="/2018/01/15/GDBT学习/4A3C74B2-427E-485D-831B-A33512DC32AA.png" alt=""></li>
</ol>
<ul>
<li>但是….穷举tree structure,这不太好吧…</li>
</ul>
<p>所以实操中,采用一种::贪心算法::来<strong>高效地</strong>learn the tree.</p>
<ol>
<li>从树的深度0开始.</li>
<li>从上至下,为叶子找最佳的split…然后可以计算这样split的增益<br><img src="/2018/01/15/GDBT学习/82C503A0-1A3A-45D1-AAE0-80E398975436.png" alt=""></li>
</ol>
<ul>
<li>那么,如何操作(2)这一步呢?<br>比如说我们要在年龄上选择划分xj&lt;a,(xj is age),那么<ol>
<li>首先把instance按年龄从左到右排序<br><img src="/2018/01/15/GDBT学习/AA63EBF1-6916-4C6C-9805-56F4193C6848.png" alt=""></li>
<li>然后从左到右扫描来插a点,没每个a点计算Gain,这就足够了..</li>
</ol>
</li>
</ul>
<p><strong>时间复杂度</strong>上,这样来产生一颗深度为k的树,有:<br><img src="/2018/01/15/GDBT学习/FC4CAB04-0231-4217-A0C9-68CC242EEB71.png" alt=""><br>其中nlogn是为instance排序的时间,然后d是feature个数,所以每一层需要dnlogn时间来确定,再加上我们需要k层,所以总时间为O(n d K logn)</p>
<p>对于<strong>离散值</strong>,我们也可以用之前的scoring fomula来计算score of a split based on categorical vatiables. 使用one-hot编码也可以.</p>
<p>对<strong>剪枝和正则化</strong>而言,当我们按下面公式寻找最佳split,找到的最佳gain<strong>可能会是负数</strong>……增益还负了,这肯定不好<br><img src="/2018/01/15/GDBT学习/8DE8536F-9DF6-4A19-B0C8-626B895330A2.png" alt=""><br>对此,有两种解决策略</p>
<ul>
<li><strong>Pre-stopping</strong>,当最佳split的gain为负的时候停止,但这样的split可能对以后的split是有好处的呢?</li>
<li><strong>Post-Prunning</strong>,生成到depth K,然后recursively prune all the leaf splits with negative gain.</li>
</ul>
<p>::现在已经知道如何构建第t轮的树了,那么可导出总的Boosted Tree Algorithm算法::</p>
<ol>
<li>每次循环加一颗新树</li>
<li>为每个instance计算(导数/梯度)gi,和hi,这只跟样本的真实值和上一轮的预测值有关,可以计算</li>
<li>使用(2)的数据来<strong>贪心地生成</strong>一颗树ft(x)</li>
<li>把这棵树加入到总的model:<br><img src="/2018/01/15/GDBT学习/AF2D790B-3DDE-4E87-92B5-B34BE7D88628.png" alt=""><br>e是常数,设置为0.1左右,称为步长….(This means we do not do full optimization in each step and reserve chance for future rounds, it helps prevent overfitting)</li>
</ol>
<h2 id="Spark-GBDT"><a href="#Spark-GBDT" class="headerlink" title="Spark GBDT"></a>Spark GBDT</h2><p>已经在本地运行了mllib里的GBDT例子,包括分类和回归,见代码即可.</p>
<p>另外,xgboost也提供了Spark支持,下面给几个链接说明xgboost怎么在spark上使用(scala)</p>
<ol>
<li><a href="https://github.com/dmlc/xgboost/tree/master/jvm-packages" target="_blank" rel="noopener">xgboost4j</a></li>
<li><a href="http://www.elenacuoco.com/2016/10/10/scala-spark-xgboost-classification/" target="_blank" rel="noopener">Spark And XGBoost using Scala</a></li>
<li><a href="https://www.qubole.com/blog/machine-learning-xgboost-qubole-spark-cluster/" target="_blank" rel="noopener">Machine Learning with XGBoost on Qubole Spark Cluster</a></li>
</ol>
<p><strong>交叉熵是衡量两个概率分布之间的差别的 越小则两个概率分布越相近 所以像逻辑回归这种输出概率的问题 采用交叉熵作为损失就能让训练去逼近训练集上代表的分布</strong></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/15/决策树/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="PW">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PW's notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/15/决策树/" itemprop="url">未命名</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-15T18:21:21+08:00">
                2018-01-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><p>#推荐引擎/论文</p>
<p>GBDT(Gradient Boosting Decision Tree) 又叫 MART（Multiple Additive Regression Tree)，是一种迭代的决策树算法，该算法由多棵决策树组成，所有树的结论累加起来做最终答案。它在被提出之初就和SVM一起被认为是泛化能力较强的算法。</p>
<p>GBDT是一种<strong>回归树</strong></p>
<p>GBDT的思想使其具有天然优势可以发现多种有区分性的特征以及特征组合。业界中，Facebook使用其来<strong>自动发现有效的特征、特征组合</strong>，来作为LR模型中的特征，以提高 CTR预估（Click-Through Rate Prediction）的准确性.</p>
<h2 id="Regression-Decision-Tree：回归树"><a href="#Regression-Decision-Tree：回归树" class="headerlink" title="Regression Decision Tree：回归树"></a>Regression Decision Tree：回归树</h2><hr>
<p>回归树总体流程类似于分类树，区别在于，<strong>回归树的每一个节点都会得一个预测值</strong>，以年龄为例，该预测值等于属于这个节点的所有人年龄的平均值。分枝时穷举每一个feature的每个阈值找最好的分割点，但<strong>衡量最好的标准不再是最大熵，而是最小化平方误差</strong>。也就是被预测出错的人数越多，错的越离谱，平方误差就越大，通过最小化平方误差能够找到最可靠的分枝依据。分枝直到每个叶子节点上人的年龄都唯一或者达到预设的终止条件(如叶子个数上限)，若最终叶子节点上人的年龄不唯一，则以该节点上所有人的平均年龄做为该叶子节点的预测年龄.</p>
<p><img src="/2018/01/15/决策树/B04B16CD-E09A-43E7-B999-D4E7A1F055E3.png" alt=""></p>
<h2 id="Boosting-Decision-Tree：提升决策树"><a href="#Boosting-Decision-Tree：提升决策树" class="headerlink" title="Boosting Decision Tree：提升决策树"></a>Boosting Decision Tree：提升决策树</h2><hr>
<p>提升树是迭代多棵回归树来共同决策。当采用平方误差损失函数时，<strong>每一棵回归树学习的是之前所有树的结论和残差，拟合得到一个当前的残差回归树</strong>，<strong>残差的意义如公式：残差 = 真实值 - 预测值</strong> 。提升树即是整个迭代过程生成的回归树的累加。</p>
<p>训练一个提升树模型来预测年龄. 训练集是4个人，A，B，C，D年龄分别是14，16，24，26。样本中有购物金额、上网时长、经常到百度知道提问等特征。提升树的过程如下：<br><img src="/2018/01/15/决策树/446468CF-EDCB-4FC8-9611-DED542E7C9CD.png" alt=""><br>那么你要预测年龄的话,对A(age14)来说,其购物金额&lt;1k,于是对第一颗树,预测值是15,然后对第二颗树,其不经常提问,所以预测值是-1…所以,<strong>预测值等于所有树值得累加</strong>,于是age(A)=14.</p>
<p>所以做提升树的过程是.<br><img src="/2018/01/15/决策树/967544-4e70966cd8a4cdf9.png" alt=""><br>fi(x)代表前i棵决策树对样本x的预测值. 于是,(2)解释为,计算样本y值与前m-1棵树预测值的残差,然后拟合残差得到第m个决策树,<strong>然后,更新前m棵决策树对x的总预测值.</strong></p>
<p>为什么要使用Boosting Tree? 答案是<strong>过拟合</strong>。过拟合是指为了让训练集精度更高，学到了很多”仅在训练集上成立的规律“，导致换一个数据集当前规律就不适用了(模型的方差更大)。也就是说,单一决策树可能要用到更多的feature,而boosting树一般分支涵括的feature更少,(模型更简单一点就不会那么过拟合).</p>
<p> Boosting的最大好处在于，每一步的残差计算其实变相地增大了分错instance的权重，而已经分对的instance则都趋向于0。这样后面的树就能越来越专注那些前面被分错的instance。</p>
<h2 id="GBDT-梯度提升决策树"><a href="#GBDT-梯度提升决策树" class="headerlink" title="GBDT 梯度提升决策树"></a>GBDT 梯度提升决策树</h2><hr>
<p>梯度肯定是相对于损失函数而言的,使用不同的损失函数,其对自变量的梯度不同,以下给出几个常用的.<br><img src="/2018/01/15/决策树/967544-1502996028c98f08.png" alt=""><br>可以看见,如果使用<strong>MSE</strong>作为loss function,其对输入f(xi)的梯度就是<strong>残差</strong></p>
<p>但对于一般的损失函数，往往每一步优化没那么容易，如上图中的绝对值损失函数和Huber损失函数。针对这一问题，Freidman提出了梯度提升算法：利用最速下降的近似方法，即利用损失函数的负梯度在当前模型的值，作为回归问题中提升树算法的残差的近似值，拟合一个回归树<br><img src="/2018/01/15/决策树/967544-37a15b71dc6f6ca3.png" alt=""></p>
<ol>
<li>初始化，估计使损失函数极小化的常数值，它是只有一个根节点的树，即ganma是一个常数值。</li>
<li><ol>
<li>计算损失函数的负梯度在当前模型的值，将它作为残差的估计</li>
<li>估计回归树叶节点区域，以拟合残差的近似值</li>
<li>利用线性搜索估计叶节点区域的值，使损失函数极小化</li>
<li>更新回归树</li>
</ol>
</li>
<li>得到输出的最终模型 f(x)<br>….看不明白</li>
</ol>
<p>GBDT几乎可用于所有回归问题（线性/非线性），相对logistic regression仅能用于线性回归，GBDT的适用面非常广。亦可用于二分类问题（设定阈值，大于阈值为正例，反之为负例）。</p>
<h2 id="Tencent文章"><a href="#Tencent文章" class="headerlink" title="Tencent文章"></a>Tencent文章</h2><p>基于梯度提升算法的学习器叫做 GBM(Gradient Boosting Machine)。理论上，GBM 可以选择各种不同的学习算法作为基学习器。GBDT 实际上是 GBM 的一种情况。</p>
<p><strong>为什么梯度提升方法倾向于选择决策树作为基学习器呢？</strong>(也就是 GB 为什么要和 DT 结合，形成 GBDT) 决策树可以认为是 if-then 规则的集合，易于理解，可解释性强，预测速度快。同时，决策树算法相比于其他的算法需要更少的特征工程，比如可以不用做特征标准化，可以很好的处理字段缺失的数据，也可以不用关心特征间是否相互依赖等。决策树能够自动组合多个特征。</p>
<p>不过，单独使用决策树算法时，有容易过拟合缺点。所幸的是，通过各种方法，抑制决策树的复杂性，降低单颗决策树的拟合能力，再通过梯度提升的方法集成多个决策树，最终能够很好的解决过拟合的问题。由此可见，梯度提升方法和决策树学习算法可以互相取长补短，是一对完美的搭档。</p>
<p>至于抑制单颗决策树的复杂度的方法有很多，比如限制树的最大深度、限制叶子节点的最少样本数量、限制节点分裂时的最少样本数量等等….</p>
<p>GBDT 算法可以看成是由 K 棵树组成的加法模型：<br><img src="/2018/01/15/决策树/349DB282-6F49-4C36-85F2-0B6F0891E13F.png" alt=""></p>
<p>如何来学习加法模型呢？<br>解这一优化问题，可以用前向分布算法（forward stagewise algorithm）。因为学习的是加法模型，如果能够从前往后，每一步只学习一个基函数及其系数（结构），逐步逼近优化目标函数，那么就可以简化复杂度。这一学习过程称之为 Boosting。具体地，我们从一个常量预测开始，每次学习一个新的函数，过程如下：</p>
<p><img src="/2018/01/15/决策树/F8686924-1A85-43BB-8B24-1E73136164D7.png" alt=""><br>因此，<strong>使用平方损失函数时，GBDT 算法的每一步在生成决策树时只需要拟合前面的模型的残差。</strong></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">PW</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">69</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">PW</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
