<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="Bayesian personalized ranking from implicit feedback#推荐引擎/论文 总是就是最后得出了一个基于底层模型的优化模型,基于这个优化模型来训练底层模型的参数,然后还是用底层的模型的perdiction rule来计算推荐,得出的结果就更符合ranking的情况. 隐式数据上,根据 看过&amp;gt;没看过 来构造pairwise数据. ABSTRACT 这">
<meta property="og:type" content="article">
<meta property="og:title" content="PW&#39;s notes">
<meta property="og:url" content="http://yoursite.com/2018/01/25/Bayesian personalized ranking from implicit feedback 1/index.html">
<meta property="og:site_name" content="PW&#39;s notes">
<meta property="og:description" content="Bayesian personalized ranking from implicit feedback#推荐引擎/论文 总是就是最后得出了一个基于底层模型的优化模型,基于这个优化模型来训练底层模型的参数,然后还是用底层的模型的perdiction rule来计算推荐,得出的结果就更符合ranking的情况. 隐式数据上,根据 看过&amp;gt;没看过 来构造pairwise数据. ABSTRACT 这">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoursite.com/2018/01/25/Bayesian%20personalized%20ranking%20from%20implicit%20feedback%201/FA4B75A5-9F78-4427-89FA-9C13253DD1E5.png">
<meta property="og:image" content="http://yoursite.com/2018/01/25/Bayesian%20personalized%20ranking%20from%20implicit%20feedback%201/91C702AB-B5C2-456D-860F-7E1B95C5998A.png">
<meta property="og:image" content="http://yoursite.com/2018/01/25/Bayesian%20personalized%20ranking%20from%20implicit%20feedback%201/73979333-68C0-43B7-BA5E-60EBE64ECFCD.png">
<meta property="og:image" content="http://yoursite.com/2018/01/25/Bayesian%20personalized%20ranking%20from%20implicit%20feedback%201/A5B9E3EA-FA8A-4122-86C2-DC79D79D840A.png">
<meta property="og:image" content="http://yoursite.com/2018/01/25/Bayesian%20personalized%20ranking%20from%20implicit%20feedback%201/ADF7D548-3473-4F68-80AF-92555D3CDD35.png">
<meta property="og:image" content="http://yoursite.com/2018/01/25/Bayesian%20personalized%20ranking%20from%20implicit%20feedback%201/85AC32E9-A5C8-4B8A-B06F-DED03B070D8A.png">
<meta property="og:image" content="http://yoursite.com/2018/01/25/Bayesian%20personalized%20ranking%20from%20implicit%20feedback%201/DBA955C0-1D2E-4A66-BD82-B024DE3EF4F5.png">
<meta property="og:image" content="http://yoursite.com/2018/01/25/Bayesian%20personalized%20ranking%20from%20implicit%20feedback%201/B732FAA5-DDE2-4BB5-8590-C148E42F0DB5.png">
<meta property="og:image" content="http://yoursite.com/2018/01/25/Bayesian%20personalized%20ranking%20from%20implicit%20feedback%201/D781948F-82EA-4B68-9070-B3EF3EF8523B.png">
<meta property="og:image" content="http://yoursite.com/2018/01/25/Bayesian%20personalized%20ranking%20from%20implicit%20feedback%201/118E2BCA-00E3-47EB-9568-1A521133AF4D.png">
<meta property="og:image" content="http://yoursite.com/2018/01/25/Bayesian%20personalized%20ranking%20from%20implicit%20feedback%201/E7D90E3E-21AD-406C-980E-EC1E29171D1F.png">
<meta property="og:image" content="http://yoursite.com/2018/01/25/Bayesian%20personalized%20ranking%20from%20implicit%20feedback%201/60D62C44-8BB8-4E84-9007-FF620A5BA72E.png">
<meta property="og:image" content="http://yoursite.com/2018/01/25/Bayesian%20personalized%20ranking%20from%20implicit%20feedback%201/BA5DF0C6-4480-49D5-A714-DA1B783CB008.png">
<meta property="og:image" content="http://yoursite.com/2018/01/25/Bayesian%20personalized%20ranking%20from%20implicit%20feedback%201/9B9402C0-0412-4182-B1B8-A029C8CF85C2.png">
<meta property="og:image" content="http://yoursite.com/2018/01/25/Bayesian%20personalized%20ranking%20from%20implicit%20feedback%201/6DE206CC-5FAE-46C9-A774-0DCC1A97477C.png">
<meta property="og:image" content="http://yoursite.com/2018/01/25/Bayesian%20personalized%20ranking%20from%20implicit%20feedback%201/2D9DEB33-2A8D-4D61-9074-56902BF37C8C.png">
<meta property="og:image" content="http://yoursite.com/2018/01/25/Bayesian%20personalized%20ranking%20from%20implicit%20feedback%201/7E514964-282C-4276-8F5C-AFDABE888A3A.png">
<meta property="og:image" content="http://yoursite.com/2018/01/25/Bayesian%20personalized%20ranking%20from%20implicit%20feedback%201/1661373F-E76D-4761-9C25-5535260BDF99.png">
<meta property="og:image" content="http://yoursite.com/2018/01/25/Bayesian%20personalized%20ranking%20from%20implicit%20feedback%201/2F9496B6-D4BA-447F-AF31-ECC67D255A80.png">
<meta property="og:image" content="http://yoursite.com/2018/01/25/Bayesian%20personalized%20ranking%20from%20implicit%20feedback%201/EF77E2F2-BC6D-4881-9634-DF728B67B79D.png">
<meta property="og:image" content="http://yoursite.com/2018/01/25/Bayesian%20personalized%20ranking%20from%20implicit%20feedback%201/04FCFD29-17A4-4E09-9077-F09F4B706A08.png">
<meta property="og:image" content="http://yoursite.com/2018/01/25/Bayesian%20personalized%20ranking%20from%20implicit%20feedback%201/7F7655BA-5604-47F4-8336-41D657DB0B96.png">
<meta property="og:image" content="http://yoursite.com/2018/01/25/Bayesian%20personalized%20ranking%20from%20implicit%20feedback%201/C8ADC423-3CC0-49EA-BB2C-D94192F8ED01.png">
<meta property="og:image" content="http://yoursite.com/2018/01/25/Bayesian%20personalized%20ranking%20from%20implicit%20feedback%201/993102CD-8DF3-4EBF-AB09-67EF0301FE0E.png">
<meta property="og:image" content="http://yoursite.com/2018/01/25/Bayesian%20personalized%20ranking%20from%20implicit%20feedback%201/656F644F-2862-4A9D-A25B-D66F9A0707D2.png">
<meta property="og:image" content="http://yoursite.com/2018/01/25/Bayesian%20personalized%20ranking%20from%20implicit%20feedback%201/F9D93F2C-A55E-4306-82D2-63EADAB70A10.png">
<meta property="og:updated_time" content="2018-03-06T03:00:26.610Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="PW&#39;s notes">
<meta name="twitter:description" content="Bayesian personalized ranking from implicit feedback#推荐引擎/论文 总是就是最后得出了一个基于底层模型的优化模型,基于这个优化模型来训练底层模型的参数,然后还是用底层的模型的perdiction rule来计算推荐,得出的结果就更符合ranking的情况. 隐式数据上,根据 看过&amp;gt;没看过 来构造pairwise数据. ABSTRACT 这">
<meta name="twitter:image" content="http://yoursite.com/2018/01/25/Bayesian%20personalized%20ranking%20from%20implicit%20feedback%201/FA4B75A5-9F78-4427-89FA-9C13253DD1E5.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/01/25/Bayesian personalized ranking from implicit feedback 1/"/>





  <title> | PW's notes</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">PW's notes</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/25/Bayesian personalized ranking from implicit feedback 1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="PW">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PW's notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline"></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-25T19:04:42+08:00">
                2018-01-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="Bayesian-personalized-ranking-from-implicit-feedback"><a href="#Bayesian-personalized-ranking-from-implicit-feedback" class="headerlink" title="Bayesian personalized ranking from implicit feedback"></a>Bayesian personalized ranking from implicit feedback</h1><p>#推荐引擎/论文</p>
<p>总是就是最后得出了一个基于底层模型的优化模型,基于这个优化模型来训练底层模型的参数,然后还是用底层的模型的perdiction rule来计算推荐,得出的结果就更符合ranking的情况.</p>
<p>隐式数据上,根据 看过&gt;没看过 来构造pairwise数据.</p>
<h2 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><hr>
<p>这里把ranking任务称为item recommendation.本文研究隐式反馈(点击,购买),引出BPR-Opt问题,::从问题的贝叶斯分析得出的最大的后验概率估计量.::. 我们还提供了一个通用学习算法来优化BPR-Opt模型,该方法基于SGD和bootstrap sampling.可以把方法应用到MF和KNN.</p>
<h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><hr>
<p>项目推荐的任务是为一组项目创建用户特定的排名。本文的贡献有几点</p>
<ol>
<li>我们提出通用优化准则=&gt;BPR-Opt,以从最大后验估计估计得出的最佳personlized ranking。 我们展示了BPR-Opt的类似于以最大化ROC曲线下面积。</li>
<li>提出优化算法LearnBPR</li>
<li>提出了如何把LearnBPR运用到现有stateOfArt算法</li>
<li>实验表明,对ranking任务,性能比那些都要好</li>
</ol>
<h2 id="RELATED-WORK"><a href="#RELATED-WORK" class="headerlink" title="RELATED WORK"></a>RELATED WORK</h2><hr>
<p>那就是MF和KNN及其各种变种了.其缺点是::Even though all the work on item prediction discussed above is evaluated on personalized ranking datasets, none of these methods directly optimizes its model parameters for ranking.:: 本文的方法基于pairwise(user-speciﬁc order of two items),和一般LTR相比,我们的方法是personlized的.</p>
<h2 id="Personalized-Ranking"><a href="#Personalized-Ranking" class="headerlink" title="Personalized Ranking"></a>Personalized Ranking</h2><hr>
<p>注意,implicit只有正反馈.首先,<em>U</em>表示用户集,<em>I</em>表示物品集.<em>S</em>表示<em>U×I</em>.任务可以描述为产生一个personlized total ranking <img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/FA4B75A5-9F78-4427-89FA-9C13253DD1E5.png" alt="">,&gt;u满足下面的属性<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/91C702AB-B5C2-456D-860F-7E1B95C5998A.png" alt=""><br>意思也就是说,两物品不相等,则rank不相等;若rank相等则一定物品相等,若i排j前,j排k前,则i排k前.另外,使用<em>I+</em>和<em>U+</em>表示在S中有隐式反馈的物品或用户</p>
<p>经典的ranking方法还是学习一个recommendation score然后排下来.并且有反馈当1没反馈当0.本文认为,你把要预测的都当做了0,然后学习S,要不是因为正则,你学出来的模型的估计可能都会是0,那就毫无意义.<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/73979333-68C0-43B7-BA5E-60EBE64ECFCD.png" alt=""></p>
<p>本文基于pairwise,并假设</p>
<ul>
<li>若u看了i [(u,i)∈S],则假设u对i的喜欢比所有non-observed item要高</li>
<li>若都看了或都没看,则无法判断preference.<br>于是训练数据可表示为:<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/A5B9E3EA-FA8A-4122-86C2-DC79D79D840A.png" alt=""><br>其中i是看过的,j是没看过的.(不过就是每个user都有这么一个矩阵了)</li>
</ul>
<p>我们的方法好处就有我们把将来要预测的任务(两个没看过物品的排序)没当做负例,而是missing的,于是这::保证了训练数据和测试数据是不相交的::<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/ADF7D548-3473-4F68-80AF-92555D3CDD35.png" alt=""></p>
<h2 id="BPR"><a href="#BPR" class="headerlink" title="BPR"></a>BPR</h2><hr>
<p>首先介绍<strong>Optimization Criterion</strong>.我们要最大化下面的后验概率,其中θ是模型参数,模型可以是MF等<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/85AC32E9-A5C8-4B8A-B06F-DED03B070D8A.png" alt="">……(1)(∝表示正比)<br>左边表示在&gt;u这种desired latent preference structure下,取得模型参数θ的值的概率,最大概率时的θ就是我们需要的θ,然后&gt;u的关系是由训练样本来拟合的.</p>
<p>我们假设用户之间行为独立性,用户对不同item行为的独立性.于是<img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/DBA955C0-1D2E-4A66-BD82-B024DE3EF4F5.png" alt="">可以重写为<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/B732FAA5-DDE2-4BB5-8590-C148E42F0DB5.png" alt="">……(2)<br>(2)式的意思是把&gt;u这个关系拆成S中所有(u,i,j)对的独立关系之积,那么,其值也就是所有满足&gt;u关系的(u,i,j)对,取出现概率;而所有不满足&gt;u关系的(u,i,j)对,取不出现概率(1-出现概率).<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/D781948F-82EA-4B68-9070-B3EF3EF8523B.png" alt=""><br>(2)式又因为对称性可以简化为<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/118E2BCA-00E3-47EB-9568-1A521133AF4D.png" alt="">…….(3)<br>然后分析(3)的右边,我们可以定义用户u对Ds中的(u,i,j)对,对i的喜好真大于u的概率是<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/E7D90E3E-21AD-406C-980E-EC1E29171D1F.png" alt="">…….(4)<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/60D62C44-8BB8-4E84-9007-FF620A5BA72E.png" alt=""><br>而x^表示底层模型(KNN,MF)的输出(建模了u与i,j之间的潜在关系),我们也就是把底层模型的输出利用sigmoid映射到(0,1)之间的概率.</p>
<p>在(1)式右边,<img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/BA5DF0C6-4480-49D5-A714-DA1B783CB008.png" alt="">还没有讨论.我们引入一个一般的先验密度p（Θ），它是一个零均值和方差-协方差矩阵∑θ的正态分布:<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/9B9402C0-0412-4182-B1B8-A029C8CF85C2.png" alt="">……..(5)</p>
<p>于是,我们可以取(1)式左边的对数似然函数.<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/6DE206CC-5FAE-46C9-A774-0DCC1A97477C.png" alt="">…….(6)<br>where λΘ are model speciﬁc regularization parameters.<br>第一步是按(1)式得到,第二部是按(4)式得到,第三部按的是对数运算法则,第四步按…??</p>
<h3 id="学习算法"><a href="#学习算法" class="headerlink" title="学习算法"></a>学习算法</h3><p>我们知道我们要学习的就是(6)式,使其最大(极大似然).(6)式是可微的,梯度下降是明显的选择,但是对我们的问题还是需要修改,我们使用a stochastic gradient-descent algorithm based on bootstrap sampling of training triples<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/2D9DEB33-2A8D-4D61-9074-56902BF37C8C.png" alt=""></p>
<p>首先求(6)对θ的梯度:<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/7E514964-282C-4276-8F5C-AFDABE888A3A.png" alt=""><br>只需要知道x^对参数的导数就可以计算了.</p>
<p>首先因为我们的训练样本是Ds=O(S*I),整体梯度下降不可行.<br>梯度下降是这样<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/1661373F-E76D-4761-9C25-5535260BDF99.png" alt=""><br>这是好的,但是有一个问题是我们如何遍历训练样本,如果user-wise或者item-wise,这可以导致poor convergence(收敛性差),因为在一个same u-i pair上有很多连续的更新==&gt;for one user-item pair (u,i) there are many j with (u,i,j)∈ DS.</p>
<p>为了解决上面问题,我们随机选择三元组,采用bootstrap sampling approach with replacement().我们不需要遍历所有样本一次,因为样本好大,通常一部分就够了.下图显示了效果<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/2F9496B6-D4BA-447F-AF31-ECC67D255A80.png" alt=""></p>
<h2 id="结合其他模型"><a href="#结合其他模型" class="headerlink" title="结合其他模型"></a>结合其他模型</h2><hr>
<p>我们选择MF和KNN,其学习结果都是(u,l)用户u对物品l的喜好x^ul.我们可以定义x^uij为:<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/EF77E2F2-BC6D-4881-9634-DF728B67B79D.png" alt="">……(7)<br>意思很明确,把两者的分差在bpr里把这拟合成喜欢i超过j的概率.</p>
<p>对于MF,用户物品评分矩阵X^分解为了W*H,W是用户隐因子矩阵,H是item隐因子矩阵,wu表示用户向量,hi表示物品向量.于是MF的θ就是(W,H),也可以看做latent variables.对于ranking,我们执行BPR-Opt算法,其中我们需要^x(7式)对参数的导数,给出如下:<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/04FCFD29-17A4-4E09-9077-F09F4B706A08.png" alt=""><br>也就是说,x^uij跟三种参数有关,就是<br>另外,还使用三个正则约束,one λ W for the user features W; for the item features H we have two regularization constants, λH+ that is used for positive updates on hif , and λH− for negative updates on hjf .</p>
<p>对于Adaptive KNN,由于KNN不是机器学习算法,我们使用adaptive KNN(利用机器学习来学习ii相似度矩阵C),描述如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A better strategy is to adapt the similarity measure C to the problem by learning it. This can be either done by using C directly as model parameters or if the number of items is too large, one can learn a factorization HH t of C with H : I × k. In the following and also in our evaluation we use the ﬁrst approach of learning C directly without factorizing it.</span><br><span class="line"></span><br><span class="line">Again for optimizing the kNN model for ranking, we apply the BPR optimization criterion and use the LearnBPR algorithm. For applying the algorithm, the gradient of xˆ uij with respect to the model parameters C is:</span><br></pre></td></tr></table></figure></p>
<p>同样需要求偏导,下面给出<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/7F7655BA-5604-47F4-8336-41D657DB0B96.png" alt=""><br>We have two regularization constants, λ + for updates on c il , and λ − for updates on cjl .</p>
<h2 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h2><hr>
<p>使用AUC评估指标,结果如下,看看就好<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/C8ADC423-3CC0-49EA-BB2C-D94192F8ED01.png" alt=""></p>
<h2 id="Bootstrap"><a href="#Bootstrap" class="headerlink" title="Bootstrap"></a>Bootstrap</h2><hr>
<p>Bootstrap的思想，是生成一系列bootstrap伪样本，每个样本是初始数据有放回抽样。通过对伪样本的计算，获得统计量的分布。例如，要进行1000次bootstrap，求平均值的置信区间，可以对每个伪样本计算平均值。这样就获得了1000个平均值。对着1000个平均值的分位数进行计算， 即可获得置信区间。已经证明，在初始样本足够大的情况下，bootstrap抽样能够无偏得接近总体的分布<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/993102CD-8DF3-4EBF-AB09-67EF0301FE0E.png" alt=""></p>
<h2 id="AUC-ROC曲线"><a href="#AUC-ROC曲线" class="headerlink" title="AUC/ROC曲线"></a>AUC/ROC曲线</h2><hr>
<p>首先有</p>
<ul>
<li>精确度P:正划分里正例的比例</li>
<li>召回率R:正例处于正划分的比例</li>
</ul>
<p>对于分类任务,我们想象把测试样本按输出概率排序(负左正右),分类相当于在序列中选择一个::截断点::.如果你重视P,那么截断点选得靠前一点(保证概率较大的你才当做正例),要是重视R,你就把截断点放后面一点.一个截断点就对应一个P/R,就可以画P/R曲线.(在RS中就对应N).我们把截断点的左边称为<strong>负划分</strong>,右边称为<strong>正划分</strong>.</p>
<p>我们使用ROC来研究模型的泛化性能.同样按上面的截断方法,可以得到ROC曲线.</p>
<ul>
<li>y轴是:真正例率,其实就是召回率(::所有正例里处于你的正划分内的比例::)</li>
<li>x轴是:假正例率,::所有反例里处于你正划分内的比例::,公式是 <blockquote>
<p>(预+真-)/[(预-真-)+(预+真-)]  </p>
</blockquote>
</li>
</ul>
<p>下面是一个ROC曲线的样子,对角线代表的即使随猜测….点(0,1)是理想情况,代表<strong>把所有正例排在了反例之前.</strong>可以看见,(0,0)对应代表你把全部都视为反例,(1,1)对应你把全部都视为正例<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/656F644F-2862-4A9D-A25B-D66F9A0707D2.png" alt=""></p>
<p>和P/R曲线一样,若一个模型A的ROC曲线包住另一个模型B,则A性能更好,但是在曲线交叉的时候难以判断,此时::合理的依据是ROC曲线下的面积: AUC::</p>
<p>当我们拥有ROC坐标上的点{(x1,y1),(x2,y2),(x3,y3)…},通过下面公式来估算AUC<br><img src="/2018/01/25/Bayesian personalized ranking from implicit feedback 1/F9D93F2C-A55E-4306-82D2-63EADAB70A10.png" alt=""></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/01/22/Evaluation of RecommendationsRating-Prediction and Ranking/" rel="next" title="">
                <i class="fa fa-chevron-left"></i> 
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/01/25/Bayesian personalized ranking from implicit feedback/" rel="prev" title="">
                 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">PW</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">69</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Bayesian-personalized-ranking-from-implicit-feedback"><span class="nav-number">1.</span> <span class="nav-text">Bayesian personalized ranking from implicit feedback</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#ABSTRACT"><span class="nav-number">1.1.</span> <span class="nav-text">ABSTRACT</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#INTRODUCTION"><span class="nav-number">1.2.</span> <span class="nav-text">INTRODUCTION</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RELATED-WORK"><span class="nav-number">1.3.</span> <span class="nav-text">RELATED WORK</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Personalized-Ranking"><span class="nav-number">1.4.</span> <span class="nav-text">Personalized Ranking</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BPR"><span class="nav-number">1.5.</span> <span class="nav-text">BPR</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#学习算法"><span class="nav-number">1.5.1.</span> <span class="nav-text">学习算法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#结合其他模型"><span class="nav-number">1.6.</span> <span class="nav-text">结合其他模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#评估"><span class="nav-number">1.7.</span> <span class="nav-text">评估</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Bootstrap"><span class="nav-number">1.8.</span> <span class="nav-text">Bootstrap</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#AUC-ROC曲线"><span class="nav-number">1.9.</span> <span class="nav-text">AUC/ROC曲线</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">PW</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
